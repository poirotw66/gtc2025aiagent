# 下一代生成式推荐模型训推引擎的建设和落地实践
[會議影片連結](https://www.nvidia.com/gtc/session-catalog/?search=%E4%B8%8B%E4%B8%80%E4%BB%A3%E7%94%9F%E6%88%90%E5%BC%8F%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E6%8E%A8%E5%BC%95%E6%93%8E%E7%9A%84%E5%BB%BA%E8%AE%BE%E5%92%8C%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5&tab.catalogallsessionstab=16566177511100015Kus#/session/1734091150868001dcjp)
# 下一代生成式推薦模型訓推引擎的建設和落地實踐

## Key Takeaways
本次會議介紹了美團如何建設和落地下一代生成式推薦模型，以及為此設計的訓推引擎 MTGR。重點在於解決生成式推薦模型訓練和推理所面臨的挑戰，包括訓練成本高、推理延遲要求嚴格等問題。
### 重點摘要：
*   美團為何採用生成式推薦模型，以及其優勢。
*   生成式推薦模型 MTGR 的設計與實現，包括訓練和推理引擎。
*   針對訓練和推理的工程優化，顯著降低成本並提升效率。
*   未來展望，包括實時學習、性能優化、模型規模擴展等方向。
### Topic: 推薦系統、生成式模型、訓推引擎、工程優化

## 會議主題
會議主要探討了美團在外賣場景下，如何利用生成式思想構建下一代推薦模型，並介紹了為支持該模型所設計的 MTGR 訓推引擎，以及在工程上進行的優化工作。

## 主要技術點
*   **生成式推薦模型 (GR)：** 採用 Listwise 建模方式，將同一用戶的多次曝光壓縮成一條樣本，避免重複計算和額外開銷。
*   **MTGR Training：** 基於 TouchRack 构建，支持千億參數、By GFLOPs Per Example 計算量的模型的訓練，並進行了功能擴展和性能優化。
*   **混合並行策略：** 採用 Spas 部分模型並行，加 Dense 部分數據並行的混合並行策略，並計劃引入更複雜的模型並行策略。
*   **動態 Hash Table：** 支持動態擴容，無需提前設置容量，無需提前對 ID 進行預映射，更適合工業界場景。
*   **自動合表：** 用戶僅需定義特征的關鍵屬性，即可自動生成模型的 SPAS 部分，並對多個吸收表進行自動合併。
*   **Kernel 優化：** 集成 NVIDIA 提供的深度優化的 Catalyst-based HSTU kernel，大幅提升了 Attention 的計算效率。
*   **變長序列負載均衡：** 引入動態 Batch Size，根據實際的數據序列長度動態調整，從而保證計算量基本相同。
*   **MTGR Inference：** 基於 TensorRT 和 Triton Inference Server，並進行了特征 H2D 優化、CUDA Graph 優化、FP16 計算等優化。
*   **User Cache：** 針對推薦場景的特點設計，復用序列中絕大部分的計算結果，只計算新增的 Token，降低計算開銷。

## 決策與共識
*   採用生成式推薦模型，以提升推薦效果和訓練推理效率。
*   構建 MTGR 訓推引擎，以支持大規模生成式推薦模型的訓練和推理。
*   採用混合並行策略，以充分利用計算資源。
*   進行多項工程優化，以降低訓練成本和推理延遲。

## 時間規劃與里程碑
*   已成功將生成式推薦模型應用於美團外賣場景，並取得了不錯的效果提升。
*   持續進行模型和引擎的優化，以進一步提升性能和降低成本。
*   未來將探索實時學習、模型規模擴展等方向。

## 未解決的技術挑戰
*   GR 模型尚未支持實時學習。
*   Embiting 壓縮、低精度訓練等優化手段還有較大的性能提升空間。
*   需要支持更大規模的 GR 模型，需要借鉴大模型的训练方法，支持 Dense 模型的并行训练。

## 後續行動計劃
*   將 GR 模型和實時學習結合起來。
*   通過 Embiting 壓縮、低精度訓練等優化手段，進一步提升性能。
*   借鉴大模型的训练方法，支持 Dense 模型的并行训练，进而支持更大规模的 GR 模型。
*   嘗試 AOT Compile，通過編譯優化手段，進一步提升 PyTouch 模型性能。
