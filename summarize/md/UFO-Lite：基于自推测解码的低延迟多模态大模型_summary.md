# UFO-Lite：基于自推测解码的低延迟多模态大模型
[會議影片連結](https://www.nvidia.com/gtc/session-catalog/?search=UFO-Lite%EF%BC%9A%E5%9F%BA%E4%BA%8E%E8%87%AA%E6%8E%A8%E6%B5%8B%E8%A7%A3%E7%A0%81%E7%9A%84%E4%BD%8E%E5%BB%B6%E8%BF%9F%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B&tab.catalogallsessionstab=16566177511100015Kus#/session/1727321215230001Bhv2)
# UFO-Lite：基於自推測解碼的低延遲多模態大模型

## Key Takeaways
本次會議主要介紹了百度提出的 UFO Lite，一種針對多模態大模型推理成本和性能的優化方法。該方法基於投機解碼，通過大小模型協同工作，在保證精度的前提下，顯著降低推理延遲。
### 重點摘要：
*   UFO Lite 是業界首個多模態投機解碼工作，解決了多模態投機採樣引入的新挑戰。
*   UFO Lite 適用於任意多模態大模型，可通過自協同進行加速，無需 tokenizer 限制。
*   UFO Lite 基於 Tokenizer 的 LM 進行研發，與緩存機制深度優化，可在 Llama 2 上實現極致推理速度。
*   UFO Lite 通過在線量化和蒸餾等技術，進一步提升加速比和精度。
### Topic: 多模態大模型推理優化、投機解碼、模型加速

## 會議主題
會議主要探討了如何通過 UFO Lite 技術優化多模態大模型的推理成本和性能，特別是在多模態任務中短 Token 回答和視覺特徵引入帶來的挑戰。

## 主要技術點
*   **投機解碼 (Speculative Decoding)：** 使用快速輕量級的小模型 (Draft Model) 生成預測序列，然後使用大模型並行驗證，從而加速推理過程。
*   **自協同 (Self-Collaboration)：** 使用大模型自身的量化版本 (如 Int4 TRT 模型) 作為小模型，避免了 tokenizer 不一致的問題，適用於任意模型。
*   **Confidence-based 自適應切換策略：** 針對短 Token 任務，提出基於置信度的自適應切換策略，提升性能。
*   **在線量化 (Online Quantization)：** 通過在線量化，可以比離線量化獲得更高的加速比。
*   **模型蒸餾 (Model Distillation)：** 通過模型蒸餾，將大模型的輸出分佈作為監督信號，提升小模型的精度和接受率。
*   **Dynamic Window：** 針對不同長度的任務，提出動態窗口策略，避免了固定窗口大小對性能的影響。

## 決策與共識
*   採用 UFO Lite 技術，優化多模態大模型的推理成本和性能。
*   使用自協同方式，簡化模型選型，適用於任意模型。
*   通過在線量化和蒸餾等技術，進一步提升加速比和精度。
*   針對不同任務，採用動態窗口策略，提升模型的魯棒性。

## 時間規劃與里程碑
*   UFO Lite 已在百度內部多個多模態應用中落地。
*   持續優化 UFO Lite 技術，提升加速比和精度。
*   探索 UFO Lite 在更多場景下的應用。

## 未解決的技術挑戰
*   如何進一步提升小模型的精度，從而提高接受率，降低推理延遲。
*   如何更好地處理長文本推理中的幻覺問題。
*   如何將 UFO Lite 技術應用於更多種類的多模態任務。

## 後續行動計劃
*   繼續研究和優化 UFO Lite 技術，提升性能和魯棒性。
*   探索 UFO Lite 與其他加速技術 (如 Multi-Token Prediction) 的結合。
*   將 UFO Lite 技術開源，促進多模態大模型的發展。
