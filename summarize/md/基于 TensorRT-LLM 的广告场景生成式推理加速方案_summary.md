```markdown
# 基于 TensorRT-LLM 的广告场景生成式推理加速方案
[會議影片連結](https://www.nvidia.com/gtc/session-catalog/?search=%E5%9F%BA%E4%BA%8E%20TensorRT-LLM%20%E7%9A%84%E5%B9%BF%E5%91%8A%E5%9C%BA%E6%99%AF%E7%94%9F%E6%88%90%E5%BC%8F%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E6%96%B9%E6%A1%88&tab.catalogallsessionstab=16566177511100015Kus#/session/1727962469507001ov1v)
# 基於 TensorRT-LLM 的廣告場景生成式推理加速方案

## Key Takeaways
本次分享介紹了京東廣告研發團隊在生成式推薦領域的工作，重點針對工業化落地場景，尤其是在高吞吐、低延時要求的生產環境下，所做的生產級推理加速方案。
### 重點摘要：
*   介紹了生成式技術在電商廣告場景下的發展契機，以及如何解決廣告業務的痛點。
*   闡述了生成式算法在廣告場景的具體應用落地方式。
*   分享了為了解決生成式模型推理延遲和吞吐壓力，在工程實踐方面所做的軟硬體協同設計以及優化，以達到算力的極致釋放。
### Topic: 生成式模型推理加速、TensorRT-LLM、廣告推薦

## 會議主題
會議主要探討了如何利用 TensorRT-LLM 在廣告場景下加速生成式模型的推理，以滿足高吞吐、低延遲的生產環境需求。

## 主要技術點
*   **知識融合：** 利用大語言模型融合用戶、環境和商品的知識，解決傳統電商場景建模的局限性。
*   **Scaling Law：** 大語言模型的 Scaling Law 曲線優於傳統 CTR 模型，可以通過增加數據和算力資源獲得更多收益。
*   **語義 ID：** 介於數字化 ID 和文本類數據之間，既具有良好的區分性，又具有豐富的語義信息。
*   **TensorRT-LLM 最佳實踐：**
    *   通過調整 `max_batch_size` 和 `max_number_tokens` 參數，優化吞吐量。
    *   根據 KV Cache 容量設置最佳 Batch Size。
    *   考慮 Token 採樣解碼過程中的顯存佔用，合理設置 Beam 寬度。
    *   利用 Trunked Context 功能，緩解超長序列輸入請求對延遲的影響。
    *   使用 LORA 微調推理方案，並手動配置 `max_lora_rank` 參數，節省顯存。
*   **廣告場景特性優化：**
    *   針對模型時效性強的特點，採用微調參數更新或全參數更新，並實現 KV Cache 復用能力和 Token 的生命週期管理。
    *   針對生成式模型需要受限生成的特點，優化搜索採樣階段，將搜索空間從 15 萬壓縮到千級。
*   **異構硬體分佈式推理架構：** 協同 CPU 和 GPU 的算力，充分發揮硬體優勢，優化模型計算過程。
*   **KV Cache Pool：** 針對用戶行為序列重複度高的特點，設計基於 User Pin 的 KV Memory 緩存池，減少重複計算。

## 決策與共識
*   採用 TensorRT-LLM 作為生成式模型推理加速的基礎框架。
*   針對廣告場景的特性，進行針對性的優化，以滿足高吞吐、低延遲的需求。
*   利用異構硬體分佈式推理架構和 KV Cache Pool，進一步提升系統性能。

## 時間規劃與里程碑
*   未提及具體的時間規劃與里程碑。

## 未解決的技術挑戰
*   未提及未解決的技術挑戰。

## 後續行動計劃
*   基於電商的垂直領域知識，構建電商理解基座模型。
*   探索端到端的生成式召回排序一體化解決方案。
```