# 面向海量模型业务场景的文生图高效推理加速解决方案
[會議影片連結](https://www.nvidia.com/gtc/session-catalog/?search=%E9%9D%A2%E5%90%91%E6%B5%B7%E9%87%8F%E6%A8%A1%E5%9E%8B%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E7%9A%84%E6%96%87%E7%94%9F%E5%9B%BE%E9%AB%98%E6%95%88%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88&tab.catalogallsessionstab=16566177511100015Kus#/session/1727591250467001Ojoz)
# 面向海量模型業務場景的文生圖高效推理加速解決方案

## Key Takeaways
本次會議主要介紹了阿里云在面向海量模型業務場景下，針對文生圖模型的高效推理加速解決方案。該方案通過算子優化、模型編譯優化和性能建模等手段，顯著提升了推理性能，降低了業務成本。
### 重點摘要：
*   性能提升：最高可達1.9倍的性能提速。
*   編譯時間優化：將模型編譯時間從30分鐘縮短至5秒。
*   硬件性能建模：針對不同硬件進行性能建模，端到端帶來額外5%-10%的性能收益。
*   業務成本下降：實現30%-50%的業務成本下降。
### Topic: 文生圖模型推理加速

## 會議主題
會議主要探討了文生圖模型在海量模型業務場景下的高效推理加速解決方案，包括算子優化、模型編譯優化和性能建模等關鍵技術。

## 主要技術點
*   **算子優化：**
    *   針對矩陣乘、卷積和注意力算子等計算密集型算子，採用調整矩陣分塊大小、片上數據復用、多級流水線和分塊調度等手段進行性能優化。
    *   針對GroupNorm、LayerNorm等訪存密集型算子，採用算子融合、single path reduce、向量讀寫等方法進行優化。
*   **模型編譯優化：**
    *   對矩陣乘和卷積算子進行預調優，並將調優結果保存到文件中，在推理服務啟動時直接復用。
    *   研發一套權重追蹤機制，對模型結構進行緩存，後續遇到類似結構或相同結構時，直接提取權重進行替換。
*   **硬件性能建模：**
    *   對不同顯卡的硬件進行性能建模，利用理論模型確定矩陣乘和卷積尺寸搜索的邊界，從而在短時間內完成對SD模型中所有矩陣乘和卷積的所有尺寸的便利調優。
*   **推理框架：**
    *   計算圖表示與轉換層：負責計算圖的解析與轉換。
    *   圖優化層：對注意力、規一化等操作進行計算圖層面的融合優化。
    *   運行時層：負責顯存的管理和推理流程的調用。
    *   高性能算子層：包括算子調優、算子性能建模、手寫模板或CUDN、CUDUS等算子調用的邏輯。

## 決策與共識
*   通過算子優化、模型編譯優化和性能建模等手段，實現文生圖模型的高效推理加速。
*   採用預調優和模型結構緩存等方法，縮短模型編譯時間。
*   針對不同硬件進行性能建模，實現任意尺寸下的高性能推理。

## 時間規劃與里程碑
*   已完成SD1.5、SDXL和FLUX模型的性能優化。
*   未來將聚焦於文生視頻、模型調度優化和分布式推理框架的實現。

## 未解決的技術挑戰
*   如何進一步提升文生視頻的推理性能。
*   如何實現顯存和算力的充分利用。
*   如何對計算和通信進行重疊優化。

## 後續行動計劃
*   繼續在文生視頻場景開展工作，並進一步提升性能。
*   對文生圖和文生視頻的模型進行調度優化，達到顯存和算力的充分利用。
*   進行分布式推理框架的實現，並對計算和通信進行重疊優化。
*   持續适配最新的架構，從而在最新GPU上實現更低的出圖延遲。
