# 端到端全场景智能驾驶
[會議影片連結](https://www.nvidia.com/gtc/session-catalog/?search=%E7%AB%AF%E5%88%B0%E7%AB%AF%E5%85%A8%E5%9C%BA%E6%99%AF%E6%99%BA%E8%83%BD%E9%A9%BE%E9%A9%B6&tab.catalogallsessionstab=16566177511100015Kus#/session/1735048517548001aFvY)
端到端全場景智能駕駛

## Key Takeaways
本次會議主要介紹了小米汽車在端到端全場景智能駕駛方面的最新進展，包括物理世界探索、物理世界建模以及工程落地優化和持續演進。重點強調了數據驅動和模型泛化的能力，以及全場景智駕對用戶體驗的重塑。
### 重點摘要：
*   端到端智能駕駛系統的構建，包括物理世界探索和建模。
*   小米汽車在物理世界探索方面的硬件基礎和數據積累。
*   物理世界建模的三層架構：數據觀測層、隱私特徵層和顯示符號層。
*   工程落地優化和持續演進，包括雲端和車端的算力優化。
*   全場景智駕功能的快速迭代和場景拓展。
### Topic: 自動駕駛、深度學習、模型優化

## 會議主題
會議主要探討了如何構建在物理世界中魯棒運行的端到端智能駕駛系統，涵蓋了物理世界探索、物理世界建模以及工程落地優化和持續演進等方面。

## 主要技術點
*   **物理世界探索：** 通過大規模車隊收集多模態數據，實現對物理世界的全面認知。
*   **物理世界建模：**
    *   **數據觀測層 (大OT)：** 原始數據的記錄，如圖像、點雲等。
    *   **隱私特徵層 (大JT)：** 通過深度神經網絡學習到的場景理解。
    *   **顯示符號層 (大ST)：** 方便人理解和操作的符號表達，如車道線、行人、車輛等。
*   **時序建模：** 將三層表達聯合起來進行實踐建模，預測未來幀的數據。
*   **工程落地優化：**
    *   **雲端優化：** 利用 NVIDIA 算力，提升自動標註大模型推理的利用率。
    *   **車端優化：** 減少模型不必要的連接，優化耗時算子，將圖像前處理和點雲數據壓縮 Offload 到 E-GPU 計算單元。

## 決策與共識
*   採用端到端架構，實現全場景智能駕駛。
*   通過大規模車隊收集數據，為模型訓練提供數據基礎。
*   利用深度學習模型，實現對物理世界的建模和理解。
*   進行工程落地優化，提升雲端和車端的算力利用率。

## 時間規劃與里程碑
*   2024 年實現智能駕駛一年追三代的快速追趕。
*   持續拓展智能駕駛的應用場景，從高速、泊車到城區，最終實現全場景覆蓋。
*   準備基於千萬 Clips 的端到端版本。

## 未解決的技術挑戰
*   未來幀的建模是難點和重點，因為車端實施系統無法直接觀測。

## 後續行動計劃
*   持續交付自駕功能，從相對簡單的高速泊車場景拓展到複雜的城區場景。
*   打通各場景行車的全場景車位到車位的完整體驗。
*   準備基於千萬 Clips 的端到端版本。
