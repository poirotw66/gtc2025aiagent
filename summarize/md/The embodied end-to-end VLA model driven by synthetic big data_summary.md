# The embodied end-to-end VLA model driven by synthetic big data
[會議影片連結](https://www.nvidia.com/gtc/session-catalog/?search=The%20embodied%20end-to-end%20VLA%20model%20driven%20by%20synthetic%20big%20data&tab.catalogallsessionstab=16566177511100015Kus#/session/1726155424858001HJ8h)
# 由合成大數據驅動的具體化端到端 VLA 模型

## Key Takeaways
本次會議主要介紹 Galbot 公司及其在具體化通用人工智慧（AGI）代理方面的研究，重點是利用合成數據來訓練端到端的視覺語言動作（VLA）模型，以賦能通用機器人。
### 重點摘要：
*   Galbot 是一家專注於開發通用機器人的公司，旨在提供適用於各種應用的通用移動操作。
*   通用機器人相較於特定用途機器人更具革命性，可通過自然語言進行交流，無需編碼，並能進行零樣本和少樣本學習以獲得更多技能。
*   端到端的 VLA 模型是賦能通用機器人的關鍵，該模型以語言、視覺和其他感知和傳感器信號作為輸入，並輸出動作。
*   合成數據是解決 VLA 模型數據瓶頸的有效方法，可以大規模生成數據，並避免真實數據收集的成本和限制。
*   Galbot 通過合成數據在視覺語言導航和抓取任務上取得了顯著成果，展示了合成數據在訓練通用 VLA 模型方面的潛力。
### Topic: 機器人、人工智慧、合成數據、視覺語言動作模型

## 會議主題
會議主要探討了如何利用合成數據來訓練端到端的視覺語言動作（VLA）模型，以賦能通用機器人，使其能夠執行各種任務，包括導航和抓取。

## 主要技術點
*   **端到端 VLA 模型：** 該模型將視覺感知、任務規劃和動作生成整合到一個單一模型中，實現了機器人的自主行為。
*   **合成數據生成：** Galbot 開發了自己的對象資產和動作合成管道，可以生成大規模的機器人抓取數據，涵蓋各種不同的環境、對象和照明條件。
*   **視覺語言導航：** Galbot 的 NAVID 模型利用合成數據進行訓練，可以在未見過的環境中進行導航，並理解複雜的語言指令。
*   **空間智能：** Galbot 的 NAVID-4D 模型通過引入深度信息，提高了機器人的空間推理能力，使其能夠更好地理解環境和執行需要空間智能的任務。
*   **抓取 VLA 模型：** Galbot 利用合成數據訓練的抓取 VLA 模型，具有良好的泛化能力，可以在不同的照明、背景和對象位置下成功抓取對象。
*   **遷移學習：** 通過在合成數據上進行預訓練，然後在少量真實數據上進行微調，可以快速將模型部署到真實世界中，並適應特定的任務和環境。

## 決策與共識
*   合成數據是解決 VLA 模型數據瓶頸的有效方法，可以大規模生成數據，並避免真實數據收集的成本和限制。
*   端到端的 VLA 模型是賦能通用機器人的關鍵，該模型可以將視覺感知、任務規劃和動作生成整合到一個單一模型中。
*   通過在合成數據上進行預訓練，然後在少量真實數據上進行微調，可以快速將模型部署到真實世界中，並適應特定的任務和環境。

## 時間規劃與里程碑
*   Galbot 計劃繼續擴大其合成數據集，並開發更強大的 VLA 模型。
*   Galbot 計劃將其機器人應用於零售、醫療保健和工業等各種場景。
*   Galbot 計劃在今年年底開設多家機器人商店。

## 未解決的技術挑戰
*   如何進一步提高合成數據的真實性，以縮小模擬和真實世界之間的差距。
*   如何設計更有效的 VLA 模型架構，以提高機器人的泛化能力和魯棒性。
*   如何開發更智能的後訓練方法，以減少對真實數據的需求。

## 後續行動計劃
*   繼續開發和改進合成數據生成管道。
*   探索新的 VLA 模型架構和訓練方法。
*   將機器人部署到更多真實世界的應用場景中。
*   與合作夥伴合作，共同推動通用機器人的發展。
