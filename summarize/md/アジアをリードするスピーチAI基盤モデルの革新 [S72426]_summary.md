# アジアをリードするスピーチAI基盤モデルの革新 [S72426]
[會議影片連結](https://www.nvidia.com/gtc/session-catalog/?search=%E3%82%A2%E3%82%B7%E3%82%99%E3%82%A2%E3%82%92%E3%83%AA%E3%83%BC%E3%83%88%E3%82%99%E3%81%99%E3%82%8B%E3%82%B9%E3%83%92%E3%82%9A%E3%83%BC%E3%83%81AI%E5%9F%BA%E7%9B%A4%E3%83%A2%E3%83%86%E3%82%99%E3%83%AB%E3%81%AE%E9%9D%A9%E6%96%B0%20%5BS72426%5D&tab.catalogallsessionstab=16566177511100015Kus#/session/1727061162642001LR0l)
# 引領亞洲的語音AI基礎模型的創新 [S72426]

## Key Takeaways
本次演講介紹了言葉テクノロジーズ在語音AI基礎模型上的創新，特別是在AI同步翻譯方面的應用。重點展示了他們如何利用大規模GPU資源和端到端模型，實現低延遲、高精度的多語言同步翻譯。
### 重點摘要：
*   言葉テクノロジーズ是一家致力於利用語音生成AI打破語言壁壘的公司，專注於AI同步翻譯技術的研發。
*   該公司採用端到端的方法，直接將語音輸入模型，並輸出翻譯後的語音，減少了傳統流水線方法的延遲。
*   他們利用NVIDIA的GPU資源，特別是H100 GPU，大規模訓練語音AI模型，並在多語言語音生成和同步翻譯方面取得了顯著成果。
*   展示了AI同步翻譯的Demo，包括日語到英語、韓語等多種語言的即時翻譯，以及聲音模仿和情感控制等功能。
### Topic: AI Platforms / Deployment - AI Inference / Inference Microservices

## 會議主題
會議主要探討了言葉テクノロジーズ如何通過大規模GPU資源和端到端模型，實現低延遲、高精度的多語言同步翻譯，以及他們在語音AI基礎模型上的技術創新。

## 主要技術點
*   **端到端模型 (End-to-End)：** 直接將語音輸入模型，並輸出翻譯後的語音，減少了傳統流水線方法的延遲，更易於擴展。
*   **自迴歸Transformer (Autoregressive Transformer)：** 類似於文本LLM，但應用於語音領域，通過Token化將語音轉換為Token序列，然後進行學習和生成。
*   **語音Token化和壓縮：** 通過Token化將語音轉換為Token序列，並進行壓縮，以減少計算量和提高效率。
*   **大規模GPU訓練：** 利用NVIDIA的GPU資源，特別是H100 GPU，大規模訓練語音AI模型，提高模型的性能和泛化能力。
*   **多語言語音生成：** 通過大規模數據訓練，實現多語言語音生成，並可以模仿特定人的聲音和情感。
*   **AI同步翻譯：** 利用端到端模型和大規模GPU訓練，實現低延遲、高精度的多語言同步翻譯。

## 決策與共識
*   採用端到端模型，以實現低延遲和高擴展性的語音AI系統。
*   利用NVIDIA的GPU資源，大規模訓練語音AI模型，提高模型的性能。
*   專注於AI同步翻譯技術的研發，並將其應用於iOS應用和API服務中。
*   將持續優化用戶體驗，提高同步翻譯的精度和情感表達能力。

## 時間規劃與里程碑
*   2023年7月公司成立。
*   已在AI模型共享平台Hugging Face上開源部分模型，累計下載超過50萬次。
*   計劃在iOS應用和API服務中推出AI同步翻譯功能。
*   將持續進行技術研發，提高同步翻譯的精度和情感表達能力。

## 未解決的技術挑戰
*   如何進一步提高同步翻譯的精度和情感表達能力，使其更接近人類翻譯的水平。
*   如何在不同行業和場景下，定制和優化AI同步翻譯模型，以滿足不同用戶的需求。
*   如何在保證安全和隱私的前提下，實現數據中心和邊緣設備的協同工作，以提高AI模型的性能和效率。

## 後續行動計劃
*   繼續擴大GPU資源的投入，大規模訓練語音AI模型。
*   持續優化端到端模型和Token化技術，提高模型的性能和效率。
*   加強與NVIDIA等公司的合作，共同推動語音AI技術的發展。
*   將AI同步翻譯技術應用於更多領域，如Web會議、呼叫中心、遊戲直播等。
