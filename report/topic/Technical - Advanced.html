
    <!DOCTYPE html>
    <html lang="zh-TW">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Technical - Advanced</title>
        <style>
            body {
                font-family: 'Roboto', 'Microsoft JhengHei', sans-serif;
                background-color: #f8f9fa;
                color: #333;
                margin: 0;
                padding: 0;
                line-height: 1.6;
            }
            header {
                text-align: center;
                padding: 30px 20px;
                background: linear-gradient(135deg, #4b6cb7, #182848);
                color: #fff;
                position: relative;
                box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
                border-radius: 10px 10px 0 0;
            }
            header h1 {
                font-size: 2.2rem;
                margin: 0 0 10px 0;
                letter-spacing: 0.5px;
            }
            header p {
                font-size: 1.1rem;
                margin: 0;
                opacity: 0.9;
            }
            header img {
                max-width: 35%;
                height: auto;
                margin-bottom: 15px;
            }
            main {
                max-width: 900px;
                margin: 30px auto;
                padding: 0 20px;
            }
            .content-container {
                background-color: #fff;
                border-radius: 10px;
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
                padding: 30px;
                margin-bottom: 30px;
            }
            .section-block {
                background-color: #fff;
                padding: 25px;
                border-radius: 8px;
                margin-bottom: 25px;
                border-left: 5px solid #4b6cb7;
                box-shadow: 0 3px 10px rgba(0, 0, 0, 0.05);
                transition: transform 0.2s ease, box-shadow 0.2s ease;
            }
            .section-block:hover {
                transform: translateY(-3px);
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            }
            h1 {
                color: 	#FFFFFF;
                font-size: 2rem;
                margin-top: 0;
                margin-bottom: 30px;
                padding-bottom: 10px;
                border-bottom: 2px solid #4b6cb7;
            }
            h2 {
                color: #3498db;
                font-size: 1.5rem;
                margin-top: 25px;
                margin-bottom: 15px;
                padding-bottom: 8px;
                border-bottom: 1px solid #e0e0e0;
            }
            h3 {
                color: #2ecc71;
                font-size: 1.2rem;
                margin-top: 20px;
                margin-bottom: 10px;
            }
            p {
                margin-bottom: 15px;
                line-height: 1.7;
            }
            ul {
                padding-left: 20px;
            }
            li {
                margin-bottom: 10px;
                position: relative;
                list-style-type: none;
                padding-left: 25px;
            }
            li::before {
                content: "•";
                position: absolute;
                left: 0;
                color: #4b6cb7;
                font-size: 1.2rem;
                font-weight: bold;
            }
            footer {
                text-align: center;
                padding: 25px 20px;
                background-color: #f0f2f5;
                color: #666;
                border-radius: 0 0 10px 10px;
                border-top: 1px solid #e0e0e0;
            }
            footer img {
                max-width: 35%;
                height: auto;
                margin-bottom: 15px;
            }
            footer p {
                margin: 5px 0;
                font-size: 0.95rem;
            }
            .meeting-item {
                margin-bottom: 40px;
                padding: 20px;
                background-color: #f7fbff;
                border-radius: 8px;
                border-left: 5px solid #3498db;
                box-shadow: 0 3px 10px rgba(0, 0, 0, 0.05);
                transition: transform 0.2s ease, box-shadow 0.2s ease;
            }
            .meeting-item:hover {
                transform: translateY(-3px);
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            }
            .key-content {
                background-color: #f5fffc;
                padding: 15px;
                border-radius: 5px;
                border-left: 3px solid #1abc9c;
                margin-top: 10px;
                margin-bottom: 15px;
            }
            /* 確保列表項目在 key-content 中正確顯示 */
            .key-content ul {
                padding-left: 15px;
            }
            .key-content li {
                margin-bottom: 8px;
            }
            .key-content li::before {
                color: #1abc9c;
            }
        </style>
    </head>
    <body>
        <header>
            <img src="https://i.imgur.com/0LXUWvj.png" alt="會議摘要圖示">
            <h1>Technical - Advanced</h1>
            <p>類別清單</p>
        </header>
        <main>
            <div class="content-container">
                <h1>Technical - Advanced</h1>
<div class="meeting-item"><h2><a href="./session/NVIDIA 全面赋能端到端自动驾驶_summary.html" style="text-decoration: none; color: inherit;">NVIDIA 全面赋能端到端自动驾驶</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹 NVIDIA 如何在端到端自動駕駛領域提供全面賦能，涵蓋 World Model 的應用、神經重建引擎 (NRE) 以及訓練優化等方面。</p>
<h3>重點摘要：</h3>
<ul>
<li><strong>World Model:</strong> 介紹了 World Model 的起源、在自動駕駛中的應用，以及 NVIDIA Cosmos 平台如何利用 World Model 進行後訓練和重建。</li>
<li><strong>神經重建引擎 (NRE):</strong> 闡述了 NRE 的用途、功能，以及如何利用 NRE 進行三維重建和渲染，並結合生成式 AI 提升新視角渲染效果。</li>
<li><strong>訓練優化:</strong> 分享了 NVIDIA DevTech Team 在圖片訓練、影片訓練以及 Loss 計算方面的優化策略。</li>
</ul>
<h3>Topic: 自動駕駛、World Model、神經重建、訓練優化</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/合成大数据驱动的具身端到端 VLA 大模型_summary.html" style="text-decoration: none; color: inherit;">合成大数据驱动的具身端到端 VLA 大模型</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次演講介紹了 Galbot 公司及其在通用機器人領域的願景，重點探討了如何利用合成數據來賦能端到端視覺語言動作 (VLA) 模型，以實現通用機器人的廣泛應用。</p>
<h3>重點摘要：</h3>
<ul>
<li>Galbot 是一家專注於開發通用 AGI 代理的公司，旨在提供全球通用的機器人解決方案。</li>
<li>通用機器人相較於特定用途機器人具有革命性意義，它們可以通過自然語言進行交互，無需編碼，並具備零樣本和少樣本學習能力。</li>
<li>端到端 VLA 模型是賦能通用機器人的關鍵，它能夠處理視覺感知、任務規劃和動作生成。</li>
<li>合成數據提供了一種可擴展且低成本的數據解決方案，可以克服真實數據收集的瓶頸，並促進 VLA 模型的發展。</li>
<li>Galbot 的 VLA 模型已應用於零售、接待、醫療保健和工業等多個場景。</li>
</ul>
<h3>Topic: 機器人、視覺語言模型、合成數據</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/基于 TensorRT-LLM 的广告场景生成式推理加速方案_summary.html" style="text-decoration: none; color: inherit;">基于 TensorRT-LLM 的广告场景生成式推理加速方案</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次分享介紹了京東廣告研發團隊在生成式推薦領域的工作，重點針對工業化落地場景，尤其是在高吞吐、低延時要求的生產環境下，所做的生產級推理加速方案。</p>
<h3>重點摘要：</h3>
<ul>
<li>介紹了生成式技術在電商廣告場景下的發展契機，以及如何解決廣告業務的痛點。</li>
<li>闡述了生成式算法在廣告場景的具體應用落地方式。</li>
<li>分享了為了解決生成式模型推理延遲和吞吐壓力，在工程實踐方面所做的軟硬體協同設計以及優化，以達到算力的極致釋放。</li>
</ul>
<h3>Topic: 生成式模型推理加速、TensorRT-LLM、廣告推薦</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/Leverage Tailored LLMs for Improved Insights in Rail Transportation [S71296]_summary.html" style="text-decoration: none; color: inherit;">Leverage Tailored LLMs for Improved Insights in Rail Transportation [S71296]</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>Janos 分享了西門子如何利用專業化的大型語言模型（LLM）來優化流程、節省成本，以及如何將它們引入團隊並協同工作。他強調了在特定領域採用這些模型的專業知識，並分享了在製藥領域和工程領域的經驗。</p>
<h3>重點摘要：</h3>
<ul>
<li>西門子利用LLM解決大型資料問題，特別是工程領域中大量以文字形式存在的知識文件。</li>
<li>客製化LLM在多標籤分類、合規性聲明生成和程式碼生成等用例中的應用。</li>
<li>強調了領域特定調整的重要性，以提高準確性和滿足領域專家的需求。</li>
</ul>
<h3>Topic: LLM在鐵路運輸領域的應用</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/NVIDIA 革新智能座舱技术发展_summary.html" style="text-decoration: none; color: inherit;">NVIDIA 革新智能座舱技术发展</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了NVIDIA在生成式AI應用於智能座艙，以及數據中心與車端大模型推理優化加速的解決方案。涵蓋了全鏈路加速、大模型推理框架TRT-LM，以及端側部署等關鍵技術。</p>
<h3>重點摘要：</h3>
<ul>
<li>NVIDIA NEMO平台：端到端的全流程生成式AI解決方案，涵蓋數據處理、分布式訓練、模型客製化、推理加速、RAG以及安全護欄等階段。</li>
<li>Curator數據處理Pipeline：包含文本、圖片和視頻預處理，利用Rapids等組件加速數據清洗、去重和過濾。</li>
<li>FP8訓練：利用Transformer Engine庫，通過E4M3和E5M2格式，在計算密集型算子上提供更高的算力，並節省顯存。</li>
<li>TRT-LM：針對數據中心大模型推理的加速框架，提供高效Runtime、深度優化Kernel、多模型支持、自定義Workflow和高級量化方法。</li>
<li>DriveOS LLM SDK (DriveLM)：專為車端量身定制的大模型推理框架，提供優化加速kernel、輕量化推理Runtime和主流模型端到端推理。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>生成式AI應用</li>
<li>大模型推理優化</li>
<li>端側部署</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/基于端到端世界模型的生成式智驾体验_summary.html" style="text-decoration: none; color: inherit;">基于端到端世界模型的生成式智驾体验</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了卓域科技在端到端自動駕駛技術方面的最新進展，重點介紹了端到端世界模型以及如何基於該模型實現生成式自動駕駛體驗。生成式自動駕駛體驗是卓域首次提出的概念，旨在提供與傳統自動駕駛體驗不同的、更優質的用戶體驗。</p>
<h3>重點摘要：</h3>
<ul>
<li><strong>端到端世界模型：</strong> 卓域正在開發的端到端世界模型，用於實現生成式自動駕駛體驗。</li>
<li><strong>生成式自動駕駛體驗：</strong> 一種新的自動駕駛體驗概念，旨在提供更個性化、更符合用戶需求的駕駛體驗。</li>
<li><strong>個性化駕駛風格：</strong> 通過端到端世界模型，可以實現自定義的駕駛風格和行為，並支持通過語音交互實時改變駕駛風格和動作。</li>
</ul>
<h3>Topic: 自動駕駛、端到端模型、世界模型、生成式體驗</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/大语言模型在智能座舱中的应用_summary.html" style="text-decoration: none; color: inherit;">大语言模型在智能座舱中的应用</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議分享了蔚來汽車在大語言模型於智能座艙中的應用，重點介紹了情感智能，以及背後的技術架構和未來展望。</p>
<h3>重點摘要：</h3>
<ul>
<li>蔚來汽車將人工智能視為智能電動汽車的核心能力，並貫穿公司所有環節。</li>
<li>NOMI 作為全球首個以人工智能為核心的情感夥伴，通過語音、視覺和情感感知與用戶交互。</li>
<li>在大模型時代，NOMI 通過 NOMI GPT 家族技術框架，實現了更自然的人機交互、更強的自主性和更豐富的情感表達。</li>
<li>蔚來汽車在 AGI 方面的整體投入涵蓋了從基礎設施建設到模型層構建、工具鏈到應用開發和應用體驗的方方面面。</li>
</ul>
<h3>Topic: 智能座艙、情感智能、大語言模型應用</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/激发通用人工智能的创造力，引领智能汽车走向新的未来_summary.html" style="text-decoration: none; color: inherit;">激发通用人工智能的创造力，引领智能汽车走向新的未来</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要探討覺影智能如何透過倉駕融合的AI域，激發通用人工智能的創造力，引領智能汽車走向全新的未來。重點包括原生流逝多模態大模型、端到端智能駕駛技術以及倉駕融合驅動的超級智能體演進。</p>
<h3>重點摘要：</h3>
<ul>
<li>覺影智能與英偉達深度合作，構建倉駕融合的三大核心要素：超大算力引擎、原生流逝多模態大模型、端雲一體協同的部署框架。</li>
<li>推出座艙情感引擎 "A New Member for You"，強調積極自主的人機交互體驗。</li>
<li>提出業界首個端到端架構 UNIAD，並實現實車部署，強調低成本感測器配置下的類人駕駛體驗。</li>
<li>提出用量產實車採集的真實數據和世界模型生成的仿真數據形成雙輪驅動的車雲一體數據閉環新範式。</li>
</ul>
<h3>Topic: 倉駕融合、多模態大模型、端到端自動駕駛、世界模型</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/Enhancing Genomic Variant Detection_summary.html" style="text-decoration: none; color: inherit;">Enhancing Genomic Variant Detection</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>概述了基因組分析和精準醫療領域中，GPU 加速如何變革，特別是 NVIDIA Parabricks 的應用。探討了人工智慧、機器學習和高效能 GPU 如何實現快速變異檢測，降低計算成本，並解鎖生物標記物發現和藥物開發的洞察力。</p>
<h3>重點摘要：</h3>
<ul>
<li>基因體學和精準醫療正經歷人工智慧和合成生物學的雙重革命。</li>
<li>AI 模型在生成蛋白質結構、候選藥物和預測疾病風險方面展現了前所未有的準確性。</li>
<li>GPU 加速在處理大規模基因體數據，並將其轉化為可操作的見解方面至關重要。</li>
<li>透過 NVIDIA GPU 和 Parabricks 框架，生物標記物發現的分析時間從數月縮短至數週。</li>
</ul>
<h3>Topic: Genomics, Precision Medicine, GPU Acceleration</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/GLake：大模型训练和推理的显存优化探索_summary.html" style="text-decoration: none; color: inherit;">GLake：大模型训练和推理的显存优化探索</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了螞蟻 AI Infra 推理引擎團隊在過去兩年時間裡，針對大模型訓練和推理所做的一些顯存優化工作，包括訓練階段的 GM-Lake 和推理階段的 VTensor 及 LayerKV。</p>
<h3>重點摘要：</h3>
<ul>
<li><strong>GM-Lake:</strong> 解決大規模訓練過程中的顯存碎片問題，已發表在 S Plus 24 上。</li>
<li><strong>VTensor:</strong> 提供 Pageless 的 Tensor 管理框架，提供更大的靈活性。</li>
<li><strong>LayerKV:</strong> 通過 LayerWise 的 KVCatch 管理來優化首次延遲，並在滿足特定 SLO 情況下提升整體吞吐。</li>
</ul>
<h3>Topic: 顯存優化、大模型訓練、大模型推理</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/从智能驾驶到 AGI：下一代自动驾驶技术的演进_summary.html" style="text-decoration: none; color: inherit;">从智能驾驶到 AGI：下一代自动驾驶技术的演进</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要分享了圓融啓行在自動駕駛技術上的最新思考和進展，特別是從不依賴高精度地圖的研發到端到端的部署上車，再到VLA（視覺語言動作）模型的研發。重點介紹了VLA模型的架構、優勢以及面臨的挑戰，並展望了Road AGI的未來。</p>
<h3>重點摘要：</h3>
<ul>
<li>圓融啓行過去一年的發展：合作車型推出、城市和高速NOA開放、爆款車型製造、DLD模型部署。</li>
<li>VLA模型架構：視覺輸入、文本輸入、視覺編碼器、文本編碼器、多模態信息融合、駕駛動作行為和邏輯推理輸出。</li>
<li>VLA模型的三大優勢：兼容大語言模型範式、具備思維鏈（chain of thought）、駕駛行為更偏向人類偏好。</li>
<li>VLA模型面臨的挑戰：實時響應能力、數據獲取和處理。</li>
<li>Road AGI的目標：實現道路上所有機器人的通用人工智能。</li>
</ul>
<h3>Topic: 自動駕駛、AGI、VLA模型、Road AGI</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/释放 GPU 缓存的强大威能：闪电加速短视频推荐系统！_summary.html" style="text-decoration: none; color: inherit;">释放 GPU 缓存的强大威能：闪电加速短视频推荐系统！</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要討論了如何通過 GPU Embedding Cache 技術來加速短視頻推薦系統，解決 CPU 算力瓶頸問題，充分利用 GPU 的算力。</p>
<h3>重點摘要：</h3>
<ul>
<li>短視頻推薦系統面臨海量數據和用戶增長帶來的計算效率和實時性挑戰。</li>
<li>GPU 加速技術在推薦系統的召回和排序階段已得到廣泛應用。</li>
<li>新一代 GPU 架構（如 Ada）的引入，提升了計算密度，但也帶來了 CPU 算力滯後的問題。</li>
<li>通過將 Embedding 查詢階段從 CPU 卸載到 GPU，可以有效解決 CPU 瓶頸問題。</li>
<li>利用 GPU Embedding Cache，將高頻訪問的熱 Embedding 保留在 GPU 內存中，將低頻訪問的冷 Embedding 存儲在 CPU 內存或參數服務器中，提升 Embedding 查詢整體性能。</li>
</ul>
<h3>Topic: GPU Embedding Cache、短視頻推薦系統、性能優化</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/VLA：迈向自动驾驶物理智能体的关键一步_summary.html" style="text-decoration: none; color: inherit;">VLA：迈向自动驾驶物理智能体的关键一步</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了理想汽車在自動駕駛領域的最新進展，特別是他們提出的視覺語言行為大模型（VLA），旨在將空間智能、語言智能和行為智能統一在一個模型中，打造更像人類的自動駕駛體驗。</p>
<h3>重點摘要：</h3>
<ul>
<li>理想汽車在中國自動駕駛領域面臨的挑戰，包括複雜的道路狀況、多樣的交通規則和動態變化的城市環境。</li>
<li>理想汽車提出的端到端加VRM雙系統架構，以及VLA模型的設計理念和技術細節。</li>
<li>VLA模型在3D空間理解、語言推理和行為生成方面的突破，以及在車端芯片上的實時推理能力。</li>
<li>VLA模型在實際應用中的場景演示，展示了其在陌生環境漫遊、精確定位和人機交互方面的優勢。</li>
</ul>
<h3>Topic: 自動駕駛、AI模型、物理智能</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/下一代生成式推荐模型训推引擎的建设和落地实践_summary.html" style="text-decoration: none; color: inherit;">下一代生成式推荐模型训推引擎的建设和落地实践</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議介紹了美團如何建設和落地下一代生成式推薦模型，以及為此設計的訓推引擎 MTGR。重點在於解決生成式推薦模型訓練和推理所面臨的挑戰，包括訓練成本高、推理延遲要求嚴格等問題。</p>
<h3>重點摘要：</h3>
<ul>
<li>美團為何採用生成式推薦模型，以及其優勢。</li>
<li>生成式推薦模型 MTGR 的設計與實現，包括訓練和推理引擎。</li>
<li>針對訓練和推理的工程優化，顯著降低成本並提升效率。</li>
<li>未來展望，包括實時學習、性能優化、模型規模擴展等方向。</li>
</ul>
<h3>Topic: 推薦系統、生成式模型、訓推引擎、工程優化</h3>
</div></div>
<div class="meeting-item"><h2><a href="./session/重塑短视频视觉体验，基于 TensorRT-LLM 加速的智能视频质量评价与处理大模型_summary.html" style="text-decoration: none; color: inherit;">重塑短视频视觉体验，基于 TensorRT-LLM 加速的智能视频质量评价与处理大模型</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了快手在提升短視頻畫質領域的工作，重點在於使用基於 TensorRT-LLM 加速的智能視頻質量評價與處理大模型，以重塑短視頻的視覺體驗。</p>
<h3>重點摘要：</h3>
<ul>
<li>快手短視頻的現狀以及生產消費鏈路。</li>
<li>快手內部研發的視頻質量評價算法 KVQ。</li>
<li>快手研發的視頻處理大模型 LPM，實現極致的畫質提升。</li>
<li>基於英偉達 TensorRT-LLM 工具進行部署優化，提升服務的推理效率。</li>
</ul>
<h3>Topic: 視頻質量評價、視頻處理、深度學習、模型部署優化</h3>
</div></div>
            </div>
        </main>
        <footer>
            <img src="https://i.imgur.com/0LXUWvj.png" alt="會議摘要圖示">
            <p>此摘要由 AI 輔助生成</p>
            <p>如有任何問題或需要更多詳細資訊，請聯繫 ITR 小組</p>
        </footer>
    </body>
    </html>
    