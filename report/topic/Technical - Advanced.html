
    <!DOCTYPE html>
    <html lang="zh-TW">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Technical - Advanced</title>
        <style>
            body {
                font-family: 'Roboto', 'Microsoft JhengHei', sans-serif;
                background-color: #f8f9fa;
                color: #333;
                margin: 0;
                padding: 0;
                line-height: 1.6;
            }
            header {
                text-align: center;
                padding: 30px 20px;
                background: linear-gradient(135deg, #4b6cb7, #182848);
                color: #fff;
                position: relative;
                box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
                border-radius: 10px 10px 0 0;
            }
            header h1 {
                font-size: 2.2rem;
                margin: 0 0 10px 0;
                letter-spacing: 0.5px;
            }
            header p {
                font-size: 1.1rem;
                margin: 0;
                opacity: 0.9;
            }
            header img {
                max-width: 35%;
                height: auto;
                margin-bottom: 15px;
            }
            main {
                max-width: 900px;
                margin: 30px auto;
                padding: 0 20px;
            }
            .content-container {
                background-color: #fff;
                border-radius: 10px;
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
                padding: 30px;
                margin-bottom: 30px;
            }
            .section-block {
                background-color: #fff;
                padding: 25px;
                border-radius: 8px;
                margin-bottom: 25px;
                border-left: 5px solid #4b6cb7;
                box-shadow: 0 3px 10px rgba(0, 0, 0, 0.05);
                transition: transform 0.2s ease, box-shadow 0.2s ease;
            }
            .section-block:hover {
                transform: translateY(-3px);
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            }
            h1 {
                color: 	#FFFFFF;
                font-size: 2rem;
                margin-top: 0;
                margin-bottom: 30px;
                padding-bottom: 10px;
                border-bottom: 2px solid #4b6cb7;
            }
            h2 {
                color: #3498db;
                font-size: 1.5rem;
                margin-top: 25px;
                margin-bottom: 15px;
                padding-bottom: 8px;
                border-bottom: 1px solid #e0e0e0;
            }
            h3 {
                color: #2ecc71;
                font-size: 1.2rem;
                margin-top: 20px;
                margin-bottom: 10px;
            }
            p {
                margin-bottom: 15px;
                line-height: 1.7;
            }
            ul {
                padding-left: 20px;
            }
            li {
                margin-bottom: 10px;
                position: relative;
                list-style-type: none;
                padding-left: 25px;
            }
            li::before {
                content: "•";
                position: absolute;
                left: 0;
                color: #4b6cb7;
                font-size: 1.2rem;
                font-weight: bold;
            }
            footer {
                text-align: center;
                padding: 25px 20px;
                background-color: #f0f2f5;
                color: #666;
                border-radius: 0 0 10px 10px;
                border-top: 1px solid #e0e0e0;
            }
            footer img {
                max-width: 35%;
                height: auto;
                margin-bottom: 15px;
            }
            footer p {
                margin: 5px 0;
                font-size: 0.95rem;
            }
            .meeting-item {
                margin-bottom: 40px;
                padding: 20px;
                background-color: #f7fbff;
                border-radius: 8px;
                border-left: 5px solid #3498db;
                box-shadow: 0 3px 10px rgba(0, 0, 0, 0.05);
                transition: transform 0.2s ease, box-shadow 0.2s ease;
            }
            .meeting-item:hover {
                transform: translateY(-3px);
                box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            }
            .key-content {
                background-color: #f5fffc;
                padding: 15px;
                border-radius: 5px;
                border-left: 3px solid #1abc9c;
                margin-top: 10px;
                margin-bottom: 15px;
            }
            /* 確保列表項目在 key-content 中正確顯示 */
            .key-content ul {
                padding-left: 15px;
            }
            .key-content li {
                margin-bottom: 8px;
            }
            .key-content li::before {
                color: #1abc9c;
            }
        </style>
    </head>
    <body>
        <header>
            <img src="https://i.imgur.com/0LXUWvj.png" alt="會議摘要圖示">
            <h1>Technical - Advanced</h1>
            <p>類別清單</p>
        </header>
        <main>
            <div class="content-container">
                <h1>Technical - Advanced</h1>
<div class="meeting-item"><h2><a href="./session/NVIDIA 全面赋能端到端自动驾驶_summary.html" style="text-decoration: none; color: inherit;">NVIDIA 全面赋能端到端自动驾驶</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹 NVIDIA 在端到端自動駕駛領域的全面賦能，涵蓋 World Model、神經重建引擎 (NRE) 以及訓練優化等方面。</p>
<h3>重點摘要：</h3>
<ul>
<li>World Model：介紹 World Model 的起源、在自動駕駛上的應用，以及 NVIDIA Cosmos 平台如何賦能自動駕駛。</li>
<li>神經重建引擎 (NRE)：介紹 NRE 的用途、能力，以及如何利用生成式 AI 提供更好的新視角渲染結果。</li>
<li>訓練優化：介紹圖片訓練、影片訓練的 Pipeline，以及如何將 Loss 計算 Batch 起來以提升訓練效率。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>World Model</li>
<li>神經重建引擎 (NRE)</li>
<li>訓練優化</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/合成大数据驱动的具身端到端 VLA 大模型_summary.html" style="text-decoration: none; color: inherit;">合成大数据驱动的具身端到端 VLA 大模型</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹 Galbot 公司在具身通用機器人領域的最新進展，重點探討了如何利用合成數據來驅動端到端的視覺語言動作（VLA）大模型，以賦能通用機器人。</p>
<h3>重點摘要：</h3>
<ul>
<li>通用機器人相較於特定用途機器人的革命性意義，以及其在各個領域的應用前景。</li>
<li>端到端 VLA 模型在視覺感知、任務規劃和動作生成方面的優勢，以及其與其他大型模型的比較。</li>
<li>數據收集是 VLA 模型發展的瓶頸，以及合成數據在解決數據瓶頸方面的潛力。</li>
<li>Galbot 公司在合成數據方面的努力，包括 Gaparnet、Dexgrasp Net 和模擬深度傳感器。</li>
<li>基於合成數據訓練的視覺語言導航（VLN）模型 NAVID 和 NAVID-4D，以及其在真實環境中的應用。</li>
<li>基於合成數據訓練的抓取 VLA 模型，以及其在不同環境和物體上的泛化能力。</li>
<li>合成數據預訓練和少量真實數據後訓練相結合的訓練範式，以及其在降低數據成本和提高模型性能方面的優勢。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>具身智能</li>
<li>通用機器人</li>
<li>視覺語言動作模型</li>
<li>合成數據</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/基于 TensorRT-LLM 的广告场景生成式推理加速方案_summary.html" style="text-decoration: none; color: inherit;">基于 TensorRT-LLM 的广告场景生成式推理加速方案</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次分享介紹了京東廣告研發團隊在生成式推薦領域的工作，重點針對工業化落地場景，尤其是在高吞吐、低延遲要求的生產環境中所做的生產級推理加速方案。</p>
<h3>重點摘要：</h3>
<ul>
<li>介紹了生成式技術在電商廣告場景中的發展契機，以及行業、產品、技術的升級如何解決廣告業務的痛點。</li>
<li>闡述了生成式算法在廣告場景的具體應用落地方式。</li>
<li>分享了為了解決生成式模型推理延遲和吞吐壓力，在工程實踐方面所做的軟硬體協同設計以及優化，以達到算力的極致釋放。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>生成式推薦</li>
<li>TensorRT-LLM</li>
<li>推理加速</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/Leverage Tailored LLMs for Improved Insights in Rail Transportation [S71296]_summary.html" style="text-decoration: none; color: inherit;">Leverage Tailored LLMs for Improved Insights in Rail Transportation [S71296]</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要探討了西門子如何利用客製化的大型語言模型（LLM）來優化流程、節省成本，以及如何將這些模型引入團隊並與之協作。重點在於針對特定領域（工程領域）調整LLM，以解決大型企業中普遍存在的大數據問題，並提高知識獲取的效率。</p>
<h3>重點摘要：</h3>
<ul>
<li>西門子利用客製化LLM解決工程領域的大數據問題，提高知識獲取效率。</li>
<li>介紹了三個實際應用案例：多標籤分類（投標需求分配）、合規性聲明生成、程式碼生成。</li>
<li>強調了領域特定調整的重要性，以及評估在複雜領域中LLM的挑戰。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>LLM客製化</li>
<li>工程領域應用</li>
<li>知識獲取</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/NVIDIA 革新智能座舱技术发展_summary.html" style="text-decoration: none; color: inherit;">NVIDIA 革新智能座舱技术发展</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了 NVIDIA 在智能座艙領域的全鏈路加速生成式 AI 應用開發，以及大模型推理框架 TRT-LM 和端側部署方案。重點涵蓋了 NVIDIA NEMO 平台、Curator 數據處理 Pipeline、FP8 訓練加速、TRT-LM 的特性與功能、多模態大模型部署優化，以及 DriveOS LLM SDK 在車端的應用。</p>
<h3>重點摘要：</h3>
<ul>
<li>NVIDIA NEMO 平台提供端到端的全流程解決方案，涵蓋數據處理、分布式訓練、模型客製化、推理加速、RAG 以及安全護欄等各個階段。</li>
<li>Curator 數據處理 Pipeline 包含文本、圖片和視頻預處理，利用 Rapids 和 Dali 等 GPU 加速庫提高處理速度。</li>
<li>FP8 訓練通過 Transformer Engine 庫實現，相比 BF16 或 FP16 能夠提供更高的算力，縮短訓練時間，並節省顯存。</li>
<li>TRT-LM 是 NVIDIA 針對大語言模型推理所開發的加速框架，具有高性能、易用性等特點，支持多種大模型和量化方法。</li>
<li>多模態大模型（如千問 VL 和 DIT 模型）在 TRT-LM 上可以實現靈活的分布式部署和性能優化。</li>
<li>DriveOS LLM SDK 是 NVIDIA 為車端量身定制的大模型推理框架，具有輕量化、易上手、功能豐富等優勢，並針對車端常用模型進行了專門優化。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>生成式 AI 應用開發</li>
<li>大模型推理加速</li>
<li>端側部署方案</li>
<li>智能座艙技術</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/基于端到端世界模型的生成式智驾体验_summary.html" style="text-decoration: none; color: inherit;">基于端到端世界模型的生成式智驾体验</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了卓域科技在端到端自動駕駛技術方面的最新進展，重點探討了端到端世界模型以及如何基於該模型實現生成式自駕體驗。生成式自駕體驗是卓域首次提出的概念，旨在提供與傳統自駕體驗不同的、更優質的用戶體驗。</p>
<h3>重點摘要：</h3>
<ul>
<li><strong>端到端世界模型：</strong> 卓域正在開發的端到端世界模型，用於實現生成式自駕體驗。</li>
<li><strong>生成式自駕體驗：</strong> 一種新的自駕體驗概念，旨在提供更個性化、更符合用戶需求的駕駛體驗。</li>
<li><strong>個性化駕駛：</strong> 強調在安全、舒適和擬人化的基礎上，滿足用戶的個性化駕駛需求，包括激進、均衡和保守等不同風格。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>端到端自動駕駛</li>
<li>世界模型</li>
<li>生成式自駕體驗</li>
<li>個性化駕駛</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/大语言模型在智能座舱中的应用_summary.html" style="text-decoration: none; color: inherit;">大语言模型在智能座舱中的应用</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要分享了蔚來汽車在大語言模型於智能座艙中的應用，特別是情感智能方面。重點介紹了NOMI GPT家族的技術框架，以及如何利用大模型能力提升人機交互、自主性和情感體驗。</p>
<h3>重點摘要：</h3>
<ul>
<li>蔚來汽車將人工智能視為智能電動汽車的核心能力，並將其貫穿於公司所有環節。</li>
<li>NOMI作為蔚來汽車的情感夥伴，通過NOMI GPT家族的技術框架，實現更自然的人機交互、全能的助手功能和情感夥伴的目標。</li>
<li>NOMI GPT家族利用大模型的理解能力、生成能力和規劃能力，創造了知識類Agent、生成式Agent和任務性Agent，為用戶提供更智能化的體驗。</li>
<li>蔚來汽車在隱私安全方面做了大量工作，包括數據授權、最小化數據使用、數據所有權交還給用戶以及多層的價值觀對齊。</li>
<li>蔚來汽車在AGI方面進行了整體投入，包括基礎設施建設、模型層構建、工具鏈和應用開發。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>智能座艙</li>
<li>大語言模型</li>
<li>情感智能</li>
<li>人機交互</li>
<li>Agent技術</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/激发通用人工智能的创造力，引领智能汽车走向新的未来_summary.html" style="text-decoration: none; color: inherit;">激发通用人工智能的创造力，引领智能汽车走向新的未来</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議由覺影智能的王小剛主講，分享了覺影如何激發通用人工智能的創造力，引領智能汽車走向全新的未來。重點在於倉架融合的AI域，以及覺影在智能座艙和智能駕駛領域的技術與產品解決方案。</p>
<h3>重點摘要：</h3>
<ul>
<li>智能汽車變革的三個方面：原生流逝多模態大模型帶來的人機交互體驗變革、端到端智能駕駛技術升級帶來的自動駕駛安全和效率、倉架融合驅動智能汽車向超級智能體演進。</li>
<li>覺影與英偉達深度合作，構建倉架融合的三大核心要素：支持倉架融合的超大算力引擎、行業領先的原生流逝多模態大模型、端雲一體協同的部署框架。</li>
<li>覺影首創倉架融合AI域框架，包括算力層、系統層和應用層。</li>
<li>覺影專為车载場景客製化打造的原生流逝多模態大模型，具備全場景多模態感知、理解和推理能力。</li>
<li>覺影最早在2022年提出了行業首個端到端架構UNIAD，並獲得CVPR2023年最佳論文的認可。</li>
<li>覺影提出了用量產實車採集的真實數據和用世界模型生成的仿真數據形成雙輪驅動車雲一體數據閉環的新範式。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>倉架融合AI域</li>
<li>原生流逝多模態大模型</li>
<li>端到端智能駕駛</li>
<li>世界模型與數據閉環</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/Enhancing Genomic Variant Detection_summary.html" style="text-decoration: none; color: inherit;">Enhancing Genomic Variant Detection</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>概述了基因組學分析和精準醫療領域中，GPU加速如何變革人工智慧、機器學習和高效能運算，從而實現快速變異檢測、降低計算成本，並解鎖生物標記物發現和藥物開發的洞見。</p>
<h3>重點摘要：</h3>
<ul>
<li>人工智慧和合成生物學的雙重革命正在重塑醫療保健，AI模型以前所未有的準確性生成蛋白質結構、候選藥物，甚至預測疾病風險。</li>
<li>基因組測序產生了海量數據，其規模僅次於天文學和社交媒體，因此需要快速將數據轉化為可操作的見解。</li>
<li>NVIDIA GPU和Parabricks框架加速了生物標記物的發現，將原本需要數月的分析縮短至數週，對於神經退行性疾病的研究至關重要。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>基因組學</li>
<li>GPU加速</li>
<li>精準醫療</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/GLake：大模型训练和推理的显存优化探索_summary.html" style="text-decoration: none; color: inherit;">GLake：大模型训练和推理的显存优化探索</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了螞蟻 AI Infra 推理引擎團隊在過去兩年時間裡，針對大模型訓練和推理所做的一些顯存優化工作，包括訓練上的 GM Lake 和推理上的 VTensor 及 LayerKV。</p>
<h3>重點摘要：</h3>
<ul>
<li><strong>GM Lake:</strong> 解決大規模訓練過程中的顯存碎片問題，通過新的 Stitch API 和多級顯存池實現更高效的顯存管理。</li>
<li><strong>VTensor:</strong> 提供一種 Pageless 的 Tensor 管理框架，提供更大的靈活性，解耦顯存管理和 Attention Kernel 的實現。</li>
<li><strong>LayerKV:</strong> 通過 LayerWise 的 KVCatch 管理來優化首次延遲，並在滿足特定 SLO 情況下提升整體吞吐。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>顯存優化</li>
<li>大模型訓練</li>
<li>大模型推理</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/从智能驾驶到 AGI：下一代自动驾驶技术的演进_summary.html" style="text-decoration: none; color: inherit;">从智能驾驶到 AGI：下一代自动驾驶技术的演进</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要分享了從不依賴高精度地圖的自動駕駛研發，到端到端的部署上車，再到最近的 VLA 模型研發的技術演進。重點介紹了 VLA 模型架構及其三大優勢，以及在實際部署中遇到的挑戰和解決方案。</p>
<h3>重點摘要：</h3>
<ul>
<li>公司在過去一年與車企合作推出多款自動駕駛車型，並在城市和高速 NOA 方面取得進展。</li>
<li>DLD 模型快速部署到大量車輛，積累了豐富的數據，但也遇到了一些現階段 DLD1.0 無法解決的問題。</li>
<li>VLA 模型旨在進一步提高解決城市高階自駕的能力，處理複雜罕見的常規場景。</li>
<li>VLA 模型架構包含視覺輸入、文本輸入、視覺編碼器、文本編碼器以及駕駛動作行為和邏輯推理輸出。</li>
<li>VLA 模型的三大優勢：組件標記化與大語言模型兼容、具備思維鏈能力、駕駛行為更偏向人類偏好。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>自動駕駛</li>
<li>AGI</li>
<li>VLA 模型</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/释放 GPU 缓存的强大威能：闪电加速短视频推荐系统！_summary.html" style="text-decoration: none; color: inherit;">释放 GPU 缓存的强大威能：闪电加速短视频推荐系统！</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本會議主要討論了如何通過 GPU Embedding Cache 技術來加速短視頻推薦系統，解決 CPU 算力瓶頸問題，充分利用 GPU 的算力。</p>
<h3>重點摘要：</h3>
<ul>
<li>短視頻推薦系統面臨海量數據和用戶增長帶來的計算效率和實時性挑戰。</li>
<li>GPU 加速技術在推薦系統的訓練和推理中扮演關鍵角色，尤其是在快手的推薦系統中，召回和排序階段已大量應用 GPU。</li>
<li>新一代 GPU 架構（如 IDA 架構）的引入，顯著提升了計算密度，但也帶來了 GPU 算力與 CPU 算力不平衡的問題。</li>
<li>通過將 Embedding 查詢階段從 CPU 卸載到 GPU 上，可以有效解決 CPU 瓶頸問題。</li>
<li>GPUMbedding Cache 的設計方案，旨在將業務無關的數據統一結構化，簡化 GPU 的處理流程。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>GPU 加速</li>
<li>推薦系統</li>
<li>Embedding 技術</li>
<li>緩存優化</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/VLA：迈向自动驾驶物理智能体的关键一步_summary.html" style="text-decoration: none; color: inherit;">VLA：迈向自动驾驶物理智能体的关键一步</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹了理想汽車在自動駕駛領域的最新進展，特別是其提出的 VLA（視覺語言行為大模型）模型。VLA 模型旨在將空間智能、語言智能和行為智能統一在一個模型中，賦予自動駕駛車輛感知、思考和適應環境的能力，從而實現更高級別的自動駕駛體驗。</p>
<h3>重點摘要：</h3>
<ul>
<li>中國自動駕駛面臨的獨特挑戰，包括複雜多樣的公交車道、動態變化的車道和區域、以及對 ETC 標識和支付方式的識別。</li>
<li>理想汽車提出的端到端加 VRM（視覺推理模型）雙系統架構，以及其在量產實踐中的應用。</li>
<li>VLA 模型的設計理念和關鍵技術，包括 3D 空間理解、語言模型訓練、Diffusion 模型應用、以及人類價值觀對齊。</li>
<li>VLA 模型在實際應用中的潛力，例如自主漫遊、根據照片尋找位置、以及與用戶進行自然對話。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>自動駕駛</li>
<li>深度學習</li>
<li>物理智能</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/下一代生成式推荐模型训推引擎的建设和落地实践_summary.html" style="text-decoration: none; color: inherit;">下一代生成式推荐模型训推引擎的建设和落地实践</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議介紹了美團下一代生成式推薦模型，迅推引擎（MTGR）的建設和落地實踐。重點在於解決生成式推薦模型訓練和推理所面臨的挑戰，包括訓練成本高、推理延遲嚴格等問題。</p>
<h3>重點摘要：</h3>
<ul>
<li><strong>背景介紹：</strong> 說明了為何要採用生成式推薦模型，以及其相對於傳統 DLIR 模型的優勢。</li>
<li><strong>模型介紹：</strong> 簡述了生成式推薦模型的設計思路，包括資料組織、任務定義和模型結構。</li>
<li><strong>MTGR 介紹：</strong> 詳細介紹了美團為生成式推薦模型所建設的訓練推薦引擎 MTGR，包括其架構、核心組件和優化策略。</li>
<li><strong>總結與展望：</strong> 總結了 MTGR 的優勢，並展望了未來的工作方向。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>生成式推薦模型</li>
<li>模型訓練與推理引擎</li>
<li>性能優化</li>
</ul>
</div></div>
<div class="meeting-item"><h2><a href="./session/重塑短视频视觉体验，基于 TensorRT-LLM 加速的智能视频质量评价与处理大模型_summary.html" style="text-decoration: none; color: inherit;">重塑短视频视觉体验，基于 TensorRT-LLM 加速的智能视频质量评价与处理大模型</a></h2>
<h3>Key Takeaways</h3><div class="key-content">
<p>本次會議主要介紹快手在提升短視頻畫質領域的工作，重點在於使用基於 TensorRT-LLM 加速的智能視頻質量評價與處理大模型，以重塑短視頻的視覺體驗。</p>
<h3>重點摘要：</h3>
<ul>
<li>快手短視頻的現狀與生產消費鏈路。</li>
<li>快手內部研發的視頻質量評價算法 KVQ。</li>
<li>快手研發的視頻處理大模型實現極致的畫質提升。</li>
<li>基於英偉達成熟的 TensorRT-LLM 工具進行部署優化，提升服務的推理效率。</li>
</ul>
<h3>Topic:</h3>
<ul>
<li>視頻質量評價</li>
<li>視頻處理大模型</li>
<li>TensorRT-LLM 加速</li>
<li>短視頻畫質提升</li>
</ul>
</div></div>
            </div>
        </main>
        <footer>
            <img src="https://i.imgur.com/0LXUWvj.png" alt="會議摘要圖示">
            <p>此摘要由 AI 輔助生成</p>
            <p>如有任何問題或需要更多詳細資訊，請聯繫 ITR 小組</p>
        </footer>
    </body>
    </html>
    