
        <!DOCTYPE html>
        <html lang="zh-TW">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Vla：迈向自动驾驶物理智能体的关键一步</title>
            <style>
                body {
                    font-family: 'Roboto', 'Microsoft JhengHei', sans-serif;
                    background-color: #f8f9fa;
                    color: #333;
                    margin: 0;
                    padding: 0;
                    line-height: 1.6;
                }
                header {
                    text-align: center;
                    padding: 30px 20px;
                    background: linear-gradient(135deg, #4b6cb7, #182848);
                    color: #fff;
                    position: relative;
                    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
                    border-radius: 10px 10px 0 0;
                }
                .video-link {
                    display: inline-block;
                    margin: 10px 0;
                    padding: 8px 15px;
                    background-color: rgba(255, 255, 255, 0.2);
                    color: #fff;
                    text-decoration: none;
                    border-radius: 5px;
                    font-weight: 500;
                    transition: all 0.3s ease;
                    border: 1px solid rgba(255, 255, 255, 0.3);
                }
                .video-link:hover {
                    background-color: rgba(255, 255, 255, 0.3);
                    transform: translateY(-2px);
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                .video-link i {
                    margin-right: 5px;
                }
                header h1 {
                    font-size: 2.2rem;
                    margin: 0 0 10px 0;
                    letter-spacing: 0.5px;
                }
                header p {
                    font-size: 1.1rem;
                    margin: 0;
                    opacity: 0.9;
                }
                header img {
                    max-width: 35%;
                    height: auto;
                    margin-bottom: 15px;
                }
                main {
                    max-width: 900px;
                    margin: 30px auto;
                    padding: 0 20px;
                }
                .content-container {
                    background-color: #fff;
                    border-radius: 10px;
                    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
                    padding: 30px;
                    margin-bottom: 30px;
                }
                .section-block {
                    background-color: #fff;
                    padding: 25px;
                    border-radius: 8px;
                    margin-bottom: 25px;
                    border-left: 5px solid #4b6cb7;
                    box-shadow: 0 3px 10px rgba(0, 0, 0, 0.05);
                    transition: transform 0.2s ease, box-shadow 0.2s ease;
                }
                .section-block:hover {
                    transform: translateY(-3px);
                    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
                }
                /* 為不同段落設置不同的邊框顏色和背景 */
                .section-block.conclusion {
                    border-left-color: #e74c3c;
                    background-color: #fff9f9;
                }
                .section-block.meeting-topic {
                    border-left-color: #3498db;
                    background-color: #f7fbff;
                }
                .section-block.tech-points {
                    border-left-color: #2ecc71;
                    background-color: #f7fff9;
                }
                .section-block.decisions {
                    border-left-color: #f39c12;
                    background-color: #fffaf5;
                }
                .section-block.timeline {
                    border-left-color: #9b59b6;
                    background-color: #faf5ff;
                }
                .section-block.challenges {
                    border-left-color: #e67e22;
                    background-color: #fff8f2;
                }
                .section-block.action-plan {
                    border-left-color: #1abc9c;
                    background-color: #f5fffc;
                }
                .section-title {
                    font-size: 1.5rem;
                    margin-top: 0;
                    margin-bottom: 20px;
                    padding-bottom: 10px;
                    border-bottom: 2px solid #4b6cb7;
                    display: inline-block;
                }
                /* 為不同段落標題設置對應的顏色 */
                .section-block.conclusion .section-title {
                    color: #e74c3c;
                    border-bottom-color: #e74c3c;
                }
                .section-block.meeting-topic .section-title {
                    color: #3498db;
                    border-bottom-color: #3498db;
                }
                .section-block.tech-points .section-title {
                    color: #2ecc71;
                    border-bottom-color: #2ecc71;
                }
                .section-block.decisions .section-title {
                    color: #f39c12;
                    border-bottom-color: #f39c12;
                }
                .section-block.timeline .section-title {
                    color: #9b59b6;
                    border-bottom-color: #9b59b6;
                }
                .section-block.challenges .section-title {
                    color: #e67e22;
                    border-bottom-color: #e67e22;
                }
                .section-block.action-plan .section-title {
                    color: #1abc9c;
                    border-bottom-color: #1abc9c;
                }
                .content-container ul {
                    padding-left: 20px;
                }
                .content-container li {
                    margin-bottom: 10px;
                    position: relative;
                    list-style-type: none;
                    padding-left: 25px;
                }
                .content-container li::before {
                    content: "•";
                    position: absolute;
                    left: 0;
                    color: #4b6cb7;
                    font-size: 1.2rem;
                    font-weight: bold;
                }
                .section-block.conclusion li::before { color: #e74c3c; }
                .section-block.meeting-topic li::before { color: #3498db; }
                .section-block.tech-points li::before { color: #2ecc71; }
                .section-block.decisions li::before { color: #f39c12; }
                .section-block.timeline li::before { color: #9b59b6; }
                .section-block.challenges li::before { color: #e67e22; }
                .section-block.action-plan li::before { color: #1abc9c; }
                
                .content-container p {
                    margin-bottom: 15px;
                    line-height: 1.7;
                }
                .content-container strong {
                    color: #2c3e50;
                    font-weight: bold;
                }
                footer {
                    text-align: center;
                    padding: 25px 20px;
                    background-color: #f0f2f5;
                    color: #666;
                    border-radius: 0 0 10px 10px;
                    border-top: 1px solid #e0e0e0;
                }
                footer img {
                    max-width: 35%;
                    height: auto;
                    margin-bottom: 15px;
                }
                footer p {
                    margin: 5px 0;
                    font-size: 0.95rem;
                }
                footer a {
                    color: #4b6cb7;
                    text-decoration: none;
                    font-weight: bold;
                }
                footer a:hover {
                    text-decoration: underline;
                }
            </style>
        </head>
        <body>
            <header>
                <img src="https://i.imgur.com/0LXUWvj.png" alt="會議摘要圖示">
                <h1>Vla：迈向自动驾驶物理智能体的关键一步</h1>
                <a href="https://www.nvidia.com/gtc/session-catalog/?search=VLA%EF%BC%9A%E8%BF%88%E5%90%91%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E7%89%A9%E7%90%86%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%85%B3%E9%94%AE%E4%B8%80%E6%AD%A5&tab.catalogallsessionstab=16566177511100015Kus#/session/1727430977700001r2OJ" class="video-link" target="_blank"><i>▶</i> 會議影片超連結</a>
            </header>
            <main>
                <div class="content-container">
                    <div class="section-block conclusion"><h2 class="section-title">Key Takeaways</h2><p>本次會議主要介紹了理想汽車在自動駕駛領域的最新進展，特別是他們提出的視覺語言行為大模型（VLA），旨在將空間智能、語言智能和行為智能統一在一個模型中，打造更像人類的自動駕駛體驗。</p><h3>重點摘要：</h3><ul><li>理想汽車在中國自動駕駛領域面臨的挑戰，包括複雜的道路狀況、多樣的交通規則和動態變化的城市環境。</li><li>理想汽車提出的端到端加VRM雙系統架構，以及VLA模型的設計理念和技術細節。</li><li>VLA模型在3D空間理解、語言推理和行為生成方面的突破，以及在車端芯片上的實時推理能力。</li><li>VLA模型在實際應用中的場景演示，展示了其在陌生環境漫遊、精確定位和人機交互方面的優勢。</li></ul><h3>Topic: 自動駕駛、AI模型、物理智能</h3></div><div class="section-block meeting-topic"><h2 class="section-title">會議主題</h2><p>會議主要探討了如何通過構建視覺語言行為大模型（VLA），賦予自動駕駛系統更強大的空間理解、語言推理和行為生成能力，使其能夠更好地適應複雜的城市環境，並提供更人性化的駕駛體驗。</p></div><div class="section-block tech-points"><h2 class="section-title">主要技術點</h2><ul><li><strong>3D空間理解：</strong> 通過自監督學習獲得高質量的3D表徵，提升模型對物理世界幾何和語義信息的理解能力。</li><li><strong>語言模型設計：</strong> 從零開始設計和訓練適合VLA的基座模型，融入大量的3D數據和自動駕駛相關的圖文數據，並通過MOE架構和稀疏注意力機制提升模型容量和推理效率。</li><li><strong>快慢思考機制：</strong> 訓練模型學習人類的思考過程，並自主切換快思考和慢思考模式，以應對不同的駕駛場景。</li><li><strong>Diffusion模型：</strong> 利用Diffusion模型將Action Token解碼成最終的駕駛軌跡，並通過常微分方程ODE採樣器加速Diffusion過程。</li><li><strong>人類價值對齊：</strong> 通過人類偏好數據集和ILHF微調模型的採樣過程，使模型能夠從這些偏好數據中學習和對齊人類行為。</li><li><strong>強化學習：</strong> 結合場景重建與生成，構建良好的交互環境，並通過端到端可訓的VLA模型實現大規模的自動駕駛強化學習。</li></ul></div><div class="section-block decisions"><h2 class="section-title">決策與共識</h2><ul><li>將端到端模型和VLM模型合二為一，構建視覺語言行為大模型（VLA）。</li><li>採用自監督學習、MOE架構、稀疏注意力機制、Diffusion模型和強化學習等技術，提升VLA模型的性能和泛化能力。</li><li>通過人類偏好數據集和ILHF微調，使VLA模型能夠對齊人類價值觀。</li><li>將VLA模型應用於自動駕駛系統，打造更像人類的駕駛體驗。</li></ul></div><div class="section-block timeline"><h2 class="section-title">時間規劃與里程碑</h2><ul><li>已推出全球首個車位到車位的智能駕駛產品，並推送給超過40萬台車。</li><li>持續迭代和提升模型性能，實現更長的平均接管里程MPI。</li><li>計劃將VLA模型應用於更多行業，為更多領域賦能。</li><li>持續進行研究開發，以進一步提高VLA的效能和效率。</li></ul></div><div class="section-block challenges"><h2 class="section-title">未解決的技術挑戰</h2><ul><li>如何在有限的車端芯片資源下實現VLA模型的高效率推理。</li><li>如何處理人類駕駛行為的多模態性，使模型能夠更好地適應不同的駕駛員和駕駛場景。</li><li>如何確保VLA模型在各種複雜工況下都能夠符合人類價值觀。</li></ul></div><div class="section-block action-plan"><h2 class="section-title">後續行動計劃</h2><ul><li>繼續優化VLA模型的架構和訓練方法，提升其性能和泛化能力。</li><li>探索更多將VLA模型應用於自動駕駛系統的場景，並不斷改進用戶體驗。</li><li>與英偉達團隊密切合作，進行大量的工程優化，提升場景生成和重建的效率。</li><li>將相關研究成果發表在頂級學術會議上，與業界分享經驗和技術。</li></ul></div>
                </div>
            </main>
            <footer>
                <img src="https://i.imgur.com/0LXUWvj.png" alt="會議摘要圖示">
                <p>此摘要由 AI 輔助生成</p>
                <p>如有任何問題或需要更多詳細資訊，請聯繫 ITR 小組</p>
            </footer>
        </body>
        </html>
        