大家好,我是理想自动驾驶的甲头感谢英伟达的邀请接下来的30分钟我将通过以下4个部分展开我的分享首先,我会花几分钟和大家一起看一下自动驾驶在中国面临的挑战其次,会总结一下2024年我们如何使用端到端加VRM双系统去尝试解决这些挑战的以及最终呈现给用户什么样的产品体验第三,我会详细介绍我们的最新思考以及在VLA技术上的突破最后,会通过几个时射demo来展示一下VLA技术可能给用户带来哪些革命性的产品体验在开始深入探讨之前我想先和大家一起来看一下自动驾驶在中国面临的独特挑战作为全球自动驾驶的典范在Tesla 2024的财报会议上Elon Musk也提到FSD的中国的落地也遇到了很大的挑战其中之一就是复杂而多样的公交车道确实,除了到处乱窜的电动车和高强度的人车博意外中国的道路结构本身也足够复杂为了提升出行效果公交车道被广泛使用然而各地的标示方法和使用规则非常多样采用了比如地面的文字标识空中指示牌或者路边标牌同时会以不同的文字形式说明这些车道的时段限制这些多变的规则和文字表达为自动驾驶带来的巨大的挑战有朋友可能会说能否通过地图或者鲜艳信息来解决呢其实挑战也很大中国城市快速发展常常出现新增的公交车道或者因为施工导致的部分标识的不清或者重刷任何鲜艳信息都会面临着先动不足的问题如果想从根本上去解决公交车道的挑战车端需要具备实时识别和理解这些文字的能力公交车道还只是诸多挑战之一随着数字城市的不断深入很多车道和区域被赋予了动态变化的能力越来越多的城市出现了动态可调的可编车道和潮汐车道同时为了充分利用路口的空间也增加了如带转区带行区这些车道和带行区域的进入时机也是有多样化的信号灯或者LED文字牌来控制的同时咱们城市的建设日新月异每天都会面临着设备的新增故障和维护增加的系统需要时刻保持对这些变化的理解如果想打造一套无风的点到点的智能驾驶体验智能驾驶车辆还需要能够顺利通过ETC和收费站而这也要求系统能够识别和理解全国各地的各种各样的ETC标识和支付方式标识综上所说在中国智能驾驶系统不仅要应对高强度的人车文艺还需要能够读懂文字具备常识和很强的逻辑推理能力Tesla向中国用户推送了FSD的功能我们也看到FSD在公交车道带行区等特殊场景上的表现确实是有所不足的那么理想汽车是如何应对这些挑战的呢在去年的GDC2024大会上我有幸介绍了我们的自动驾驶框架这个框架是基于诺贝尔角获得者丹尼尔卡尼曼其出的快慢思考双系统理论简单的说人的思维可以分为两个系统快思考系统一和慢思考系统二快系统依赖于直觉判断大多数情况下人类日常角色都使用该系统而当我们面临复杂问题时才会调用慢系统去想一想思考一下再行动我们也在车端实现了这样的双系统首先车端通过端道端道的模型实现了快想它是一个单一的模型实现了传感器的输入直接到轨迹的输出类比于人类的直觉反应该系统通过模仿人类的驾驶行为来应对各种各样的场景完全基于数据驱动中间无需人为设定规则而且不使用任何高精地图或者鲜验信息它的训练和执行效率都很高另外一方面慢系统则依托于一个22亿参数规模的世界语言大模型VLM在需要文字理解能力常识和逻辑推理的场景中VLM会通过思维链COT进行复杂的逻辑分析给出驾驶决策并指挥快系统去执行端端端模型和VLM模型分别跑在一颗ORX芯片上这套双系统的一些技术细节我们也发表在了CORAL2024的DRAWLM这篇论文中双系统采用了数据驱动的范式携带效率极高在过去半年的量产实践中我们实现了每周三到四次的模型发板然而如果快速地进行测试和验证也逐渐成为了我们的平静考虑到中国拥有数百万公里的道路通过实车进行测试既不现实效率和成本也难以接受因此我们在云端构定了一个实践模型它提供了一个3D的交互环境使得双系统可以在此环境中进行高效的避环仿真测试以上三个模型就构成了迪想自动驾驶的整个体系简洁而高效在这一过程中我们非常惊喜地发现双系统同样追寻Skinning Log随着训练数据的增加模型在实际驾驶场景中的表现逐步提升我们在最早期的早鸟测试中使用了100万KLPS训练出来的模型其平均接管里程MPI仅有10几公里但是经过半年的持续迭代和数据量的持续提升到今年年初我们1000万KLPS训出来的模型已经实现了超过100公里的MPI这些重要的发现也发表在下面的这两篇论文中基于双系统架构我们成功地在英伟达RX平台上推出了全球首个车位到车位的智能驾驶产品目前已经推送了超过40万台车所谓车位到车位指的是从停车位出发穿越车库经过园区进入公共道路直到通过ETC进入高速公路的整个过程中没有任何的系统降级和退出请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目同时 借助VRM的通识能力我们在这一产品中实现了多个行业首创的功能比如实现了不依赖于地图或者现役信息的全国ETC自由通行全国潮汐车道和可变超道的自由通行在带转区 带行区的自主进出以及在坑洼路面 积雪路面 积水路面的自动减速这些突破性的功能目前在其他车厂都尚未实现极大的提升了我们用户的用户体验赢得了广泛的好评 也推动了我们的销量在持续增长同时 我们知道用户可能会担心端道单模型是个黑盒子比如说有的用户会想知道模型在想什么下一步的动作是什么那么为了解决这一问题我们创新性的引入了AI推理交互功能用户可以直观地看到模型在关注哪些点即将执行的动作 以及整体的思考过程这个透明化的设计显著提升了用户的信心让用户用得更加安心放心也得到了大量的积极反馈在2024年10月理想机车量产双系统方案后单独单加VRM的模式逐渐成为了行业的标杆许多同行开始采用这一路线不仅在自动驾驶领域在通用机器人领域也得到了应用例如上个月Figure.AI发布的Helix机器人系统也使用了类似的架构在过去几年的时间中增驾驶团队形成了一种高效的工作模式在产品交付的同时我们不断反思和总结现有架构的不足并流出一部分资源由于探索下一代的技术在端道端加VRM的量产过程中我们也发现了一些需要改进的地方首先虽然我们可以通过一步联合训练让端道端和VRM协同工作但由于它们是两个独立的模型而且运行于不同的频率整体的联合训练和优化是非常困难的其次我们的VRM模型是基于开源的LM大语言模型它使用了海量的互联网二级图文数据作为训练但是在三级空间理解和驾驶知识方面是有所不足的虽然可以通过会训练进行一定程度的弥补但是它的上限还不是很高第三自动驾驶芯片如RX和SOU它的内存带宽和算力是不及服务器GPU的如果进一步提升模型的参数量和能力同时还能实现高效率推理这是个巨大的挑战第四目前驾驶行为的学习更多的依赖于Transformer进行回归建国但这种方法难以处理人类驾驶行为的多模态性这里的多模态性是指在相同的场景下不同人的选择是不同的即使是同一个驾驶员不同心情的时候驾驶行为也是不同的那么有什么方法能够进一步提升模型的上限让用户体验到更加丝化的产品呢同时我们认为不仅仅要提升模型的上限同时也要提升模型的下限如何对其到人类的价值观也是急需要解决的问题幸运的是在我们交付端道单加VM的期间空间智能LMAIGC和巨神智能有了快速发展也给了我们很多启示我们再思考能不能将端道单模型和VLM模型合二为一像GP-1和DeepSecret R1一样模型自己学会快慢思考同时赋予模型强大的3D空间理解能力和行为生成能力将双系统天花板进一步打开基于以上的思考我们提出了理想的VLA模型VLA是视觉语言行为大模型它将空间智能语言智能和行为智能统一在一个模型里VLA是Physical UI的最新范式它赋予自动驾驶这样的物理系统感知思考和适用环境的能力Mind VLA不是简单地将Dodonan模型和VLM模型结合在一起所有等模块都是全新设计的3D空间编码器通过语言模型和逻辑推理结合在一起后给出合理的驾驶决策并输出一组Edge Token最终通过Diffusion进一步优化出最佳的驾驶轨迹这里所谓的Edge Token是对周围环境和自车驾驶行为的编码那整个模型推理过程都要发生在车端而且要做到实时运行接下来我会从六个关键技术点去详细介绍Mind VLA的设计和训练过程包括Mind VLA强大的3D空间理解能力是如何获得的我们是如何从零设计和训练语言模型使其具备驾驶知识和推理能力的Diffusion是如何与语言模型结合在一起的以及我们是如何解决VLA在车端芯片的实时推理的好那咱们一起看一下这六个关键技术首先Physical AI和物理世界的交互需要强大的空间智能也就是对3D物理世界的感知理解和推理能力回顾自动驾驶技术的发展历程对空间的理解我们经历了从DAM2D特征到DAM3D特征再到多相机的鸟看图BEV特征和占用网格特征等不同的阶段这个演变过程也体现出咱们工程师对物理世界几何和语义信息精确提取的不懈追求然而这些方法大多依赖于监督学习需要精确的标注数据效率和数据利用率都很低下我们前面提到在双系统的实践中我们欣喜地发现了数据量的利率随着数据量的提升系统的表现会同步提升如果抽空也利用我们海量的数据在研发实践模型时我们发现3D高四是一个极其优良的中间表征它不仅具备出色的多力度多尺度3D几何表达能力同时也有方法承载丰富的语义最为关键的是可以通过图片RGB进行自监督训练这使得我们有机会去充分利用海量的真实数据获得一个优秀的3D表征我们的研究成果显示采用自监督训练得到的高四表征能够极大的促进下入任务的性能提升部分实验结果和能力我们展示到我们的论文高尘域地理大家如果有兴趣可以进一步查阅解决了3D表征接下来如何将它和语言智能结合在一起呢LM已经被证明是一个强大的通用模型它可以兼容视觉语言等多种模态但是如果想要LM同时具备3D的空间理解能力3D的空间推理能力及强大的语言能力需要在模型的预训练阶段就要加入大量的相关数据同时车载芯片如Orient和Soyu它的算力和内存带宽度有限如若设计模型架构让模型参数进一步提升还能在有限资源下实现实时推理那这里解释一下为什么我们还要进一步增加模型参数量呢因为数据参数规模和能力强弱可以画等号越大越好为了解决这些问题我们需要从零开始设计和训练一个适合VLA的几座模型因为任何开源的RM模型都不具备这样的能力在这个过程中吸收化是模型设计的关键它可以实现模型容量扩容的同时不会大幅度增加推理负担我们通过两个维度来实现吸收化首先我们采用了MO1的架构通过多个专家实现模型扩容还可以保证机构采量不会大幅度增加第二我们引入了Spark Attention来进一步提升吸收化率提升端侧的推理效果在这个新的极左模型训练过程中我们花了很多时间去找到最佳的数据配比融入了大量的3D数据和自动驾驶相关的投文数据并减少了文史类数据的比例最后为了进一步激发模型的3D空间理解和推理能力我们加入了未来人的预测生成和稠密深度的预测等训练任务RM在获得3D空间证能的同时在逻辑推理方面也需要进一步的提升我们训练模型去学习人类的思考过程并自主切换快思考和慢思考在慢思考模式下模型会经过四位链COT再输出XToken由于自动驾驶不需要冗长的COT同时也因为实时性的要求所以我们使用了固定且简短的COT模板在快思考模式下模型则不需要经过COT就可以直接输出XToken这也是我们将快慢思考有机结合在同一个模型中的体现很多人会问LM是Token by Token的输出推理速度能够支撑自动驾驶吗确实即便有了上述的结构设计和优化想要实现VLA超过10个字的推理速度还是具有挑战的我们做了大量的工程工作去压榨HORNX和SOLU的性能针对COT过程我们采用了小词表和投机推理大幅提升COT的效果针对XToken的推理我们采用了创新性的并行减码方法也就是在同一个Transformer模型中兼入了两种推理模式语言逻辑的推理通过英国注意力机制逐次输出而Action Token则采用双向注意力机制一次性全部输出经过上面一系列的设计和优化我们终于实现了模型的参数规模与实时推理性能之间的平衡最后在这个架构图中还有一个亮点VLA的强大之处在于用户可以直接与模型对话给它下达指令模型会自动拆解并执行任务我稍后会介绍这一特性是如何改变自动驾驶产品形态的在成功构建了一个强大的机座模型之后我们利用Diffusion将Action Token减码成最终的驾驶轨迹在日常的驾驶过程中车辆于周围的交通参与者如车辆行人骑行人存在着密切的交互关系并会最终影响自车的行为因此在Diffusion模型中我们不仅生成自车的轨迹还预测其他车辆和行人的轨迹大大提升了VIA模型在复杂交通环境中的博弈能力此外Diffusion还有个巨大的优势就是可以根据外部的条件输入改变生成结果这在图像生成领域被称为多风格生成有了这样的特性类似理想同学开快点我赶时间这样的功能就很容易实现了我们使用了多层的DIT去实现了Diffusion然而Diffusion模型有一个显著的挑战就是它的生成效率也低需要很多部才能成功生成稳定的轨迹为了解决这一问题我们采用了基于常微分方程的ODE采用器大幅加速了Diffusion过程使其在两到三部内就可以生成稳定的轨迹至此我完整介绍了VLV的架构和基础的训练过程VLV模型在绝大多数场景下能够见证人类的价值水平然而在某些常委工况下VLV仍然存在着不符合人类价值观的问题为解决这个问题我们增加了互训练的阶段希望能够对其人类驾驶员在这些公团下的行为在过去几年里我们不仅积累了大量的人类司机的驾驶数据也有很多NLV的接管数据这些接管都是不符合人类预期的表现我们筛选了大量的接管数据建立了一个人类偏好的数据集应用ILHF去微调模型的采样过程使模型能够从这些偏好数据中学习和对其人类行为这一创新性的步骤让我们在模型性能上取得了进一步的提升随着偏好数据的逐步丰富模型的表现也逐步接近了专业司机的水平安全下线也得到了绝大的提升有关ILHF与Diffusion结合的具体细节我们也在近期的论文中进行了详细的阐述欢迎大家查阅也能希望给大家一些启发要实现真正的自动驾驶仅仅达到人类司机的水平还是不够的那么如何让系统有机会超越人类驾驶水平呢或许大家第一反应是强好学习强好学习在自动驾驶领域已经不算新鲜事但是过去的尝试都没有取得很好的效果我认为这里面有两个主要的限制因素第一早期的车栓架构未能实现端端端的可训强好学习作为一种稀疏的热监督过程若无法实现高效的无损的信息传递强好学习的效果就会大打折扣第二Fysical AI需要与真实世界进行交互以获取奖励信号因此自动驾驶作为Fysical AI最直接的应用它的强化学习也高度依赖于良好的交互环境然而过去的尝试都是基于3D的游戏引擎场景真实度不足限制了强化学习在真实驾驶场景中的应用同时因为场景建设效率低下场景规模小模型很容易学偏去hack the world model导致强化出来的模型完全不可用那我们已经获得了一个端道端可训的VLA模型它解决了第一个限制至于良好的交互环境我们的做法是结合场景重建与生成纯生成模型的优势在于其良好的犯化能力能够生成多变的场景但是可能会出现不符合物理规律的幻觉难以满足自动驾驶的严格要求相反纯重建模型则依托于真实数据重建出3D场景但是在大视角变换下可能会出现空洞和变形也没办法满足自动驾驶的要求我们选择以真实数据的3D重建为基础同时特意在不同的视角下添加造音来训练生成模型恢复这些模糊的视角这样一来生成模型就具备了多视角的生成能力在于3D重建联合优化后可以获得一个各个视角下都接近真实世界的3D环境这在很大程度上解决了上面提到第二个限制关于生成和重建是如何结合的很多细节发表在我们的论文里其中4篇还中了今年的CVPR2.25突破了这两个限制后我们终于有机会去尝试大规模的自动驾驶强化学习但规模化需要解决效率的问题无论重建和生成效率都不高过去一年里我们与英文达团队密切合作进行了大量的工程优化显著提升了场景生成和重建的效率其中一项工作是将3DGS的训练速度提高了7倍以上这项工作也已经投稿到CGRAPH2025上好以上就是MandaVLA最关键的6个技术点总结下来MandaVLA成功整合了空间智能语言智能和行为智能可以说是一个巨大的突破并且通过创新性的预训练和后训练方法我们发现VLA实现了卓越的泛化性能和永现特性它不仅在驾驶场景下表现良好在室内环境中也展示出了一定的适应性和延展性这是Facebook AI能够大门落地的关键一旦跑通这套判施理想将有望为更多行业赋能我把之前提到的相关论文也总结在这里大家有些兴趣可以看一看那么在技术分享之后让我们转向用户更关心的产品形态和体验VLAV模型究竟能够为用户带来什么不同的产品体验呢一句话总结有慢能为负能的车不在只是一个驾驶工具而是一个能够与用户沟通理解用户意图的司机最后我们也展示一下在研发过程中的三个实车弹幕也对应了我们日常生活中用车的三个场景首先来看第一个当你来到一个陌生园区想去某个特定商店比如星巴克但是具体的位置你不知道在这种情况下你只需要告诉车辆带我去星巴克车辆将在没有导航信息的情况下通过自主漫游找到目的地在执行任务的过程中你还可以随时进行人工干预比如说开太快了开慢点吧或者说我觉得你应该走左边感觉右边会绕远通过这样的自然对话来改变它的路线和行为Mand VLA能够理解并执行这些指令而且在认出目标商店后将你放在附近我要去星巴克开慢一点吧开快一点吧快前方路口左转不要右转明白还有一个大家经常遇到的情景在一个陌生的城市打车时你不知道如何描述你的位置最终你找不到司机司机也找不到你当你拥有Mand VLA赋能的车辆就没有转到烦闹了你不需要描述你的位置只需要拍一张附近环镇的照片发给汽车让车子自己来找你它可以自己从车库开出来开出园区经过一些城市道路找到图片中的位置把你介绍请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目这些场景展示了自动驾驶车辆如何从单纯的运输工具转变为贴心的专职司机它能听得懂 看得见 找得到想象一下将来每个人拥有一个这样的司机你可以让他接孩子 带老人去菜市上买菜那将是一个多么令人愉悦的体验我们希望Mand VLA能为自动驾驶车辆赋予类类人类的认知和适应能力将它转变为能够思考的智能体就像iPhone重新定义了手机Mand VLA也将重新定义自动驾驶好 这就是我今天的分享感谢大家的聆听感谢大家的聆听