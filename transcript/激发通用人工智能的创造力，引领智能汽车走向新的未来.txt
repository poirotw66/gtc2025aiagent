各位开发者朋友大家好,我是觉影智能的王小刚。感谢应伟达GTC活动的邀请,也非常感谢各位对觉影的关注与支持。觉影智能是最专注汽车行业领先的AI公司,旨在推动智能汽车加速驶入通用人工智能时代。今天我想给大家分享觉影如何激发通用人工智能的创造力,引领智能汽车走向全新的未来。我常常在想,AGI时代下,未来汽车的出行体验是怎样的。它应该是可以实现更为自然的、有温度的人车交互体验,让智能汽车从出行代步的工具进化为你情感的陪伴。同时呢,它还要具备实现安全自动驾驶的能力,解放你的身心束缚,让你的时间和精力都可以投入到与世界的连接中,进行享受大千世界的无限可能。爸爸喂,小天主啊田田这么开心,是参加小天鹅芭蕾舞大赛拿奖了吗?你怎么知道的呀?你生前的奖牌在山闪发光呢田田这么棒,想要什么奖励呀?田田,你不是一直恨想养只狗狗吗?妈妈可以吗?田田,你不是一直恨想养只狗狗吗?妈妈可以啊前方路口绿灯,保持直行。前方障碍,支持通过,减速直行。智能汽车带来的变革主要体现在三个方面。第一,是通过原生流逝多模态大模型带来的人机交互体验的变革。第二,是通过端到端智能驾驶技术的升级,带来极致的自动驾驶安全和效率。第三,是仓架融合,驱动智能汽车向超级智能体演进,极大的拓展了人和物理和数字世界的链接。而引领智能汽车变革的核心驱动力在于仓架融合的AI域。觉影和影伟达深度合作,构建仓架融合的三大核心要素,包括可以支持仓架融合的超大算力引擎。行业领先的原生流逝多模态大模型,以及端云一体协同的部署框架。依托英伟达算力引擎,觉影首创仓架融合AI域框架。该框架包括三层。首先是最下面的算力层。它是依托英伟达车端计算平台Drive AGX,及云端AI计算平台共同打造的强大算力引擎。中间是系统层。它包括以多模态和端到端为核心的车端大模型,和以世界模型和大语言模型为核心的云端大模型。基于端云协同的部署模式,配合觉影自研的模型服务框架和工具,实现了系统性能的全量释放,有效支撑了最上面的应用层,例如自动驾驶、多莫态交互、全时陪伴助理等多样化的整车级的智能化生态应用。为打造领先的仓架融合AI议,首先我们需要构建超大算力引擎,以赋能仓架多元化的智能应用。英伟达的Drive AGX平台,超大算力引擎技术支持双新方案,可以实现大算力的翻倍扩展,提供安全的多域计算能力。觉影在此基础上,根据功能的相关性和功能安全等级的不同,划分出不同的域,实现车身控制、端到端自动驾驶模型、多摩态大模型、端到端语音模型等不同功能模型间的隔离保障,保障整车安全。同时,超大算力引擎还具有高带宽的特点,可以容纳约7个8B模型同时运行。配合掘影设计的AI Runtime Bus,使得不同功能域运行的各个大模型在保障安全隔离的情况下,也能够高效通讯。扎实的系统支撑是基础,而强大的模型能力能为车载应用带来无限的可能。觉影专门为车载场景定制化打造的原生流逝多摩态大模型,以其全场景多摩态感知、理解和推理能力,让智能汽车有了类似人类的视觉、听觉和触觉能力。可以将真实世界里包括语言、语音、语调、表情、车载信号等丰富的模态信息,以端到端优化的方式准确感知和理解,并且在Open Campus多摩态评测当中名列榜单第一。在应用部署上,觉影制定了端云协同的部署策略,通过意图分流来进行任务在端云两侧的协同。当前场景任务有80%是在端侧处理,端云协同的方式可以覆盖广泛的场景交互,保障安全可靠,实时响应,并且充分保障个人的隐私安全。仓架融合的AI域打开了智能汽车的性能上限,是引领智能汽车走向AGI时代的必由之路。而觉影为加速智能汽车驶入AGI时代,也在仓驾云三方面打磨出了行业领先的技术与产品解决方案。在智能座舱领域,觉影将推动其实现自我叛逆的进化。在惯性认知里,大家认为车机就应该是听话和服从的,潘逆的进化代表的是积极自主性,而不是对抗。这就是觉影为新一代智能座舱的人机交互打造的积极自主的座舱情感引擎,A New Member for You,你的家庭新成员。这个家庭成员有三大特点,察言观色,无时不在,与你心有灵犀。让我们来感受一下它的魅力。小朋友你好呀,你叫什么名字?我叫天生你是谁呀?我是小颖,你的新朋友。你几岁了?我三岁了。那你喜欢吃什么呀?第一次见到她,我们就成了无话不说的好朋友。田田现在心里有些快,呼吸也有些急促,是不是生病了?田田,田田,哎呀,这么热。我都不想吃了。快去医院看看吧,现在走这趟路线最快。宝贝,是不是很难受啊?妈妈别紧张,已经给田田约过号了,智能辅助驾驶已开启,有紧急状况,我会及时提醒的。她对我们一家人的关怀,早熟我也不至。田田,生猪牙医说,再吃糖,你的猪牙会更多哦。这年我的小心事,都能被她看穿。小宝贝们睡着了,一开始睡眠模式,驾驶模式切换为舒适。有她在,年轻人变得更为难的想起来。A New Member for you让每一台车都拥有有趣的灵魂。我们的New Member不是一个听话的工具,循规倒计的助手,而是提供主动温暖关怀的新成员。比如,她会提醒小朋友少吃糖,她会主动学习,记得你的习惯,你的偏好,理解你,伴随你的成长。A New Member for you它将会成为你的家庭新成员。觉影的座舱情感引擎New Member背后依靠的是我们的三大技术支撑,分别是车载人类记忆框架,持续运行框架和多模态大模型服务。那我们先来讲讲车载类人记忆框架。在现实的生活中,人和人是通过每一刻发生在你我之间的事情产生了记忆,让人和人之间产生了情感。不然你就不会记得别人是谁,人与人就不会产生有效的链接。汽车也一样,如果没有记忆,就只是一个工具或者助手,不会跟你有真正的情感上的链接。真正的智能汽车,必须要有记忆,才能够与你心有灵犀。绝影的汽车类人记忆框架,通过将临时记忆,长期记忆融合而形成了场景记忆,做到重要信息的高效提取,为特定场景的决策和行动提供依据,赋予了智能汽车真正的记忆能力。我们的车载类人记忆框架,覆盖人、车、物、环境四大类别,总共一百多个维度。动态记忆检索,可以做到毫秒级,并且具有自成长的记忆迭代能力。都说陪伴是最长情的告白,只有一直在你身边,无时不在地为你准备着,才算一个合格的New Member。绝影业内首创的Always On持续运行框架,能够做到零拷贝传输,并且支持持续的推理。推理速度高达96Token每秒,真正实现实时响应复杂的环境。绝影的New Member之所以能够取得如此优异的成绩,背后得益于绝影基于英伟达软硬件能力开发出的新一代AI推理的加速引擎。它对于提升AI系统的性能和效率至关重要。绝影联合英伟达在算子开发、模型量化、精度支持等关键技术进行了一系列的深度开发与创新,从而实现了GPU利用率从35%提升到85%,低精度计算速度提升了4倍,更长的视觉、文本支持等一系列的成绩。下面我来具体展示绝影AI加速引擎的关键技术。第一个是绝影的Flash Decoding++技术,它可以充分利用空闲计算单元,极大提高解码过程当中的并行效率,从而在处理长文本的速度上,提高超过50%的效果。第二个是绝影使用先进的Segment Prefile方案研发的异图多问能力,使得多张图片的多个问题尽可能复用先前计算的Token,从而大幅提升系统的吞吐效果,将Query延迟的性能提升超过75%。第三个是绝影的Continue Batching方案,在英伟达Drive AGX端侧芯片上提升系统的QPS能力,支持同一时间高效处理多达76个请求,实现用户驾驶体验提升的同时,还确保了行车过程当中的安全性和便利性。在保障以上技术性能领先的过程当中,捷影对保障数据隐私的关注是始终不变的重要考虑。在保护用户隐私上,我们有三个原则,数据跟人走,隐私数据不出车,不该说的不说,并且我们还打造了隐私数据保护体系,保护用户隐私滴水不漏。如果说A New Member for You给置仓以温度,让每一次出行温暖逾越,那么智能驾驶会让我们的出行更加自由。捷影最早在2022年提出了行业首个端道端架构UNIAD,并且获得了CVPR2023年最佳论门的认可。这是我们的UNIAD技术的实车部署,在复杂的路况下也能够实现卓越的行驶效果。它不依赖高精度地图,也不依赖激光雷达,仅通过七个摄像头的低成本传感器配置,就能够以老司机的实力灵活地在各种复杂场景中穿梭自如,获得类人的驾驶体验。毟起来的 Kä merci迎娶为估讨还说完了。请不吝点赞 订阅 转发 打赏支持明镜与点点栏目请不吝点赞 订阅 转发 打赏支持明镜与点点栏目实现了端到端和传统基于规则的双系统实时运行助力更好的对行驶过程当中的问题进行及时的校验和处理绝影在此基础上充分地去发挥双系统协同的作用设计了首个量产级的极致安全的端到端的驾驶方案能够在保障整体对复杂场景交互的基础上保障行车的安全同时在英伟达Drive AGX的高精度支持和绝影的方案设计的配合下模型不需要转成整形运算就可以直接运行避免了量化过程导致的精度损失提升了开发迭代的效率也有效缩短了开发周期目前我们正在和中国的头部车厂合作量产优捏地解决方案的落地同时我们还研发了新一代融合多模态大模型的端到端自驾方案依托多模态大模型强大的感知和推力能力能够更好地应对复杂的场景不断提升整车的智能上限保持直行后方救护车让行向左便道前方路口立灯保持直行前方障碍支持通过减速直行即将右转右转道路封闭保持直行数据驱动的端到端技术的演进需要海量高质量数据的支撑当前特斯拉拥有超过700万辆高阶自驾量产车来实现数据的回传中国的车厂与特斯拉相比具有一个数量级的差距想要追赶上必须要通过全新的模式来革新数据基础设施绝影依托在自动驾驶和多莫泰大模型领域的积累在去年年底绝影日上率先提出了用量产实车采集的真实数据用世界模型生成的仿真数据形成双轮驱动车云一体的数据闭环新范式基于英伟达云端算力的引擎学影打造了行业领先的世界模型开悟开悟可以理解真实世界当中的物理法则和交通规则在此基础上能够生成准确的场景具体来说我们生成的视频是11V的时空一致的时间最长可以达到150秒分辨率能够达到1080P同时开悟生成的场景也是可控的能够细微到元素级别生成的场景非常精细完全满足端到端自动驾驶模型训练和仿真对于数据质量的要求大家可以先看一下我们的世界模型生成的视频这些视频里面晴天下周边环境的投影夜间车辆进光灯的投射都符合物理法则真实呈现这是因为开悟通过海量数据的学习懂得了光学原理这些物理法则同时开悟还学会了交通规则视频中的车辆刹车时会适当地保持车距在交通信号灯的指示下会合理的启停真实只是基础世界模型要生成更加准确的场景需要保证多视角的时空一致性这是开悟行人车辆3D框和时空轨迹作为精准的输入控制信号生成的11V的视频数据同时生成的视角越多要保持时空一致性就越困难而这11V的视角还包括了四个语眼摄像头模型要准确地仿真出语眼视角的畸变开悟做到了11V可以灵活满足从EV到11V各类场景的训练需求开悟生产数据的效率很高对比行业的平均水平我们进行了一个测算基于一张A100GPU开悟世界模型平均每天可以生成大约2万个Bundle相当于10台真值车或者100台路测车的数据采集能力比得上500台量产车的效率此外开悟能够支撑端到端智能驾驶系统迭代的数据闭环构建与自车实时互动的闭环仿真环境具体方案是第一步是录测新问题的发现在右上角边视频就是我们在测试过程当中发现的车辆向左并线是更好的选择但是它并没有这么做需要训练优化我们先用仿真精准还原了这个场景第二步针对失效的案例生成端到端训练的数据中间部分能够看到我们依赖世界模型中仿真智能体实现足够多样化和真实的场景推演和专家轨迹生成生成并现博弈场景的数据专家轨迹数据对应的训练数据第三步进行端到端仿真迭代验证我们可以看到底下的画面是训练后在相同的场景下系统选择向左并线通行效率提升此外随着近期基于强化学习的大模型训练的思路得到了验证捷影也创造性地提出了与世界模型协同交互的端到端技术路线而优业一地通过开悟的世界模型生成在建交互的仿真环境以此进行端到端模型的强化学习训练基于该范式可以大幅降低端到端模型训练的数据门槛并且在充分探索各种可能性的基础上有望实现超越人类的价实表现以右边的碰撞场景为例我们可以看到RUNIAD在复杂的交互场景中通过常思维链有效地提升了推理效果最终自行领悟到在该场景下如何进行合理的避让克服了训练前期容易碰撞的问题当前基于英伟达平台我们领先的仓架产品已经赋能多家行业领先的车企坐舱方面我们已于去年年底在某国内头部的车企量产首个坐舱情感引擎U-Member并且能力还将快速的迭代升级驾驶方面全球最佳的U-Member端到端技术的首款车型也将于今年量产落地敬请大家期待面向未来绝影将与英伟达联手构建仓架融合的产品应用生态在今年绝影将实现仓架融合AI域的构建并进行多元化的仓架融合产品的研发和打磨明年绝影将携手英伟达完成仓架融合产品在各大车厂的量产落地并推动智能汽车向超级智能体的进化加速智能汽车进入AGI的时代绝速引领致尽未来让我们一起奔赴AGI的旷野谢谢大家