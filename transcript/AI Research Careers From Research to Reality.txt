 Hello, good afternoon, good morning and evening everyone and welcome to our panel AI Research Carriers from Research to Reality. My name is Tomasz Bednarz, Director of Strategic Research and Engagement at NVIDIA and I am delighted to moderate this distinguished panel featuring pioneering researchers who are transforming AI across multiple domains. Today we'll explore how the groundbreaking work in areas ranging from computational biomedicine, social robotics to mobility science and open data infrastructures is revolutionizing real-world applications. Our panelists will share their personal journeys, the challenges they overcome and practical advice to all of you for those who are looking to make the mark in AI research. I am excited for the insights and inspirations that we emerge from our conversations today. So we're going to start with a very quick introduction. So we're going to start with Professor Oya Sali-Kutan who's a reader in AI and robotics from King's College London. Oya, over to you. Oya Sali- Hi everyone. It's a pleasure to be on this panel. Thank you for the invitation. I am Oya Sali-Kutan, a reader in AI and robotics at King's College London. My career journey began in Turkey where I completed my PhD in Computer Vision focusing on human behaviour modelling. Initially, I worked on understanding human face behaviours and body motion by developing graph-based vision models. My path then took me to France, later to the UK where I expanded my research on human-centred perception to integrate with robotics and multi-model data. Specifically, I explore how we can transfer these models to robots for learning, action and interaction. At my research group, the Social AI and Robotics Laboratory, we work at the intersection of machine learning and human-robot interaction, and we are approaching these challenges from an interdisciplinary perspective. Particularly, in my lab, we focus on developing algorithms that enable robots seamlessly interact with humans and their environment, assisting humans in daily life. We approach this challenge through the lens of multiple intelligence, combining visual, motor and interpersonal. For instance, exploring how robots can transfer prior knowledge to new situations, learn tasks simply by observing others, and understand human non-verbal communication cues and learn to adapt for enhancing their acceptance. By collaborating with industry and organisations, we aim to make a real-world impact using interactive robots to support individuals with limited mobility to foster independence, or help children in pediatrics care to reduce anxiety and enhance their wellbeing. Next, I hand over to Peter Koveni, who is also my neighbour, a professor at the University of College London. Thank you very much indeed. It's great to be on this panel. It's an honour to join you here. I want to tell you a little bit about my background and how I came to do what I do today. And it's an interesting one in the sense that when I was, you know, first a studious undergraduate and doing research, I was heavily into the physical sciences, mathematics, some elements of engineering, but I was quite focused on things you'd regard as fairly esoteric academic and of mainly academic interest. At some stage, after my first sort of permanent appointment in the UK, I started to get itchy feet because my interests are actually wider than that might suggest in terms of silos. And I was persuaded to join a company, a very interesting one at the time, that's probably fairly well known. It's called Schlumberger. It's an oilfield service company. And what distinguished that in the domain was its high tech reputation. When I joined it, I found myself suddenly immersed in high tech of a kind that I'd never really engaged with before. And everything within that organisation was driven in that way. And one of the things that I found most exciting about working in such a kind of industrial context was we had lots of problems to address, they were diverse. But the issue was to solve those problems, as it were, by any means at one's disposal. That might be thought of as an engineering style approach. But it means that you're intrinsically doing interdisciplinary work, because almost any problem worth solving requires expertise across multiple domains. And it also involved a drive to always do things that you could say were bigger, better and faster by exploiting infrastructure and technology. I was there for some eight years or so in the 1990s. You may recall that was the era when parallel computing and high performance computing started to get going. The company turned out to be the first non-defence related organisation to buy a high forms computer. It was a connection machine from Sticking Machines Corporation. And that led us to do many interesting things in areas as diverse as indeed what is now called artificial intelligence. At the time, we were living through one of those AI winters caused by exaggerated claims some years earlier. But basically, that was laying the foundations for things like neural networks. We were applying it right, left and centre. At the time, I was convinced this was the way we should be going in the world. At the time, I was convinced this was the way we should be going in the company widely. But it didn't interestingly get the traction that it has subsequently. In my own case and career, I then came back into academia and as is described on these slides, I've been running what I call a centre of computational science ever since I came back. And that espouses exactly the same approach. We look to solve problems of any sort. So the catchphrase for us is advancing science through computers. And it doesn't say which areas we're going to work on. And in the in the context of this discussion, it may be clear that quite a lot of what we do, but by no means all of it is in the area we call computational biomedicine, which has become increasingly compelling and tractable with the advent of digitisation, large data sets and the ability to exploit supercomputing. And we must say things like GPUs, which weren't around a long time ago. So it's the context of all of those things which has brought me to where I am. And I work now very heavily with people across many different domains. My PhD students come from any area that has quantitative background to it. And we collaborate on an international scale to solve interesting problems. What we learn in some areas becomes rapidly transferable into another because the algorithms share a lot of points in common. And so it's about being open to opportunities and ability to collaborate that's led us to do the things we do today. This is illustrative of the sort of things we do and in my international activities, which again, date back to the time I was in industry because it was a very international company. We work heavily and continuously with colleagues in the USA. We have access to the highest performance supercomputers globally in the DOE through Insight Awards. And this slide just speaks to one of the codes we work on there, which is called HEM-LV, as in blood flow. We can now model and simulate the entire human vasculature from head to toe, arteries and veins and so on. And we do that for single instances that might occupy the entirety of Frontier, which is a machine with roughly 10,000 nodes, eight GPUs per node. So we can run an application like this over 80,000 GPUs. And of course, it flies incredibly quickly in that context. We are ambitious in terms of connecting organ models to each other. This slide shows a heart which we can connect to the vasculature. And before you know it, we're doing modelling and simulation of the cardiovascular vasculature. And that opens lots of interesting questions that are often not even thought about in current medicine, which are the coupling between things going on in the blood around the body and the heart and the brain. OK, so having said my bit, I want to pass on to Stephen Travis Waller, who's professor at the Technical University in Dresden in Germany. Well, thank you, Peter. So my name is Travis Waller. I'm a lighthouse professor and chair of transport modeling and simulation at Tehu Dresden in Germany. I've lived here now about three years. Prior to that, I was a professor and head of the School of Civil and Environmental Engineering at the University of New South Wales in Sydney, Australia. I was there from about 2011 until my relocation. And then before 2011, I was on faculty at the University of Texas, Austin for about nine years. And before that, Urbana-Champaign. Before that, postdoc Northwestern. My background started in electrical engineering and then I moved from my doctoral work into industrial engineering and management science. So very much modeling complex systems, typically socio-technical systems. So really graph theory optimization, but then increasingly over the last 20 years, branching into machine learning, data science, because my two key interests, as I've sort of discovered as I've done it, was sort of considering emerging technology and how they impact human mobility, both in terms of changing the travel behavior itself, but also leveraging those emerging technologies to represent the complex system better. But then simultaneously considering sort of our evolving social consciousness, environmental impact, justice, equity, fairness, and how we can integrate these models to try to do a better job. The work I've done is highly theoretical, as many of my colleagues, but also as my colleagues, very practical. And we've been funded by a lot of national science foundations country to country, but also a lot of practicing agencies and institutions and deploying the work. And there you can just see at the bottom right, you know, the some of the teams that I've led over the years, University of Texas, Austin, UNSW, and now here in Germany. In terms of the collaboration with NVIDIA, we've been for years on the next slide, we've been developing the sort of AI driven modeling that trying to transcend what's been possible historically to rapidly develop these models because they've taken a great deal of time and resources while leveraging the emerging data that's been just opening up tremendously. And these two things in combination have allowed a transformation in what we can do. And just as a couple of use cases there. So we've been looking at that travel behavior during human conflict. We've been doing multinational modeling, which historically was very problematic. Been looking at post disaster needs assessment. Most recently, the 2024 Armenian floods. And we've been trying to integrate all of that into the the the the vast capabilities present within the NVIDIA platforms, because we very much focus on the representation of the system. We're not specialists in terms of visualization and the engagement. But these are critical in terms of engaging with the public and engaging with decision makers. And so we're trying very much to align all of these different components to make it both a scientifically representative model, but also accessible to help inform decisions and try to change things into the future. And so that's us in a nutshell. And with that, I would like to pass over to my colleague, Yanis, who's a professor at the University of Athens. Thank you very much. It's a great pleasure to be part of this panel again. Let me thank the organizers for this invitation. This kind of shows the hats that I'm wearing on right now. The path I came here, I won't go over it, just except for just to say that my undergraduate degrees in electrical engineering. And then I went to the US for graduate studies. And I went from applied mathematics and eventually computer science. And then from Berkeley and then University of Wisconsin-Madison was where I stayed as a faculty of computer sciences for 11 years before returning to Greece. And I'm here for almost 30 years. And to briefly just describe the hats. These hats that I'm wearing now kind of try to capture all aspects that any academic may be involved in. And I still have things to cover. The first one is, if you want, the culmination of all the others that have brought me here, being a president of ACM, elected for a second term now. Where ACM is the largest global organization of computing professionals. It's about 120,000 colleagues. It's an extremely challenging task. Not only because of the richness of our field, but also of the challenges that arise. The role that computing and artificial intelligence plays right now. And trying to set a strategy for how ACMs would change and help us all as computing professionals and AI professionals requires all the experience and wisdom that all the other positions that I still have bring to me. And hopefully I'm doing half a decent job in that. But that is the global footprint that is the most exciting. In my paying job, I mean, as president of ACM, I'm a volunteer. But my paying job is I'm at the University of Athens. And my area is data. More or less from the beginning of my graduate studies, data, data management, and so on is my main field. And leading the management of data information and knowledge group at the university. You can pronounce the acronym MAGIC. And hopefully we bring some MAGIC into the field of data management. And that position led me and also my Wisconsin background, learned me how to teach and how to do research and how to create large teams. And then I went into administration. And for 10 years, I'm in the Athena Research Center, still affiliated. But for 10 years, I was the president of that. And there I discovered non-technical stuff that you need in order to bring together and serve the AI researchers, serve the data researchers, serve the industrial researchers that this institution had. And for many large science, whether computing science or not, you need large infrastructure. So openness and open access was what the open air infrastructure brought to Europe for all the research results, papers and others that are produced by Europeans. And that's open air. I led it for more than 10 years. And again, not thinking of your own research, but the research of others in terms of infrastructure service, complemented what the other positions taught me. And interdisciplinary, in my next slide, I'll emphasize this. Being involved with the sustainable development goals and co-chairing the global climate hub of the United Nations Sustainable Development Solutions Network is a culmination, if you want, of my interdisciplinary work. And finally, industry. So next to that, I'm involved in a couple of startups, one of which is, again, AI-driven, data-driven platform. So all of these experiences come together as a meeting point and help me inspire and lead our whole community as president of ACM. Now, my work profile, as I said, primarily my interest is in data, data infrastructures, data science, data and text analytics. But in the past 10 years or so, I've been attracted to more of the human side. Data usually is the dungeons. So recommender systems and personalization are a key, which is AI-driven, but also non-AI-driven as well. And that actually was a pathway to come to come in completely different interactive digital storytelling. And the human element and how you engage humans with knowledge is something that is really exciting. Interdisciplinarity has been my, almost from the very beginning, after I became a faculty. And most of my work, even the data work or the storytelling work, is inspired by many other sciences in the life sciences, physical sciences, social sciences, the humanities and the arts, dance and painting. So, and I feel enriched by all the colleagues that I interact. Some highlights, I just mentioned two of my current projects. One, how do you combine programming languages with the main database language that exists, you know, for more than 30, 40 years. SQL, it's like oil and water. How do you bring them together in something cohesive? Federated learning for medical data, when privacy is a concern because of these are human data and you have to respect the privacy of patients. The storytelling experiences that I mentioned, primarily in how you change the way, the overall philosophy of how you visit the museum, but also many other environments where a human needs to be engaged. You want to, you want engagement engineering, how do you make them to be emotionally involved with the knowledge. And then open air, as I said, trying to capture the whole production, not just of European researchers, more than 200 million publications, 75 million data sets and so on. How do you bring them in a knowledge base so that others can do the research? So this is, if you want my profile, personal path and also my passions, and that's what brought me here. Yes, thank you, Anis. I think while I have you here, I may start actually conversations with you right now. So you are ACM president, right? So you've seen the evolutions of computing research firsthand over the years. Can you tell us a bit more how has your journey from database systems, as you describe, to leading ACM, shaped your perspective on AI research careers? When I started my research career in databases, AI was mostly top down, you know, rules and frames and manually created models based on physics or other options. And it had some partial success and bottom AI did exist, but it couldn't deliver much because computational power and data size were limited. So AI results also were very limited. And most people looked down on AI. It was something exotic on the side. And then you wouldn't, the people dealing with that were weird. But as data and computational capacity and speed grew, things changed. And now everyone is doing bottom up AI. And even Turing Awards are again given for AI achievements after decades. And now it is the glorious time. I mean, it was mentioned the winter. Now it is the heart of the summer and then probably it will be continuously, the summer will continue. And no matter what anyone is doing, it's likely they will say, oh, yeah, I'm in AI, just to not feel left out. And my perspective also changed in that balance will be restored. The weaknesses of this approach to AI will be shown and we're trying to find them. And I'm constantly, although I'm a data person primarily, I'm constantly invited to talk about AI this and AI that. Although my area, as I said, is not that. But well, let's face it, since modern AI depends completely on data and I am doing data, so I can legitimately say I'm in AI also. So this path has changed. That's how I changed. And now AI is extremely exciting. Fed by data, extremely exciting. Thank you so much. It's like, as they say, everything connects to everything else, right? I think it was Leonardo da Vinci many, many years ago. All right. So let's continue. So I have my next questions targeting Oya. So Oya, as we already know, your work focuses very heavily on social revolution. Very heavily on social robotics and human-centered AI. Exciting topics. What inspired you to pursue the specific intersections of AI and robotics? Can you tell us a bit more about that? And how your international academic background influenced your approaches? Thanks for the question. Actually, I cannot agree with Yanis more to answer this question because what inspired me most about working in this domain is the multidisciplinary. Human-robot interaction is extremely complex domain. Human behavior is rich, diverse, and often unpredictable. To tackle these challenges, we must integrate multiple feats, not just robotics and AI, but also social sciences, such as behavioral psychology and ethics. It is crucial that the approaches we developed are privacy preserving, for instance, and ethical design. Working in different academic environments has offered me exciting opportunities to collaborate with researchers from diverse disciplines, including social scientists, clinicians, and even artists. And learning from these different perspectives and applying new ideas to my work is what keeps me motivated in this field. Very, very good. I love it. Art and science, right? All together. Just to drive the motions in robotics and human-centered AI. Fantastic. Thank you so much, Alia. Travis, so you've secured significant funding from organizations worldwide for mobility science. You've been working across the globe. Could you share with us a pivotal moment in your research journey that convinced you that AI transformative potential in transportation systems? Absolutely. And it really began in my own graduate studies. So my graduate studies was very focused on modeling of transport mobility systems to inform planning, city, regional, national levels. And we developed some new techniques and we even spun those off out of Northwestern University with my doctoral supervisor and I. We created a startup and that startup went for about 15 years. It made a profit. It did well enough. But the real, the reason it didn't go bigger was it was still very limited because creating those models was very bespoke, extremely time and resource dependent. It relied on a lot of human decision making just to create the model. And that limited the applicability and the take up. And then over the years, subsequently, as my research team, we began learning more about the emerging data sets, about applied AI. We've come up with newer methods that can instead of a year, you can do it in potentially weeks, days or sometimes even hours. And that's radically changed this application space. I mentioned modeling travel behavior during the Ukraine war, post disaster needs assessments. These sorts of applications are impossible with the old methods, but all of that opens now with these new techniques. It's transformative. That's awesome. And this newest computational platform, which is amazing, right? And we're going to be hearing lots of about those during GTC. So I think everybody is super excited about that. Let's go to Peter now. So Peter, I love your work. You have like very interdisciplinary approach as well. Your computational biomedicine work spans from physics to medicine, as you described before. How did you navigate the transitions between those different disciplines and domains altogether? And what advice would you give to researchers looking to work across disciplines? These are the biggest challenges to actually get things happening that are substantial in those areas. If you try to do computational biomedicine, I mean, ultimately, we're aspiring in the modern context to use what we call digital twins. So we're trying to really produce high fidelity representations of individuals. And so that is an interesting combination of large scale computing, what we can do to accelerate it. And AI plays a substantial role there with a community which, of course, involves everyone on the health care level because it affects us all. But in particular, a group of professionals in the medical domain and clinicians who aren't really trained to understand these methods. And there is a sort of division across the sciences as we go, as it were, from physics through chemistry and materials. You come to the interface with the life sciences. And whereas that first group of people are very familiar with the role of prediction. Prediction meaning I know enough or understand enough about the system I'm studying to forecast something that might happen. And if I use appropriate methods, which we call validation, verification and uncertainty quantification, I can get those predictions to some degree certified as reliable. Then people pay attention to them. Of course, weather forecasting and to some lesser degree climate prediction are all part and parcel of that. We're working with people who understand the methodologies. When you move to the life sciences and medicine, these people are not brought up and educated to think that there are models that are of the predictive kind. But yet that's what we have to implement if we're going to do personalized medicine. It's all about saying something ahead of time so that it's actionable by clinicians. So there's quite a challenge to bring these people on side. And you can't underestimate the importance of that. That does include education and training efforts to make them see the world in a similar way. And those kind of things we have had to indulge in in order to broaden the appeal of the methodology. So I'd say with the younger communities now bringing them into contact with the technologies we're talking about here really does start to fire them up. And then they will be expecting to use those in their daily lives in the future. So it's really important to see the whole panoply there. And then, as I was saying earlier, the ability to bring in individuals with different disciplines is vital. People have talked about this. I mean, I'm interested in complexity. I wrote a book called Frontiers of Complexity. We understand what we mean by that. It's systems where the whole is greater than the sum of the parts. And that's what we're attempting to do with individuals. If we can work together on the same wavelength and we have different kinds of complementary expertise, there's no end to the achievements we can make. But that's what you have to be prepared to do. And it is more challenging because you inevitably go outside a comfort zone that you may have created for yourself earlier. But the rewards in the end are far greater. That's the inspiration I would hope to convey to younger people just setting up on that pathway. Yeah, that's very, very deep and nice. So I actually share the same view. I think I always say to younger generations, just experiment with different things. Just go to the unknown very often and try new things. Right. So basically this is like going outside of your comfort zone to mention as well in a way. So it's very, very cool. All right. Let's talk a bit more about impacting applications. So Travis, you develop like Rapidex, which is basically integrated with NVIDIA Omniverse to create next-gen 3D traffic smothering. So I've seen that one. It's wonderful. How do you see this technology evolving to address urgent global challenges like the ever increasing traffic as the populations of city grows? Absolutely. Excellent question. I mean, the key challenge, at least in my domain, is, as others have sort of also mentioned for there, is very siloed, able to look at one aspect of a problem in isolation. And we've built very detailed methods for this, but it really creates barriers to looking at interactions. And human mobility strongly interacts, obviously, with energy usage. It strongly interacts with all aspects of sort of city planning, aspects like environmental justice, pollution levels, road carbon, but also equity, fairness and access. And how to look at all of these at the same time requires these new methods and much more advanced technology, both to run these incredibly complex systems models, as Peter knows better than I, but to run them so we can look at scenarios where we can vary each of these different dimensions to consider hypothetical possibilities so we can plan and inform the decisions. So how do we represent all of these at the same time is only now are we able to start doing that at all to a sufficient level. Very cool. So the future is very bright connecting all these methods together. Very cool. Oh yeah. Your social AI and robotics lab has received recognition through multiple awards right across across the years. Can you share with us an example of how your research has overcome a significant challenge in human robot interaction? Sure. So I'm not sure whether we overcome any significant challenge yet, because this domain is very challenging and complex, but we are doing our best. For instance, one of our projects focuses on robot navigation in human environments with social awareness. However, we aim to go beyond simply ensuring safe navigation and explore a fundamental question. Can we teach robots unspoken social rules? Consider a simple scenario. If two people are engaged in a conversation, should the robot pass between them? Probably not. As humans, we indistinctly avoid doing so. So address this challenge. We introduce the first egoscientic data set designed to capture conversational groups from a robot's perspective. We then developed a graph neural network based methods to detect these conversational groups contribution that received an award. And finally, our research was recently accepted in the International Journal of Social Robotics, where we integrated this approach with reinforcement learning enabling robots to exhibit advanced social awareness in human environments. Very cool. Thank you so much for that. Coming back to Peter. So we are at GTC. So I wanted to come back to some of the GPU conversations a bit. So the HEMLB projects that you mentioned before creates detailed simulations of human blood flow, digital twinning, you know, like blood flow and stuff. How has GPU computing transformed what's possible in computation biomedicine for you and your research? I must confine myself to a short reply here because it's incredibly exciting and diverse. The opportunities it's created. If you're just talking about the compute end of this, which was, you know, to try and build the ultimate aspiration, some sort of virtual human. You can see it in the vasculature. It's from head to toe. So it's very graphical. The idea that you can actually get a simulation of a whole human running at very high resolution. It might be 25 microns or so from from head to toe and do it fast enough to be able to interact with it in various ways that are relevant. Well, you have to have very powerful supercomputers. I mentioned that I've enjoyed access to the, you know, the top machines of the top 500 in recent times. And in fact, they all started with the heterogeneity coming with GPUs with the Nvidia on Titan, which had one P 100 per node. And when that happened, because of my orientation and sort of interaction with colleagues in the US and availability of the infrastructure, I realized we'd have to start migrating codes to work on those platforms, which is non trivial. And what's happened since then is we've gone through the machine called Summit and then onto Frontier and in fact Aurora at the moment. And now we're looking at Grace Hopper based machines in Europe and elsewhere. The reason why these are compelling is, first of all, we can scale these codes actually to very high node counts and GPU counts. So that means, in fact, we've got tremendous acceleration, which is important to be able to do simulations as close as you possibly can to real time. And then I was hinting at going back to basics in terms of what GPUs were originally for, which is video gaming. And now what about coming back to those in the case of what we would call computational steering? Because in the end with the clinicians, they don't want to be looking at lots of numbers, but they want the ability to actually interact with simulations in real time or something like that as they're going on. Well, if you've got that number of GPUs working together and you can render the stuff as it's going, well, you've got a chance to do interesting interactive simulations. So those things indicate why GPUs are important. The third one, of course, is the heterogeneity by design does allow AI tools to be applied as well. And those things can be useful when you're doing maybe training and trying to accelerate some of the runs when you train for an individual who's got a particular blood flow pattern. And you can use what we typically call physics based neural networks or machine learning tools, which are disciplined to understand, as it were, the laws of nature for fear of them going off in an unfortunate direction. But then you've got to be at the ability to actually accelerate even more the simulations that you are running previously. And that combination is not lethal is the wrong word. It's very, very powerful. And the importance of doing things very quickly can't be gains said. I was talking about actionable decision making. Remember, we want to make predictions ahead of interventions and so on to improve outcomes. All of this benefits tremendously from that type of technology around graphical processing units. Very, very cool. Yeah, I agree 100% what you just said as well, like importance of visualizations, visual analytics for looking at the simulation outcomes. It's actually essential, especially if it's done in real time for quick decision making, whether it's in hospitals or the traffic networks or other robotics or some big data science, right? Problems absolutely essential. Thank you so much for that. Yanis, back to you. So you've done, you mentioned open air initiatives like that. You championed open science. How do you see the relationship between open research and commercial AI developing development evolving further? Yeah, this is a huge impedance mismatch, so to speak. Openness and open science, the new philosophy of how to do research is the development of the AI. Research is a democratic way, is in the direction of collaboration, whereas commercial AI development currently is pretty much closed and it's competition. So these two class with each other. Before that, though, I mean, current AI development, the bottom up AI, commercial or academic, it's already by nature quite a bit closed because it's not explainable. So even if you open everything still, you cannot explain the results you get. Of course, on top of it, you have, you know, hidden data and algorithmic bias, hidden data privacy issues, trust issues, privacy leading to a known safety and lack of accountability. And I appreciate, you know, Lama and DeepSeek and so on that I just have the weights open. And I hope they continue to do that. And it's not just a one off. So it's Lama, I mean, and NVIDIA is very close to Lama. This is great. But that's not enough. We need even the code to open to at least solve some of the problems. Explainability, of course, is orthogonal. And at least for critical issues, I think policies should be established so that they force, like we do with drugs and we have clinical tests and so on, for certified people to be able to look into the code, to look into the data that is used to train the system so that we can have some sort of reassurance that what is being developed is what is being developed, even if it's closed for the big community, it is at least tested by some experts. Of course, like in open air, like in open science, the motto is as open as possible, as closed as necessary. And some things should be closed because if they fall in their own hands, then instead of being AI for good, it will be AI for bad. So this is a balance that we have to keep as a community and as a society to proceed. I believe that the more within limits that even commercial entities open up their code, open up their data, I think new business models will show up that will be very lucrative and beneficial even for these businesses. But for the time being, I'm afraid I'm not holding my breath that the leaders in the AI development sphere will dare to do that. And that's unfortunate. Thank you so much for that. So like maybe connecting every I will see like lots of kind of gap between maybe academia versus industry industry moving very fast because of the resources. And they having large language models, for instance, as an example, requires you to have like 10,000 GPUs to train very often this kind of models. But each of you were quite successful in academic career. You secured significant funding to drive your research and do the stuff that matters in your field. So I wanted to maybe get each of you to say a few words about what's your most valuable advice for kind of early career researchers who are just starting the career trying to fund ambitious AI projects. And maybe we go to the screen. So I was the first on the screen. Sure. So my advice would be never give up and keep trying because AI is evolving rapidly and has become highly competitive in recent years. From an academic perspective, if you truly believe in your idea, don't be discouraged by rejections. Instead, view them as opportunities to take the feedback, define your proposal and apply again. I think persistence and adaptability are key to securing funding. Very cool. Thank you so much for that, Peter. Yeah, well, in addition to that, but really underscoring the same things as well as other points I made earlier, the interdisciplinarity is usually the area where most of the more exciting things can happen. But by definition, you have to move out of your comfort zone to engage with them. And that does create risks, as we were just suggesting. I mean, making grant applications is a notoriously time consuming activity. And if you pitch something into an area where the experts aren't, they may reject something which is very unfortunate. If you recall, part of what I said about my earlier career, I spent a significant amount of time in industry. And what I didn't necessarily say at that time was I had the order of, I don't know, seven or eight years where I didn't have to write a single grant proposal. On the contrary, I was given money and people to work with and solve problems. OK, they were problems that I found actually very fascinating. But if you were a dull academic, you might think that's too scary and too applied. What you learn from looking at real world problems is that they pose fundamental challenges to science as well. So actually, I'm sort of suggesting that it's not a bad thing for people to consider at least collaborations, if not spending some time within an industrial context where they're actually able to see things in a way that can make progress more quickly without being tethered to some silo. So that's a thought for people to consider as well. Very cool. Thank you for that, Peter. Travis? Yeah, in terms of advice, early career, I guess two key things. The first one, find something you love doing. Because my mentors taught me you're going to need to live and breathe it. It will be for your life, especially during that period of time. So find something you love. And something else my mentors taught me was and I love both. I love science and engineering. But as I was taught, science understands engineering solves and you probably need both. Yeah. And so you need to focus on the value proposition to society. What is it that you're solving? So with something new and cutting edge? Yes. But being very, very clear yourself and able to articulate to others quickly what the value proposition is. So love it and be able to articulate that value proposition. Very cool. Thank you, Travis. And Yanis? Yeah, some of the same, maybe in different words. Well, chart your own path and dig where no one else is digging. This is clear. And be as ambitious as you want. Follow your ideas. Don't be afraid. Well, don't start completely blind. I mean, if you have some good insights on how you may approach them, even if it's dangerous, even if it's risky and it may fail, go after it. Go for the moon and the stars that come into your mind. And even if you fail on the way, you'll find so many other good results and great gems. But I think in our field, you should not be afraid of, oh, where am I going if I fail? You'll never fail. Okay. So go for the stars. That would it be. And follow your instinct. Follow your insights. And I really like Travis's comment about articulating it. If you can articulate it, if you can find the language in which you can articulate your stars and the moons, then go after it and you won't regret it. Go there. Yeah, it will. Yes. Experiment, experiment, connect dots, right? It's great. All right. So like, Yanis, you are here now on the stage. So like, let's say you as ACM president, right? You're developing the strategy for the next 25 years. And again, coming back perhaps to the questions on AI, what emerging AI research areas do you believe will be more transformative going forward? Okay. I don't know how much of this, what I'll say comes from me being ACM president or just being a researcher in the area, but it's probably a combination. One thing that I believe will be tremendous of tremendous importance is combining top-down and bottom-up AI. There are problems where top-down AI beats bottom-up and obviously the opposite, but the best of both worlds will give us solutions that we cannot imagine now. It's easier said than done, but I think that that would be transformative. The explainable AI is another one that is still fighting. And I think when we crack some part, even partly, this element, I think it will have tremendous impact and also the way society will accept this. The third thing is AI for science. Although we've seen some examples, you know, with Nobel prizes in physics and chemistry and so on. I think the fifth paradigm of science, of scientific discovery, which is AI based, has tremendous of things to show us. And in the cracks, you know, in the seams where science, scientific fields and AI come together will give us great things. And one last thing, if you want, most of computing research, most of AI research is done for things that are cognitive, that are high level. If you think of the Maslow's hierarchy of needs, we are focusing on the upper part. AI is not there to help people, to help the members of the society that haven't fulfilled the bottom layers of needs. And I think not only because of social responsibility, but because of the way I can see them, tremendous challenges that we have there and will face even scientifically. If some members of our community turn and look into these problems, some very exciting research results will come. Very cool. Thank you so much for this, Yanis. Oh yeah. You've been working with industry partners over the years. So Toyota, SoftBank and BDR. How do you balance academic research goals with industry collaboration requirements? So first of all, collaborating with industry partners and organizations so far has provided access to cutting edge equipments like robots, practical insights, as well as real world use cases to enrich our research. But at the same time, we remain committed to ensuring that our work not only addresses immediate industrial challenges, but also contributes to the broader scientific advancements. I think which is one of the benefits of being in academia. So we establish clear expectations from the start, defining projects that enable us to pursue fundamental research while also delivering value to our industry partners. And I think this energy fosters innovation and ensures that our academic independence is preserved while making an impact beyond the lab. Okay. Very good. Thank you. Travis, your work is very exciting and incorporates environmental drastic metrics into mobility models, right? How important it is for researchers to consider ethical dimensions of their work? I mean, for me personally, I think this is the single most important thing. I think it's been broadly observed. You know, we were living in a world increasingly run by algorithm. If the algorithms do not have our social values encoded in them, they will optimize everything else. And by necessity, they will then lean on those social values. You know, I got interested in this starting back in about 2005 or six, working with the largest metropolitan planning organization in America. And they were responding to a 1990s presidential executive order on considering environmental justice defined quite broadly and included equity and other aspects. But they had no idea how because their modeling process was very technical and quantified. They wanted they sincerely wanted to consider these things, but they needed help on how do we embed it into a number? Because if it wasn't in a number, it wouldn't actually change the outcome. But that's a very hard thing to do because there are so many different perspectives. What is equitable? What is fair? You almost have to start reading philosophy to get different perspectives on what it can be. And it's still not simple. You may have to engage focus groups, social outreach, engage in governance and involve these. But nonetheless, at the end of the day, to get them into the algorithm, it likely still needs to be quantified as well. And so how you bring all of that together, I think, for all of us is absolutely critical moving into the future, because these things are running more and more of our systems that impact our daily life. Yeah, thank you. Peter, coming back to your multiple domains and your research from physics to medicine, you mentioned a lot about usage of GPU and advanced computing to solve some of your problems. You gave a bit of advice about interdisciplinary in needed for computational biomedicine going forward, emerging technologies and next generation AI in some ways. I want to hear from you a bit more about what kind of breakthroughs do you anticipate to happen in the next, let's say, five years? In your personal opinion and maybe professional opinion as a top researcher in the field. And that's quite an open topic in a way, depending on how you want to circumscribe what I can talk about. But in terms of the biomedical area, of course, I was talking about digital twins. They're really very nascent at the moment in the biomedical domain. Imagine that trying to capture yourself in a computer model in a sense. And how do you manage that? But the opportunities are there now with the scale of computing, the combination of compute AI visualization. And the issue is how that might change the world for people. Really, the issue is to get away from using AI in a population sense and claim that's dealing with personalized medicine, because what it actually amounts to when you think about it is, in fact, building a large set of data on other people and then using it to predict how you're going to behave, which, when I say it like that, clearly isn't personalized medicine. It's assuming that we all fit together in a nice way. And the notion of things like averages is relevant to the human condition. But the average is actually more of an artifact than a representative thing. So there's that aspect of it that digital twins, in principle, can eradicate because they're asking for each person to be evaluated in the same way on the basis of their data, not other people's data. At a stroke, that sort of democratizes things. And if you stand back and think about the world we live in and other countries, I spent much of January in India, and I was learning there quite to my astonishment, in fact, that they haven't cracked the idea of collecting their own clinical data sets. As many in the developing world have not, they rely on Western ones. And so their AI systems are predicting behavior for their own patients that have nothing to do with their local populations. In a country as complicated and heterogeneous as India, that's farcical. So this is an opportunity to try to really bring this through to individuals. It's challenging. There's the other aspects that have been touched on, which are actually, in a sense, how can we trust the output of computers in the first place? And that actually speaks to some areas of AI at the moment where one can train the system very well. But then if you let it loose on new data, you can become a little uncertain about how reliable the data is. And that's actually connected to the uncertainty quantification point I was making earlier. So we really have to crack that in the AI case. It's a totally open problem. The last thing is the shocking level of energy demand, almost insatiable by these so-called large language models and others, which are now three orders of magnitude or more higher than supercomputers at gigawatts. So there is another interesting way of trying to look at computing in the future, which is analog computing that everyone has forgotten about. But our brains operate at 20 watts. Frontier, the top first exoscale machine is 20 megawatts. And we're talking about opening Three Mile Island to handle AI services, three orders of magnitude. We can do better with analog systems. We just haven't paid enough attention to them hitherto. But it could be that these insatiable energy demands will force us to look again at those systems. And they have ability to solve mathematical problems that you can't solve with algorithms and computational methods that depend on the discreteness of systems. I think there's a role for those in the game as well as potentially quantum computing when it eventually gets past the current problem of too much noise and error and not enough reliability. There's all kinds of things that could come into play. And heterogeneity is therefore the name of the game. Very good. Thank you so much for that. I'm just aware that we are slowly running out of time. So we're going to do like two very quick questions. So I'll ask everybody to maybe just say a few sentences on each. OK, so it's going to be very general questions. The first one is if you go back to the beginning of your research career, maybe after you finish your PhD with the knowledge you have now, what would you do differently? And we go with Oya. Oya. So I'm very pleased to see that this panel is converging on one central message that the multidisciplinary research. If I could go back to the beginning of my research career, I would focus on more interdisciplinary collaboration early on because human robot interaction benefits immensely from inside across multiple fields. Actually, I'm still very much interested in neuroscience, for instance. I still want to do a master's degree in the field and academia provides exceptional opportunities for personal development and lifelong learning. So it's never too late. Very good. Peter? I think I would endorse that. It's I've led a very highly interdisciplinary career from a certain stage of my development. But I could argue that it would have been better for me if I started that out earlier. I think that's the direction of travel that many people should follow because of the opportunities it throws up. And I think that's what I would state here and now simply. Very good. And Tavis, your perspective? Yeah, I think that that harmonizes exactly. I started sort of graph theory optimization, very technical algorithm based mathematical modeling. And then I've been slowly over subsequent 25 years reading more on the social side, the humanity side, the philosophical side. I would have started all of that much, much earlier, although there is a bandwidth. But I would have done that as quickly as I could. Very cool. Yanis? I was lucky to have been lured into multidisciplinarity already from my second year as faculty by a great colleague. So if I had not done that, I would have said what everyone else said. But having done that, I would say two things I would do differently. First of all, I would take sabbaticals. I'm a faculty member for 39 years. And for many reasons, I have not taken a single sabbatical. This is a sin. And the second thing is I probably wouldn't have listened. I shouldn't have listened to others when they were bashing neural networks because I was kind of intrigued. But then with what everyone else was saying, I didn't go into that. And I think it could have been exciting to go there. Very cool. All right. So we're going to close with the last final question. Okay, we're going to do very quick turnaround. Like, I assume we have like lots of folks watching us, hundreds of people being inspired by our distinguished panelists and their research career. So if you have one single piece of advice you would give to someone who is looking to pursue AI research after hearing from us and this panel, what it would be. So we're going to go perhaps opposite orders. We start with Yanis. I would say to not listen to any advice that we gave you. Of course, listen it, process it, but then follow your own path, put your own standards, follow your heart, shoot for the stars, and forget about us. Thank you. Travis. It actually coincides with Yanis in a way, which is that keeping in mind, whatever is the most popular cutting edge thing right now will not be what it is into the future. There is no single right set of skills that will serve you for decades to come. So pick what you enjoy, embrace it, but be willing to move and learn new things constantly and find what you love at some cutting edge and then ride that wave. Very cool. Peter? I'm not going to say anything more than that because it captures exactly the point. We can't really predict the future. And the relationship of technology, as we can see today with science and everything else, is a deeply impressive one. We have to be able to move in an agile way in the future, more so than we dinosaurs are at the moment. Oh, yeah? Yes, I agree with everything that's what's said. And I think one thing maybe to add to aim to build a strong foundation, because kind of what I observe as students, they try to jump on the outcomes without really developing a deeper understanding and deeper insight into the existing literature, try to focus on understanding theory. There are many excellent online resources, but at the same time gain as much as hands-on experience, because practical implementations is crucial in understanding real world challenges. Very, very cool. And that brings us to the end of this panel. So again, I wanted to thank our super professors Oya, Peter, Travis and Yanis to be part of this panel. And I wish our audience to have wonderful GTC.