大家好,我是治愈科技创始人周小花目前也担任公司CEO非常感谢英伟达给我们提供了一个展示产品的最新技术的平台大家都知道,最近几年各行各业的数据量曾快速增长,据RDC统计2023年全球每秒产生4.2p的数据这些数据在2028年将增长至12.5p由于数据分析和深圳市AI的广泛应用企业数据占比将从2023年的64%上升至2028年的81%在这样的背景下,数据分析和智力对企业来说是个越来越繁重的任务在众多行业中,金融凭借其庞大的数据量和复杂的计算需求一直以来都被认为是数据分析最具挑战性的领域之一尤其在量化金融领域涉及到大量实施数据和英质数据的分析要求极高的计算效率和精度因此,在这个新的时间纪念下如何高效处理和分析这些海量数据是我们需要探讨的问题DawnFundMe的目标就是帮助金融等行业解决这一难题在探索过程中一项重要成果就是我们和英伟的合作的CPU、GPU、易购计算平台Shark接下来,我将为大家做详细的介绍首先,我简单介绍一下我们公司我们公司成立于2016年一路走来,兼职自助研发我们的产品DawnFundMe是基于高性能分布式实施数据库支持复杂分析与流出力的实施计算平台换句话说,我们希望通过一个平台为大家解决数据成熟检索、分析、计算等各类需求到目前为止我们已多逐选Garton的榜单被评为中国数据库管理系统供应商、征宣厂商中国领先基础设施代表厂商中国实施数据管理代表厂商DawnFundMe演长年位列DBN京时实施数据库排行榜中国区第一名去年我们还很荣幸获得了英伟达出仓加速计划最终荣耀企的称号在我们开始原型研发时针对的就是金融领域数据的沉酸需求经过近十年的生根我们的付费客户已覆盖国内数百家金融机构、Allcore、银行、券商、私募、公募、期货、理财、信息服务商等细分领域同时得益金融客户对DawnFundMe功能与新能的高标准严要求我们不断约化产品也因此有能力去服务更多行业客户比如能源、电力、智能制造、科研机构、快效品等等可以说DawnFundMe是非常少见的既能深度结合金融业务又能有效服务实际经济的技术设施我们一直走在技术前沿力图将客户需求与技术创新紧密结合不断约化产品提供可靠的解决方案近年来AI技术的虚猛发展为各行各业带来革命性的变化从制造业到金融领域从医疗健康到教育培训AI正在以惊人的速度改变传统的工作方式DawnFundMe也在积极地将AI技术融入到产品中进一步释放生产力就是在这样的背景下我们与AI领域的领军者英伟达转开密切合作推出了CPU、GPU、易构计算平台Shark接下来我将对Shark做详细的介绍让我们将目光投向量化金融领域在这一领域数据的价值密度极高甚至是最高的谁能将数据用得好谁就能攒取优势大家看这是一个典型的用户工作流整个过程可以拆解为两个核心阶段投研阶段和生产阶段在投研阶段用户通胀会把股票行情舆情数据等多摩数据统一成为到数据不足接下来研究人员需要对原始数据进行清洗加工从中挖掘出有价值的因子然后研究人员会把这些挖掘出的因子投为给深度学习或者机器学习模型进行因子的合成最终通过历史回测验证他们的有效性只有通过层层考研的幼稚因子才会被部署到石盘交易中到了生产阶段系统需要实时接受交易所的行情数据流这些源源不断的市场动态会被快速转化为因子数值如果设计AI模型还需要同时进行实时的推理计算这些因子会产生交易信号制造用户在交易所下单在这样一个完整的工作流当中Shark和DafinDB可以如何为用户赋能呢让我们顺着链条来看一看首先是数据的乘除DafinDB具备多摩台的乘除能力支持TSDBOLAP组件乘除内存数据库向量乘除等五大引擎可以乘除和管理不同类型数据在数据压缩方面DafinDB采用劣势压缩乘除例如对于行情数据我们可以做到1B5到1B10的无损压缩这样用户的乘除成本得到了大幅的减少数据访问也会更加方便之后呢是拖延阶段在这一阶段当中用户可应使用Sharc的应用GP Learn和Sharc的Graph分析和挖掘因子在模型的训练和回测阶段用户也可以使用DafinDB的LibTouch插件和回测插件这就意味着用户不需要离开数据库的环境直接能够完整数据的转换模型的加载和推理计算的全过程在生产阶段因子计算任务可以使用Sharc的Metric Engine和Sharc Graph来完成推理和行情接受可以使用LibTouch插件DafinDB的流计算引擎来完成DafinDB内置了十几个流计算引擎例如时间序列引擎复杂事件处理引擎订单部引擎等等用户可以通过调用相应的引擎来完成实时复杂的计算任务最后用户可以使用DafinDB完成数据的入库形成一个完整的业务闭环接下来我为大家详细解释一下Sharc的组织架构大家可以看到Sharc有四层组成从下到上分别为数据的层出层数据的转换层基础组件以及应用层在数据层出层Sharc与CPU版本的DafinDB没有本质的区别我们依然采用了高性能分布式实际数据库的架构确保大规模数据能够快速被层出检索好管理由于Sharc通常是将计算负载到GPU来提升计算效率所以中间的数据转换层就充当了沟通GPU与数据库GPU与CPU的桥梁它的功能主要是将成都在数据库中的数据转换成GPU上能处理的格式具体的工作流程是这样的在计算开始时数据转换层可以从DafinDB中读取成熟的数据到CPU然后从CPU的数据复制到GPU供后续的计算使用当GPU完成计算以后数据转换层会将结果从GPU传回CPU然后将处理好的数据重新成熟在DafinDB的数据库当中形成高效的双向数据流在这次上我们还构建了一些基础组件比如适用于GPU的数据结构如表矩阵向量等将DafinDB的时序分析算子也迁移到GPU的数据库以及对数据分析任务更加友好的默认的显存管理器至于上层只是应用层目前由Shark已经推出的三大应用自动因子挖掘的GPU论因子计算的Metric Engine和一个通用的计算框架Shark Graph在真实介绍Shark应用之前我想先介绍一下我们对基础组件所做的一些优化我们都知道在一些复杂的数据分析中显存和内存的数据需要经频繁的交互通信我们观察到在某些高频因子计算的场景中将近90%的时间并非用于实际计算而是消耗在通信过程中当GPU计算单元每秒能处理百万级任务时这种用通信研制导致的算力限制实质上造成了巨大的隐形成本所以我们希望对拷贝进行优化阻断这个过程的耗时起初我们尝试将非索业内存注册为索业内存从而减少一次内存拷贝但在一些小内存的任务中频繁注册和取消的代价极为昂贵于是我们尝试将所谓内存值化所有的拷贝任务都共享一个所谓内存值但这种做法依旧没有办法跑满内存贷款由于拷贝流程是一个多阶段的任务每个阶段完成之后才能开启下一个阶段因此我们就考虑使用一个经典的计算机优化思想popline流水性的优化首先我们将两招的一个快进划分然后采用多线程分块拷贝的方式每个线程负责多个数据块在单个线程内部数据会先从显存拷贝到索业内存再从索业内存拷贝到非索业内存通过这种流水性的处理方式我们在牺牲一定PCOE代款的情况下大幅提升了内存代款的利用效率除此之外我们也正在GPU的数据库做了大量的优化以更好的适应大规模数据分析和任务我们以函数groupby为例在NVIDIA的RAP当中当多类数据使用sortgroupby算法进行分组时首先需要将所有类的数据拷贝到显存然后构造一个基于view的自定义比较器这种做法会导致频繁的内存访问造成性能瓶颈在经营AO1开始的情况下每次内存访问至少会多去32之间开启缓程后这些数据会增至128之间最后sortgroupby使用的是贵宾排序这种排序方法在速度上不如基数排序高效正在这一问题我们做了如下的优化这次我们只将一列数据读取到显存中取出这一列数据后按照上一列的排序结果对当前列进行重新组织然后对当前列进行基数排序在重排和排序的同时我们还可以一步的将下一列数据拷贝到显存中通过这种方式我们将数据拷贝与计算过程相互掩盖与技术实现相比新能最高提升的6倍接下来我们将介绍Sharc的应用程包括音质挖掘的GP论音质计算Magic Engine以及通用的异构计算框架Shark Graph首先是Shark GP论这一功能就是使用GPU加速的遗传算法来实现自动音质挖掘遗传算法有一个显著特点就是计算开销非常大尤其是在处理复杂音质时算法需要不断生成和评估公式这些过程会消耗大量的计算资源同时我们也发现这些计算任务中有相当一部分是可以并行处理的这一特性使得GPU的强大计算能力成为解决问题的理想选择因此我们就产生了个想法用GPU实现一个基于遗传算法来自动音质挖掘工具这也是Shark GP论的诞生背景在Shark GP论推出之前音乐已经尝试过适用遗传算法来自动音质挖掘其中基于Python的GPU框架是一个较为常见的工具但这个方法存在两个明显的问题一是由于Python本身的限制导致计算速度比较慢挖掘效率低下二是它指质着二维数据的特征挖掘但在金融领域经常需要利用时间标的和特征构成的三维数据来挖掘实现因子或者截面因子相比之下Shark GP论在多个方面转现出了优势我们将它们总结成了四点第一利用GPU加速挖掘Shark GP论的设计充分利用了GPU的并行计算能力可以大幅提升计算效率当需要处理海量数据时用户可以同时使用多块GPU来并行处理任务我们做过测试Shark GP论相比CPU版本的一串算法有了几十倍的责心能提升第二更加丰富的算子库Shark GP论的另一大优势在于它拥有一个极为丰富的算子库支持用户轻松实现各类复杂的计算在因子挖掘中活动仓口函数是不可获取的工具用于计算如移动平均移动标准差等指标而Shark GP论对活动仓口函数提供了原生支持使用户能够快速高效地完成这些计算除此之外Shark GP含支持多种类型的算子包括实际算子横戒面算子例如用户可以通过实际算子分析股票在一定时间范围内的价格变化趋势或者利用横戒面算子对某一时间点上的多个标的数据进行计算Shark GP提供的算子库不仅扩展了因子挖掘的可能性也降低了用户自行开发算子的成本第三这是Group 8语义金融数据通常是有多个标的而这些标的之间需要被分足处理例如用户可能需要分别计算每只股票的移动平均值或者比较同一行业内不同股票的表现Shark GP的Group By的功能能够将数据按照用户定义的分足条件进行处理这样一览Shark GP不仅适应于传统的二维数据处理还能够轻松应对时间标的特征构成的三维数据的外界需求外界出更加准确有效的因子四这是初始化公式在传统的遗传算法中初始化公式通常是随即生成的这可能导致计算效率不高或者生成的公式缺乏业务逻辑Shark GP论这是用户在算法开始之前设置初始化公式这意味着用户可以根据行业经验或者先验知识为遗传算法提供一个更优的起点从而提升最终的因子质量举个例子在模式场景下用户可能已经知道一些特定的数学公式在实际应用中表现优异那么他们就可以将这些公式作为初始化公式输入Shark GP人让算法在基础上进行优化确保生成的因子更加符合设计需求同时也介入大量的试错成本相比Python的GP人框架Shark GP人具有显著的性能优势我们在服务机上做过测试Python GP人使用32精神并发Shark采用A800的显卡在预测这些公式的任务中Shark在处理大数据量1000万号的情况下能够实现83倍的加速仅需不到10秒的时间而Python则需要将近14分钟接着我们来聊一聊Shark的另一大功能因子计算在DafinDB当中我们内置了2000多种原生函数与算子覆盖了用户从基础运算到复杂分析的各类需求我们从中挑选了200多最长印的算子将Rapix和QDF作为基础设施把这些算子迁移到了Shark平台加速因子的计算过程虽然GPU能够加速计算过程但Shark在自动因子挖掘过程中生存的公式是随机的这种随机性使得Shark无法加速特定公式的计算此外Shark的自动因子挖掘中使用的算子大多是保护性算子这意味着它们在计算过程中不会生存空置或者无群大这样虽然可以保证数据的完整性但在一些情况下也会限制计算的灵活性和效率为了弥补这些局限我们推出了Metrics Engine这是因为一个因子计算量身停滞的高效引擎它不仅能够利用GPU加速计算还能解决公式随机生存带来的问题在Metrics Engine中用户只需要输入需要计算的原代码系统会自动解析并生存计算图一旦计算图生存Metrics Engine就会对极竞脱扑排序确定各个算子的执行顺序借助这一机制SHAK能够在不牺牲计算整确性的前提下大幅提升音质计算的速度我们尝试用四种方法来完成任务包括SQL查询内存表CPU模式SQL查询分布式表CPU DFS模式SQL查询内存分区表CPU MPT模式以及基于GPU的Metrics Engine以下是这些方式在相同任务下的耗式对比结果从结果中我们可以明显看到使用Metrics Engine的计算耗式显著低于其他方式尤其在面对计算密集型的任务时Metrics Engine的性能表现会更加优异达到几十倍的提升SHAK GP Learn和Metrics Engine以定次化借口的方式帮助用户利用GPU加速音质挖掘和计算但这两个工具有一定的学习成本并且精致向量之间的运算对于更复杂的金融音质分析场景用户希望有一个更加简便通用的解决方案将先用的DoffinDB脚本与GPU加速无缝结合因此我们在最新版的DoffinDB中推出了SHAK Graph一款通用异构加速的脚本执行引擎用户在DoffinDB中编写自定义脚本后只需要加上SGPU注解就可以享受GPU加速带来的效益从工程实现上来看SHAK Graph同样以LAPT和QDF作为基础设施在此基础上SHAK Graph会将用户自定义的脚本转换或构建成一个有向无环图随后它会对图中的节点进行广度优先收缩对数据节点SHAK Graph会自动与数据传输模块进行通信对操作服节点系统则会自动在GPU上进行加速处理我们来看一个具体的金融场景下的加速案例雪球计券是一个经典的计券定价模型需要大量的蒙特卡罗模拟来确定计券的价格在一个包含480个交易日离待次数为100万字模型中需要生成100万x240x2的随机数并进行大量的矩增运算这是一个典型的计算密集型任务而且输入和输出的数据量相对较小非常适合使用GPU加速与DafinDB的多核执行相比Shark Graph在8并发的情况下能够实现最高70亿倍的加速即便与128并发相比Shark Graph仍然能够提供17倍的加速效果未来我们计划实现GPU直接从纸盘读取数据的功能优化数据处理的工作流程目前数据从纸盘读取到计算的整个链路需要进入CPU的中转而GPU直接夺取将会免去这一过程用户还可以直接将计算得到的因子输入深度学习模型进行训练或者推理通过这一优化数据的拷配次数将大幅减少整个链路的实验也会显著的降低介绍完下课之后我再和大家分享一下达分db对AI的深度支持在过去的一两年里AI和大模型无理唯一是技术界的火热话题那么大模型对数据库最核心的诉求是什么呢不同的人或许会给出不同答案但无论答案怎么变化REG都是一项无法ROCK的关键技术什么是REG呢它是一种结合了信息检索与生存模型的创新技术在生存文本之前REG会先从一个知识库或文档结合中检索相关信息就在利用这些检索大的内容来辅助生存更准确更加符合上下文的文本这种技术特别适合用于从海浪信息中提取有价值内容并再次技术上生存高资料的文本比如问答系统文档生存等场景以往在大模型生存内容中经常会出现一些看似合情合理但实际上且与真实情况相悲的展现结果这就是所谓的幻觉现在通过REG技术所有生存的内容都有依据可以追溯和验证大幅提升的结果的可解释性对于数据库而言只有提供了优秀的信息检索能力才能很好的成为REG的技术底座这种检索能力主要体积在两个方面密集检索和稀疏检索密集检索依赖于嵌入技术这种技术可以将文档和查询影射到一个同一个高位向量空间在这个高位向量空间中相似内容距离更近不同的内容距离更远因此通过计算查询向量与文档相量的相似度密集检索能够快速找到与查询最相关的文档最近两年向量数据库成了密集检索的代表工具所谓密集检索能力也就是向量检索的能力另一方面系数检索则依赖于传统的基于关键字匹配的检索技术例如TFIDF和BM25它通过分析文本中的直评和易文档频率查到与查询最相关的文档在处理结构化数据简短查询和关键字匹配时非常高效与密集检索相对应的系数检索能力又被称为文本检索能力DolphinDB仅跟AI技术潮流致力于成为REG技术的坚实底座先后推出了向量数据库VectorDB和文本层出引擎TaxDBVectorDB是一款以TSDB作为底层层出引进的向量解锁工具为密集检索能力提供了强有力的支持VectorDB有三大特点第一通过添加高效的索印机制实行了快速精准的向量相似度查询这种索印机制能够快速定位数据避免了传统向量检索中全标扫描带来的高耗时的问题大大提升检索速度我们在VectorDB中支持了五种不同的索印以支持用户不同的检索精度与速度都要需求第二VectorDB支持向量索印与吉他二级索印的持续化成组这意味着索印可以直接保存到置盘上当系统重启时我们只需要从置盘独取出去索印而不需要再耗费时间重新构建另外VectorDB同样支持分区等到分DB的经典功能所以很容易扩展到大规模的集训当中第三VectorDB支持混合搜索将杰克化检索与向量检索的又是结合在一起例如在风险投资分析场景中这种机构可能要筛选出一谋特定行业或企业特征相似的公司同时又对这些公司设下一些明确的财务条件的筛选这时通过VectorDB的混合搜索功能系统就可以既利用相量化的企业描述数据来计算予以的相似性又能根据年收入负债率等杰克化数据进行精确的筛选除了上述的技术特点之外VectorDB在性能上的表现也十分出色它可以实现单击11级级别的向量存出同时它还能够实现毫秒级的向量近视最近搜索为高冰发高实施性的业务场景提供坚实的保障TaxDB是基于刀牌索引的文本存出引擎那什么是刀牌索引呢它是一种高效的文本检索技术用来快速找到包含特定关键词的文档或者数据记录简单来说刀牌索引就是将每个单词与它出现的文档进行倒字记录举个例子现在我们有五篇文章刀牌索引会将文章中的每一个字印刷到包含它的文章编号中去比如第一篇和第三篇文章出现了我那么我就相应的印刷到这两篇文章中去这样在查询我这个字的时候我能很快速定位到这两篇文章而不需要逐篇进行扫描那么我们推出TaxDB用哪些优势呢首先是性能TaxDB可以显著加速自负材类型的全文检索与常规的Lucky查询相比TaxDB的查询性能提升了几十倍除了性能TaxDB还只是多种检索方式比如这是关键词检索短语检索这是前后锁检索这是在检索短语的时候指定词句这是中文英文以及中英文的混合检索等等还有很关键的一点是TaxDB深度集成了DalfinDB的乘出引擎一般来说很多系统都会在数据库外部维护一个独立的倒排索引来支持检索所以又带来了两个问题一是索引的空间转移往往会非常大二是索引的读写速度会受到外部的系统的限制而TaxDB优势就在于它不仅能够有效减少所应的空间占用还能显著提升所应的读写速度帮助用回应更低的成本更高的效率来完成任务在高效支持了密集检索和西数检索以后DalfinDB就能够成为RAG的数据底座我们以基于RAG的大模型问答系统为例向大家展示DalfinDB是如何赋能这一应用场景的在这个问答系统中针对输入的问题系统首先利用这两项核心技术进行检索一方面系统是用VectorDB来进行向量静零检索具体而言问答系统通过我们提供的Libetouch插件将输入的问题转化成一个向量表示然后系统将这个向量发动到VectorDB执行向量检索假设我们从数据库中查出了五篇与问题相关的文档于是同时系统还通过TextDB进行关键字检索TextDB会对输入问题进行分次并利用倒排索引技术与快速检索到包含关键字的文档假设TextDB也检索到了五篇与问题相关的文档这使系统就会通过综合VectorDB和TextDB检索到了十篇相关文档作为达模型生成回答的输入信息在处理完这些文档后达模型会基于文中的信息生成相应的回答借助DolphDB这样一个技术底座的支持开发者能够以更加简单和高效的方式开发出问答系统的后端以上就是DolphDB在探索AI领域时取得的进展未来DolphDB将继续优化现有的技术功能并不断拓展新的应用场景为更多的企业和开发者提供更具价值的解决方案成为推动行业智能化精神的重要引擎感谢观看