尊敬的各位同仁,大家好首先感谢NVIDIA GDC为我们提供了这样一个宝贵的机会让我代表LINEA公司来做这个session的分享今天我将与大家分享的主题是LINEA AI工厂NVIDIA AI Enterprise在中国的最佳事件首先我来介绍一下LINEA科技LINEA科技是一家提供大模型全站技术的服务商我们致力于为企业提供从数据到智能决策的一站式平台帮助企业高效利用主权数据通过低成本的大模型训练和微调实现智能化转型依托公司自主研发的LINEA AI工厂解决方案提供灵活经济的大模型微调与推理服务支持企业数据的智能化决策我们希望能够通过我们的服务和方案助力企业以低成本实现数据驱动的智能决策在此过程中成为全球智能化转型中手取一指的大模型平台大家看到这张图是我们LINEA AI工厂的总览图在LINEA AI工厂的架构中我们构建了多层级的系统以实现高效可靠且灵活的生成式AI的开发业经用我们从基础设计层开始我们会以NVIDIA AI Enterprise中的BCM极群管理组件为核心达到了一个能够管理万卡规模GPU极群的系统这一系统不仅实现了极群的统一管理也提供了服务器驱动适配的一致性动态部署扩展以及高性能的多用户多租户的隔离全方位的确保了资源的高效利用与安全隔离在整个技术设施层上我们实施了全站的优化方案包括对计算网络GPU的计算网络存储网络它的通信带宽还有延时进行了一系列的优化这一措施其实在我们的模型生产和训练过程中会极大的提升我们的模型利用率MFU从而会显著的增强了模型的生产能力在整体的优化之上我们也构建了一套易用的模型生产服务涵盖了数据预处理模型预训练模型对齐模型微调等关键环节在这一过程中我们广泛采用了MVIE中的一系列的强大组件例如用于数据处理的NEMO Crate模型预训练的NEMO MicroTrain的训练框架模型定制相关的NEMO Framework和最终的模型安全护栏NEMO GATA Reels等全方位保证了服务的高效性与可靠性在模型生产层面之上我们在模型的应用层我们融合了MVIE的NEMO技术并结合了LiteA的深度优化推出了LiteA大模型Inference Micro Service该服务提供了高效稳定的Token API服务确保了模型在实际过程中的并发存土力 延时都能达到卓越的行为表现在最终的用户服务层我们为用户提供了全方位的服务包括数据服务大模型微调服务模型推理服务知识库服务以及模型安全被暗相关的服务帮助用户能够无缝对接并高效地应用于垂直领域的多样化场景大家看到这个页面是LiteA AI工厂的管理平台它是专门为高效管理和优化的大规模GPU集群而设计的通过该平台我们可以实现GPU基础设施的统一管理平台支持对千卡万卡规模的GPU集群进行集中化标准化的部署互管理确保硬件资源的高效配置和快速的上限对于GPU算力的统一调度我们平台也基于这种很先进的这种调度算法平台能够实施的监控算力需求动态分配GPU算力资源最大化的利用了GPU集群的算力满足不同任务的计算需求然后整个任务的话也是全部容器化管理并做相关的这种资源优化平台对不同的任务进行了这种隔离和管理实现了资源的弹性与分配确保了所有的计算专利资源的高效利用提升了整体的运行效率对AI工厂的整个管理平台基于NVIDIA BCME的核心功能打造它的主要功能是自动化集群管理和调配无论你的集群规模是一个节点几个节点还是数十万个节点它都能够轻松的来管理通过集成K8S管理平台也能够对所有的AI工作负载进行动态的扩展并基于策略的资源分配可以根据实际的需求灵活的调整资源分配最大化的利用计算资源另外这个管理平台还提供了全方位的这种资源监控功能它能实时监控机群里面的作业运行状态网络状态还有相关的一些细致的这种profiling的一些运行状态包括我们的GPU相关的内部的资源使用情况最终也可以通过这种按照项目或应用程序报告相关硬件资源的使用情况实现最终的用户的机费和账号管理这套系统的另外一个亮点是其对易购环境的支持它不仅能够支持NVDI的GPU加速系统还兼容支持ARM的边缘色的计计设备和CPU相关的服务器的节点所以这些这个平台的管理特性是比较灵活的总的来说Layer AI工厂基于BCM的核心组件帮助企业提供了一个高效灵活可靠的集群管理解决方案它不仅简化了集群的部署管理还通过优化资源和监控系统最终提升了大规模集群的运行效率接下来我们来看一下Layer AI工厂提供的服务内容第一个是数据服务我们的服务目标是简化数据处理提升数据价值大家也知道在当今的企业运营中数据的多样性和复杂性其实是我们遇到的一大痛点我们其实是面临着这种结构化非结构化多模态以及不同垂直领域的数据挑战这些不同的结构不同的多模态没有关联的数据的提取检索以及在模型训练迭代和推理决策中的使用是一项极具挑战性的任务Layer AI工厂的数据服务会极大的简化这一流程并且支持数据的资标注和关联这不仅简化了数据处理的流程还会进一步提升数据的质量接下来我们来看一下Layer AI工厂是如何提供数据服务的在Layer AI工厂的数据服务中我们使用了MVIE的数据处理组件包括MVingest和NEMO DataCrate首先我们来看一下MVingest的Blueprint大家日常工作中也发现我们的企业其实积累了很多海量的文本数据这些数据其实大部分是以PDIF文章存在其中包括了文本表格图表等多种形式我们传统的方法只能提取文本信息而忽略了图表和表格中的丰富关系和上下文MVingest提供了多摩泰PDF数据流数据提取的工作流它其实能够从PDF文章中提取文本表格图表的完整信息整个工作流包含了很多个强大的NEM为服务可以有效的提升数据摄取的登图率和摄取精度例如用于图表分解的NEM它能够将复杂的图表分解为可理解的元素对于图像结构化处理的NEM它能够从PDF页面中的图像检测出表格等元素OCR相关的NEM它能够识别图像中的文字将图表中的表格中的文本提取出来这些NEM的组件都服务共同协同最终构建出来了多摩泰数据提取的工作流在Lai AI工厂对NV Ingest进行优化和提升后通过试测我们可以看出数据摄取的吞吐率提升了三倍相应的提取精度也提升了25%此外我们的Lai AI工厂也使用了NV Ingest进行优化和设计的核心另外一个数据服务的组件Nemo DataCreat在Lai AI工厂中可以直接使用Nemo DataCreat的组件它是专门为模型训练和定制化设计的数据处理和整理的工具经过Lai AI工厂的集成和本地化还有一些加速的优化我们可以提供完整的可训练数据处理功能主要功能包括以下几点第一个是它对于多摩泰数据的处理它既可以处理我们传统的文本另外也可以处理图像视频等多种数据摩泰的处理对于文本数据它的处理包括数据下载清洗质量过滤驱虫混合等步骤对于图像数据整理它可以支持从Web DataSite格式下载的数据集并通过过滤低质量的图像和驱虫来生成高质量的数据集对于视频数据处理它通过解码转码添加字幕和文本签入等步骤处理视频数据第二个大功能它是及时支持可以支持合成数据的生成提供合成数据生成管道支持从大模型生成相关的合成数据这样非常适用于问答队对话生成等这样类似的场景此外它也结合了MVDL的DASK和Ravidas技术支持GPU加速能够支持多GPU跨节点的行动工作这样的话我们的数据处理任务就会变得更加高效显著的会缩短了数据的准备时间第四个对于隐私保护和合规性它也提供了工具以便于识别和删除个人的识别信息确保数据的符合隐私的法规最终在LAYAI工厂中我们可以提供NEMO Data Creator的可定制化的模块化接口用户可以根据自己的需求构建自己的训练数据及处理管道通过右图中我们可以看到在8TB的数据量的情况下数据处理的速度提升了大概16倍大家看到这张图是在LAYAI工厂场中的数据服务和实际的操作页面它提供了这种方便快捷的页面用户可以直接上传各种类型的文件高效的将多模态的海量PDF数据进行相量化处理此外LAYAI工厂的数据服务还配备了专家模式在此模式底下用户可以直接申请GPU算力资源并创建专属的开发者Notebook环境以便开展高级的数据处理操作在平台中用户可以一键选择NVIDIA的NIME Data Creator镜像和NVIDIA的微服务无需重新配置任何依赖环境即可快速开启训练数据处理和开发的相关工作接下来我们来看一下LAYAI工厂的另一项核心服务大模型微调和定制服务大家也知道通过微调然后POST training的微调训练可以显著提升模型的性能与适应性使其能够在适配多元化的业务场景和垂直领域的需求整个微调流程构建于数据驱动与模型迭代的闭环之上同时在LAYAI工厂中也支持多种先进的增强方法为模型定制优化提供了全方位的支持基于LAYAI工厂的强大数据服务微调流程是会从任务描述与输入数据出发经过数据的清洗去从质量过滤等一系列精细化的处理生成高质量的监督微调SFT的数据在生成问答队和指令队的过程中我们会引入练习思考COT的增强机制从而进行可控训练的优质数据对于模型微调的方法LAYAI工厂也提供了丰富多样的PATH参数高效微调方法涵盖了Prompt TuningPrefix TuningLauri3 Adaptive方法我们会对这些方法进行深度优化与创新改进第一种改进方法我们叫它为ISTU方法它通过融合Lauri3 Fix Tuning和Adapt的优势利用低阶矩阵调整前缀插入和任务独立模块化实现了高效微调显著减少了参数量参数的更新量同时保持了模型性能和资源效率此外通过门共机制也限制了激活算法的数量避免了这几种算法的冲突进一步提高了模型的效率与最终的性能另外一个Pepht增加方法我们叫做SPC的方法它通过将前置网络的MOE化显著了提升了参数效率和模型性能同时也引入了Adapt模块有效地保留了微调过程中的知识积累通过在Expo专家中嵌入了Adapt后模型不仅能够学习每个分支的专属知识还能增强对共有知识的学习能力这种设计使得共有知识无需重复学习从而提升训练效率而每个专家则专注于自身的领域知识进一步的优化模型的最终性能最终我们通过开放数据集和自定义数据集进行全面的模型的基准分支码测试在模型训练后的各项能力指标进行精准评估在确保基准能力不下降的前提下充分满足业务场景的实际需求实现模型性能与业务失败性的完美平衡这张图是LIAE的高性能训练框架的整体框架图在高效训练框架中LIAE工厂基于NVIDIA AI Enterprise中的NEMO MicroTrain训练框架进行了深度优化显著提升了在Doka机训中的模型训练效率首先是我们对各种并性技术的吻合我们将数据并行DP 模型并行TP60线并行PP 以及Sinquents序列并行SP等多种并行技术有效的吻合这一举措会使模型能够在多卡多节点的集训中实现高效的分布训练充分发挥了硬件资源的这种潜力和它的算力第二个是显存与内存的优化策略我们在提供并行技术的同时也探索了这种显存和内存的并行的这种优化策略通过相关的显存与内存的资源管理和调度会显著的提升显存和内存的利用率从而有效缓解了在模型训练过程中遇到的显存资源不足这样类似的平均问题可以在一些特定场景下可以降低训练成本的投入另外也引入了NVDA在HOOPER和ADA-LEVANCE架构中提供的IFP8算子大家也知道使用IFP8算子在保持模型推理晶的同时会大幅度降低计算需求和通信带宽最后训练框架也引入了计算图优化的技术我们通过智能的重组计算流程进一步提高了执行效率这样的优化手段其实会让我们在模型训练过程中更加高效然后利用本身的计算算力资源通过上述的四点的基础的结合我们可以看到在右图中可以直观的看到在128个GPU节点的基础环境中基于实际的模型训练的基准测试的数据我们可以将模型利用率MFU从不到30%显著提升至50%有了计算框架我们来看一下类AI工厂是如何做模型定制的我们基于NV的AI Enterprise中的NEMO Framework一战计刑法案可以高效的定制生成式AI模型首先会从数据整理阶段开始我们能够高效的处理海量的数据集并生成高质量多样化的合成数据为模型定制训练提供基础在训练环节我们配备了优化和可固然的数据加载器然后并行处理内存优化以及之前提到的四点技术然后确保大规模数据集的高效训练可以大幅度提升模型的训练性在进入对析阶段类AI工厂也支持DPU、PPO、RHF、DLIM等一系列对析算法精准和效准模型的输出并使其预期的目标一致从而保证模型的可靠性和准确性对于模型定制我们也支持之前提到的一系列Path的方式也提供我们对Path的一些增强方式用户可以根据特定的需求灵活调整这些方法实现高度的个性化的模型定制在这基础上我们最终为用户打造了基于图形界面的任务模块化生产力工具LayerManus然后它提供一站式的解决方案把以上的这些步骤都可以通过UI界面简单化操作然后来对接用户能够高效的来做相关的模型平成这个是LayerAI工厂模型微调的操作页面我们提供了快捷的微调模式将所有的技术细节完全封装用户无需深入了解底下的架构即可轻松的开启微调和模型定制用户需要准备好数据一键上转便可以启动微调服务快速的实现模型的定制化和微调最终生成的模型通过一键部署和奔驰骂个评测确保了模型的各类指标的满足需求对于有更高要求和灵活的用户LayerAI工厂也提供相应的专家模式在这里用户可以建申请GPU算力资源创建开发者的Notebook环境进行更高级的更灵活的训练和微调平台内部也内置了NEMO的framework形象用户可以直接选择完成一站式的模型训练微调和定制的开发调试部署工作真正实现了高效便捷这个是LayerAI工厂的模型推理服Layer在模型生产完之后会进行模型的推理我们的推理框架也进行了一系列的优化通过对缓存机制推理的任务编排和硬件资源的分配优化最终会大幅度提升推理的服务性能对于缓存机制的优化方面我们会通过训练专门的模型来评价两个query之间的相似度并在相似度高以预知时直接从response cache就是响应缓存中扩取结果避免了重复的推理这种机制可以显著减少计算资源的浪费提高系统的响应速度第二个是在使用kv cache的技术上引入了Red Xtree它会进一步提升缓存的性能因为Red Xtree是一种高效的数据结构可以快速定位和检索缓存中的数据减少了相关的长运时间第二个主要大优化是对推理过程的优化首先会通过微调Draft Mode它使用高质量的数据训练使得这种平均的接收率从提升到了0.87所以我们在推理的早期一段就能够生成较为准确的结果减少了后续的一系列工作量计算量第二个是对于这种流水线任务的编排大家也知道对于推理其实是分为两个阶段一个是prefilling一个是decoding进行了一系列相关的优化prefilling阶段大家也知道它是计算运行的而decoding阶段是内存访问运行的通过这样的任务编排使得两个阶段都能够充分利用硬件资源提升整体的效果第三个是对硬件资源的一系列的合理分配我们会将kvcash的数据集中存储在显存性价比高的算力卡上而将逆急的计算操作放在计算性价比高的算力卡上这种策略会显著降低推理设备的整体成果同时也保证了推理的性能这些ppt展示了我们对于deepseek v3和re的推理优化的提升大家知道deepseek v3和re在训练过程中使用了mtp的技术multi token prediction多token的预测目标将预测的范围扩大到了多个token使其具备了原生多token预测的能力例如右图所示Multi AI工厂也在第一时间在推理的后端增加了mtp的feature并且大幅度提升了推理的性能首先是获得了更高的supoot吞吐率因为mtp的技术会使得木星有更高的效率能处理输入数据从而在单位时间内获取更多的数据而最终提高了出动吞吐率第二个是更快的响应时间通过优化模型的结构和算法mtp会减少模型在推理过程中的延时从而降低了平均手token延时的时间第三个是更好的这种并发处理的能力mtp会使得模型在处理并发请求时表现的更加出色通过左图我们可以看到mtp的优化方式在不同的场景下对模型新能的影响模型中展示了在不同的输入输出输出signfin slice和不同并发数下使用mtp和非mtp技术时模型的swp吞吐率tpot每秒的处理的token数和ttft首次的token响应时间等指标的差异从数据中可以看到使用mtp的优化模型在大多数情况下都展示出更高的swp和每秒处理的token数以及更低的swtoken延时的时间这表明mtp的这种优化可以很高效的提升模型的推理性能在LINEI工厂中的我们的模型服务另一个特点是对MediaNeme的集成和优化在左侧是MediaNeme的在线体验平台这里汇聚了最新最前沿的AI模型大家可以在里面体验最新的API模型的能力而在右侧是我们LINEI工厂的Neme平台LINEI Inference Microsoft Service平台LINEI的Neme平台也会提供最高效最灵活最可固然的模型API为大家来服务在LINEI工厂中我们会率先会对Neme发布的模型进行第一时间的适配和优化我们的目标是对0完成Neme相关的适配和优化一旦Neme发布了最新的服务和模型我们就能够快速的进行快速的适配和优化并集成到LINEI的LINEI平台中这样可以为企业打造最好最快最稳定的模型API服务接下来我们来看一下LINEI工厂的RIG知识库服这样服务基于Hybrid的RIG方案融合了GraphRIG和VictRIG的优势并借助Neme的Neme的模型显著的提升了检索的准确度和速度对于查询处理查询处理是一个在线的处理过程它会将用户的查询进行分类明确其类型和处理方式第二个是进行检索它能够精准地从知识库中检索出相关的信息第三个是RIG重排序对前提到的结果进行重排序进一步提升了信息的相关性和准确性第四点是Repack它包括了正向和反向的处理确保了信息的完整性和可用性我们最终对用户的Quarrie信息进行智能的总结同步提取关键的信息由于为用户提供准确的信息摘要第二个大部分是数据的处理数据处理是确保实时库服务的高效和高精度的基础首先我们会对数据进行语义分块然后确保数据的可管理性和可简单性第二个是会将数据进行相量化处理保存到相量数据库中第三个也会对数据进行Graph处理利用节点的嵌入和PageRef方法构建高效的图结构数据并且支持复杂的关系查询和分析最后的数据库管理是包括限量数据库和数据库的管理确保数据的高效存储和快速防御最终为用户提供了一个准确智能的知识检索和总结顶带这是LINE AI工厂的RG知识库服务演示视频在LINE AI工厂中企业用户可以高效的管理知识库通过图信化界面完成在线和离线的数据梳理企业自由化数据将被高效的存储到相量数据库和图数据库中通过在线的Query查询用户可以快速的减速知识信息为用户提供精准的答案此外LINE AI工厂还提供RG知识库的评测服务确保知识库的各项指标满足线上需求接下来我们来看一下LINE AI工厂的大模型安全服务大家也知道大模型的应用之一广泛但随之而来的这种合规和安全的挑战也愈发严禁LINE AI工厂的大模型服务正是为此痛点而生它能够协助客户高效的完成政策法规所需要的大模型备案服务我们的安全审核能够保证生成内容符合行业合规要求无论是医疗金融还是教育等高阶段行业都能够轻松的适配通过这一模块可不可以显著地加速大模型上限的速度减少合规阻力在LINE AI工厂的大模型安全服务中我们使用了NEMO Goddarius的安全护栏组件的能力它可以通过对输入输出内容进行审核防止生成莫犯性语言错误的信息或违反策略内容第二个对于敏感数据的检测和匿名法它能够检测并匿名法用户输入模型输出或知识库中检测到的敏感信息如个人的身份信息信用卡信息电话号码等第三个它是会对事实进行进一步护肠还有一致性的检测知识对模型生成的想应进行实时检测确保其知识库中的信息保持一致这种机制会有助于提高生成内容的可靠性和准确性避免模型生成与实时不复的内容第四个是防止越狱与恶意攻击能够检测并阻止用户试图绕过模型限制的行为从而保护模型免兽恶意的攻击第五个是可以对上下网的控制和立体off topic的检测通过忽览机制可以确保模型的响应紧构主题避免偏离用户需求和生成无关的内容在LIA工厂中的场景化应用与数据闭环流程中我们首先会对场景和行业的数据进行初步的抽象和提炼通过DataLink实现数据的高效连接并完成数据的清洗转换最终生成高质量的训练数据为模型训练奠定基础随后在业务场景中我们会根据模型的实际使用效果进行Benchmark 评估并开展可解释性的决策分析基于这些分析结果判断是否会对需要对训练数据进行手动纠正如果需要我们会根据条件决策和可解释性分析生成针对性的训练为条任务整个流程是会以数据驱动为核心构建了一个完整的数据闭环通过在业务场景和流程中的持续迭代模型会让模型更加准确的理解业务场景和业务需求从而显著提升业务场景的决策能力和登记效果这是在LIA工厂中实践的具体案例大健康咨询业务整个业务围绕着以下几个关键步骤展开包括客户信息收集健康评估方案数据效果评估以及答案管理这些环节紧密线紧形成一个完整的健康管理闭环为了更好的满足业务需求我们将这一方案深度拆解并融入LIA工厂的服务体系中具体而言我们整合了以下的服务模块包括数据服务模型定制服务模型推理服务RIG知识库服务模型安全服务整体方案使用的模型会在业务流程中不断的进行迭代优化随着数据的持续积累和模型的自我学习和迭代我们将形成一个数据模型迭代飞轮不断的提升业务场景的指标表现这个是我们在金融欺诈交易检测场景中的一个成功案例在金融欺诈交易检测场景中我们在LIA工厂通过构建数据闭环和模型迭代机制可以显著提升欺诈检测的准确率和效率首先我们会收集海量的交易数据包括正常交易和欺诈交易的样子会对数据进行清洗特征提取和标准化处理确保数据的质量第二个会将训练好的模型部署到实施的交易检测系统中对每一笔的交易进行实施风险评估当检测到可疑的交易时系统会触发预警机制被通知封控人员进行进一步的核实第三个是数据回流与模型更新将新的交易数据和人工审核结果回流到数据平台作为新的训练样本定期对模型进行重新训练和优化以适应不断变化的机长模式在最终的指标中我们可以看到从最初的40%多提升到85%的检测精度提升最后我们来看一下Lai AI工厂的产品和服务Lai AI工厂提供的产品具有极高的灵活性能够适应不同的部署要求而既可以在单台一体上运行也可以扩展至万卡进行以满足更大规模的计算需求通过集成Lai AI工厂提供了一套完整且可靠的企业集结计方案这样使得开发者和企业将更多的时间投入到自己业务场景的创新和优化中无论是进行企业级的大规模应用开发还是支持科研人员的前缘探索Lai AI工厂都能够提供强大的支持和助力以上就是我今天完整的分享谢谢大家的聆听谢谢大家