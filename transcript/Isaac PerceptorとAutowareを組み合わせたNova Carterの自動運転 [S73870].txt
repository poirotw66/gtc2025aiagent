 And Thank you.NVIDIA GTC 2025 Japan AI Dayにお集まりいただきありがとうございます。アイザックパーセプターとオートウェアを組み合わせたノバカーターの自動運転と題しまして、株式会社Tier4のコンドエタカが発表を行います。まずはじめに目次ですけれども、まず弊社Tier4の説明と自動運転ソフトウェアオートウェアの紹介をいたします。その後、NVIDIA ISAC Perceptorを使ったパーセプション、そして自立移動ロボット開発プラットフォームであるNVIDIA Nova Carterの説明をいたします。最後にNVIDIA Nova Carterと自動運転ソフトウェアオートウェアをインテグレーションする様子についてご紹介いたします。まず最初に最終的に得られた成果物をご紹介いたしましょう。こちらは品川オフィスの2階でカフェエリアを使いまして、実際にNVIDIA Nova Carterがオートウェアによって動いている様子になります。オートウェアの特徴として、他のマビゲーションソフトウェアと違いまして、斜線上を動くというのが特徴ですので、ご覧のようにあらかじめベクターマップとして用意した斜線上を、今は8の字上に動いております。この斜線上に仮に障害物があったり、人が通ったり、信号が赤を変わったりすると、オートウェアの動きが自律的に変更されるというのが、このオートウェアの仕組みであります。今回は屋外実験ではなく屋内実験ですし、障害物なども少ない状況ではありますが、実際に避けながら動いている様子が見て取れます。またさらに、3次元ライダーの情報だけじゃなくて、実際にロボットが動き回っていると、徐々にロボットの下の平面に、白と黒の占有コーシブルができてくると思うんですけれども、こちらはライダーの情報ではなくて、パーセプションを使いまして、左右と前方向につけられたステレオカメラの情報から、占有コーシブルを作っております。これによって、動的障害物を認識しながら、オートヤーとノバカーターが動いている様子が見て取れると思います。こちらの6名のメンバーで、今回オートヤーのインテグレーションを行いました。開発期間は実質1ヶ月ということで、非常に限られた時間でありましたが、成功を理に収めることができました。神戸さんと佐々木さんが、カーターのセットアップと安全な走行実験を担当しまして、浅部さんは遠隔からアイザクシムを使ったシミュレーションで、インテグレーションを進めてくれました。そして、三瀬さんは、オートヤーのインテグレーションのメインを担当しまして、センサーや車両の制御の部分のインテグレーションを担当しております。そして、平井林さんは、普段はJetsonプラットフォームのエンジニアリングをしておりまして、今回、アイザクインセプターのインテグレーションを担当しております。私はプロジェクトマネジメントのみを担当しまして、今回、皆さんの他のメンバーのおかげで、インテグレーションは完成しております。私は、近藤井高と申しまして、2013年に学習家庭を卒業した後、カードロボティクス、プリファードネットワークス、プリファードロボティクスを経て、今、Tier4でエンジニアリングマネージャーとして働いております。個人活動といたしましては、NVIDIAに関連するところで言いますと、Jetsonインフルエンサーを数年前から担当しておりまして、NVIDIA AI Daysでの講演や、後で紹介します、NVIDIA Jetson Platformを使った、いろいろな活動をしております。また、会計審判、ロス2で始めようという本が、昨年も出まして、ぜひ皆さんに読んでいただけるとありがたいです。過去のNVIDIA Jetson Platformのご紹介、少しだけさせてください。こちらは、世界初と僕は思っている、モバイルマニピュレーター、ロス対応のモバイルマニピュレーターの様子です。コンピューティングのプラットフォームとして、Jetson Xabiaを搭載しております。こちらは、ひるがえって、Jetson Nano 2GBという、一番小さいコンピューティングプラットフォームを使って、四軸のマニピュレーターのIK、逆運動学を学習、推論しているプロジェクトであります。さて、まず最初に、Tier4とオートウェアの説明をさせてください。Tier4は、2015年に、オートウェアをオープンソースソフトウェアとして公開いたしました。その後、2018年に、Tier4だけじゃなくて、いろんな会社を巻き込んで、オートウェアを開発していくために、オートウェアファウンデーションを設立いたしました。その後、実証実験や資金調達、シリコンバレー拠点などを設立いたしまして、2025年1月、自動運転レベル4の許可を取得いたしまして、長野県塩尻市で、自動運転システムを稼働させたりしております。オートウェアというのは、LinuxとLOS2を基盤とした、世界初のオープンソースの自動運転ソフトウェアです。自動運転を設計する上で、必要な機能を全て提供しているのが特徴であります。例えば、センサーで得られた情報を事前処理し、その後、事故位置推定、そして物体認識を行って、経路計画を行うプランニングを行います。その後、車両に対して制御入力を行い、実際に車を動かすという一連の仕組みを、オートウェアは提供しております。この一連の仕組みは、全てコンポーネントとして定義されておりまして、サードパーティーが別のコンポーネントに置き換えたり、別の車両のための車両の制御インターフェースに置き換えたりすることも可能です。すでに500社以上の企業や、20カ国以上の国、地域で使われております。オートウェアは、ティア4だけじゃなくて、グローバル規模で開発加速、普及促進をしていくために、オートウェアファンデーションという業界団体で開発をしております。ご覧のように、80以上のメンバー、いろんな企業や業界団体を含めたメンバーによって開発をしておりまして、すべてオープンソースとして提供することを良しとしております。オートウェアは、すでに研究開発のプラットフォームではなく、実用化もできるプラットフォームになっております。こちらは、東京都内のとある場所で、実際にオートウェアを動かしている様子です。ライダーやカメラの情報を使って、車や人を認識している様子も分かりますし、実際ここから車線変更を行って、信号待ちを行って、人がいなくなったこと、信号が青信号になったことを認識して、右折していく様子を見て取れると思います。こういったソフトウェアインテグレーションは、たくさんのコンポーネントに分かれておりますし、いろんな機能開発が必要なんですけれども、それら、様々なソフトウェアというものは、すでにオートウェアに取り込まれておりまして、オープンソースで我々も提供しておりますので、仮にTier4がいなくても、皆様の手によってオートウェアを使い込めば、このような自動運転の実証実験を行うことは可能です。Tier4は、オートウェアが提供している自動運転ソフトウェア以外の部分で、事業を進めております。最初のWebオートは、クラウド技術を活用して、開発運用に適したプラットフォームを提供しておりますし、パイロットオートでは、オートウェアを基盤として、拡張可能な自動運転ソフトウェアプラットフォームを提供して、いろんなリファレンスハーブウェアで動くようにしております。さらに、H-Oとは、実際のセンサーやコンピューターシステムみたいなものを提供するプラットになっております。オートウェアは、Tier4だけが開発しているわけではありません。ですので、いろんなソフトウェアの品質やメンテナンス、そういったものをどうしてもTier4でメンテナンスする必要があります。そこでパイロットオートがその役目を担っているわけです。例えば、バス用のインテグレーションであったり、品質保証の部分、テストの部分を行ったり、タクシー、トラック、いろんなものに対して、同じように運行領域を設定して安全に動くように、プロダクトの形にして提供しております。さらに左側ではセンサーのリファレンスハードウェアを提供したり、継続的にシステムを良くしていくために、運行管理、遠隔監視のプラットフォームとして、Webオートの仕組みも提供しております。Tier4は、こちらのオープンソースソフトウェア、オートウェアを使って、様々な場所で実証実験を重ね、実際に実社会で活かしていく活動をしております。すでに38都道府県、97市区町村で実証実験を実施し、さらに、今現在では、すでに製品化した例もたくさんございます。その一つとしては、石川県小松市で自動運転バスを通年運行いたしました。こちらはですね、すでにお客様から運賃もいただくような、実際の製品になっておりまして、すでに延べ1万人以上が、ご利用いただいている自動運転システムになっています。こちらのシステムはまだ、友人の運転手が安全のために乗り入れしているんですけども、次の例ではですね、本当にドライバーがいない自動運転を実現いたしました。こちらは長野県塩尻市で、実際に、バスの、シャトルバスが運行している様子になります。ご覧のようにですね、運転席に人がいない状況を実際に実現いたしました。私はもちゃんと行政や、市区町村の許認可を得て、実施している例になります。これまでにも、もう100件近くの実験を、実験じゃない、走行を行いましたが、運転席に対する介入が必要になったり、非常停止したりという状況は確認されておりません。次に、NVIDIA ISACプラットフォーム、特にパーセプターの説明に移らせていただきます。まず、NVIDIA ISACプラットフォームなんですけども、こちらは、Kudaのアクセラレーションができる、ロスパッケージの総称です。NVIDIA GPUだけじゃなくて、Jetsonプラットフォームによって対応しておりまして、LOS2ハンブルのディストリビューションからは、型的用、タイプアダプテーションという仕組みを使ってですね、CPU、GPU間のメモリーコピーを抑制する仕組みが、取り入られており、非常にメモリー効率の良い、高速でかつ低消費電力な、演算が可能になっております。ご覧のように、画像処理だけじゃなくて、ナビゲーションや、マニピュレーションにも適用できる、パッケージが公開されております。このISACロスパッケージのうち、パーセプションに関わるパッケージを、ワークフローに編成したものが、ISACパーセプターです。学習モデルを使った、各種推論や、3次元構成、VisualSlamに対応しております。特に、今回使いました、NovaKartaなどの、自立移動ロボットへの、インテグレーションを想定しております。ISACロスパーセプターが提供する、いくつかの機能について、説明します。まず、DNAのインファレンスですけれども、こちらは、名前の通り、真相学習を用いた、推論に対応しております。今回、特に用いました、ステレオカメラの、視差、画像推定や、セグメンテーション、物体認識、ポーズ推定、振動画像推定など、いわゆる、画像を使った、真相学習の仕組みは、全て対応しておりますし、NVIDIAの、Tensor RTという、アクセラレーションや、軽量化をする仕組みにも、対応しておりますので、マジェットソンプラットフォームや、GPUを積んだ、コンピューターで、非常に性能高く動かすことが可能です。そして、それらの基本機能の上に、ビジュアルスラムの仕組みも、提供しております。先ほど、説明した、視差画像推定の仕組みと、IMUを使って、自己位置推定を、行うことが可能です。さらに、キーポイントの点群を使って、ナビゲーションの地図を、作ることも可能です。これを使って、ロスでよく使われる、Nav2の地図を、生成することも可能です。次に、2次元の地図だけじゃなくて、3次元の地図を、再構成することも、可能です。こちらは、IsaacロスNVブロックスという、仕組みで、提供されております。今回の、Novaカーターでも、使っているんですけども、ナビゲーション用の、コストマップを、生成する仕組みも、提供されておりますし、追加機能として、人の認識もできるので、その部分の、セグメンテーションを、除去して、人を、地図から、取り除くということも、可能です。そして、今回、用いました、自立移動ロボットプラットフォームの、NVIDIA NOVAカーターの、説明に移ります。まず、NOVAカーターは、こちらの、自立移動ロボットコンピューティングプラットフォーム、センサープラットフォーム、NOVA ONLYの、参照実装、みたいな形で、提供されております。様々な、センサーの構成された、移動ロボットに、適用できて、Izac Perceptorを使って、アクセラレーションできるように、するプラットフォームです。例えば、こちらの、図のように、デプスカメラを、前後、左右に、取り付けておりますし、3D、2Dのライダーも、取り付けてあります。さらに、超音波センサーも、内蔵しております。こちらは、ロボットのプラットフォームだけじゃなくて、AGX ONLYに、ステレオカメラ、センサーだけを付けたものを、開発キットとして提供する、取り組みも、なされているようです。この、NOVA ONLYの仕組みを、参照実装したものが、NOVA CARTERです。SEGWAYロボティクスと、共同開発しておりまして、またしたような、センサーを、内蔵しております。今回使った、サイズユニケーライダーや、ステレオカメラ、魚眼カメラ、魚軸センサー、たくさん付いております。なので、このロボットを使えば、基本的な、自立移動の研究開発は、スムーズに行うことができますし、ロス2パッケージとして、全て提供されておりますので、ロス2の開発プラットフォームとしても、大変適していると感じました。今回は、ライダーではなくて、カメラの情報を、たくさん使っていこうという取り組みですので、ステレオカメラと、魚眼カメラが、どのように映るのか、まず試験してみました。ご覧のように、左半分が、ステレオカメラの様子で、右半分が、魚眼カメラの様子です。こちらのように、360度を、囲うように、センサーが取り付けてありますので、ライダーを使わずに、カメラだけで、動的障害物を検出したり、地図を作ったりということが可能です。今回は、安全な走行実験のために、ケーブルを抜くと、非常停止できるような仕組みに、非常停止スイッチの部分を、改造いたしました。ただ、NVIDIA様からの対応品ですので、完全な、可逆的な改造という形で、取り組んでおります。まずは、Nav2対応について、いろいろ実験したんですけども、すでに、NVIDIA様から、参照実装が提供済みですので、ライダースラムや、アイザックビジュアルスラムを用いた、実行が、すでに可能になっておりました。このうち、アイザックロスビジュアルスラムを使った、Nav2走行実験について、弊社でも、再現実験を行ってみました。ご覧のように、ちょっと見づらいんですけども、RBISで、パスが描かれて、経路計画をして、ロボットが動いている様子が、分かります。ただし、線有行指図の数メートル先に、謎の障害物ができてしまう、という状況がありまして、こちらは、線有行指図の障害物の下限を、下の式位置を、床面から30センチ以上にすると、解決されたんですけども、それだと、床面にある障害物を、引いてしまうという、課題もありますので、根本解決には、ステレオマッチングの、ディープラーニングを、改善していく必要があるのかな、と感じております。次に、本題であります、Novacartaへの、オートウェアインテグレーションの、お話をしていきます。今回開発しました、Novacartaと、オートウェアのインテグレーションを、行ったパッケージに関しては、全て、GitHubで、Apache 2.0のライセンスで、公開しております。ぜひ、ご覧になっていただくと、オートウェアの、自社への、適用の事例として、多い、参考になるのかな、と思っております。オートウェアを、ご自身が持つ、車両へと、インテグレーションをするための、手順に関しましては、オートウェアドキュメンテーションという、ホームページで、詳細に説明しております。こちらは、オートウェアの入力となる、センサー情報や、出力となる、制御情報を、オートウェアの設計に合わせて、接続できるようにする、仕組みについて、紹介しております。今回は、ノバカーターを例に、その実装方法について、詳しく説明していきます。まず、車両モデルへの、適用方法なんですけども、こちらでは、車両の、制御入力に合うように、オートウェアが出力する、制御コマンドを、変換していきます。例えば、ノバカーターは、いわゆる、自立移動ロボットのように、作動二軸の、車なんですけども、自動車などは、ステアリングと、アクセルブレーキで、制御する仕組みですので、その、制御メカニズムが、大きく異なります。そういったものを、汎用的に、扱えるようにするために、この、車両モデルを、定義します。さらに、車の大きさによっても、動作計画は、変わってきますので、車両の、気価格的な情報、例えば、どこに原点がある、車のサイズは、どれくらいだ、という情報も、設定する必要があります。実際に、ノバカーターの、車両モデルの、適用例なんですけども、こちらは、オートウェアノバカーター、インターフェースというパッケージで、オートウェアと、ノバカーターの、トピックサービスを、相互変換する、インターフェースを、提供しています。右の図で、ご覧になるように、ノバカーターから、オドメトリーの情報が、やられるんですけども、その情報を、インターフェースを、通して、オートウェアで必要となる、ベロシティレポート、ステアリングレポートに、変換します。そして、オートウェアからは、制御コマンドとして、コントロールが、コントロールトピックが、投げられるんですが、それも、ノバカーターインターフェースを、通して、ノバカーター、作動二軸の、車の制御に合うように、ツイストトピックに、変換しております。もう一つ、ノバカーター自体の、起動スクリプトを、合わせて、蒸気変換ノードと、合わせて、オートウェア、ノバカーター、ヴィークルパッケージで、起動を行います。このとき、オートウェア、ノバカーター、ディスクリプションという、パッケージで、さらに、オートウェアの制御パラメータを、少し調整する、仕組みも、取り入れております。次に、オートウェアへの、センサーモデルの適用を、ノバカーターを、事例にして、紹介いたします。こちらは、例えば、ライダー、IMU、カメラ、GNSSのような、センサー種別ごとの、取り付け位置、計測範囲、分解の、視野角、取得周期などを、定期する、ための、場所です。特に、ライダーや、IMU、カメラなどは、補正の仕組みも、提供していますし、フィルタリング、例えば、クロックしたり、あとは、アウトライヤーを、除去したり、という部分も、フィルターとして、提供しておりますので、それを使うことで、容易に、オートウェアに、統合していくことが、可能です。実際、ノバカーターから、オートウェアへの、センサー、入力の変換は、このように、行っておりまして、オートウェアの、バックアーターセンシングで、ネビュラという、TFOが作っている、汎用のライダードライバー、いろんな、ライダーのメーカーが、あると思うんですけども、それらを、汎用的に扱えるような、ドライバーを、提供しておりまして、それを使うと、パス3Dライダーを、オートウェアで、統一的に扱いやすくする、形式に、変換することが、可能です。これによって、右の図では、ポイントクラウド2に、変換して、オートウェアに投げています。そして、オートウェアの、バックアーター、オキパンシーグリッド、パッケージを使って、NVIDIAから、提供されている、アイザック・クロス・ビシャド・スラムから、必要な機能、例えば、ステレオマッチング、フィルタリング、そして、3次元構成の、パッケージのみを、抽出して、さらに、パッケージの、パラメータを調整して、起動する仕組みを、提供しております。続いて、実際に、オートウェアを、パッケージを、コーディングした様子を、見ていきましょう。まずは、3Dライダーを使った、オドメトリーで、オートウェアを、起こした様子です。こちらは、まず、事故位置推定を、行いまして、カフェの、とあるうちに、ノバカーターを、セットアップする。そこから、次に、目標位置を、設定して、経路が、自動的に、計算されます。ここから、ノバカーターは、オートウェアの、プランニングと、コントロールに従って、動き始めます。走行場所は、最初の方でも、説明しましたが、ヘアホーの、品川オフィスの、カフェエリアを、使っておりまして、障害物の代わり、といったなんですが、椅子や、机が、経路に、存在いたします。これを使って、8の字に、ロボットが、動いております。実際に、障害物が、認識されると、後ろの、人もそうなんですけども、ちゃんと、それを、認識している様子も、見ておれますし、もし、前方に出てきたら、それを回避するような、動きも、設定されます。次に、今回の本題である、アイザークロス、ビジュアルスラムを使った、ビジョンバージョンでの、オートや、走行実験について、ご覧になっていただきます。こちらは、ビジョンバージョンにより、事故位置推定と、地図作成を同時に、実行している様子が、見て取れます。ライダーの天群も、同じように映っているんですけども、今回は、こちらが、メインではなくてですね、ロボットの下にですね、二次元の、白と黒の地図が、できていく様子が、見れると思いますが、こちらが、アイザークロス、ビジュアルスラムによって、専用格子地図を、時々刻々、作っている様子になります。これによって、動的障害物を認識したり、人や、人を避けて、動いたりすることが、可能です。ただし、ビジュアルスラムを使うと、どうしても、スラムを安定化させるために、先ほどのライダーの動きに比べて、低速での移動が、必要となっている点は、少しご了承ください。また、ちょっと、実装時間の、制約もありまして、残念ながら、ビジュアルオドメトリーを、オートウェアに、統合することは、間に合っておりませんで、オドメトリーに関しては、先ほどお見せした、ライダースラムの、ライダーロカリゼーションの、情報を使っております。少し、追加の実験も、いたしまして、実写の実験だけじゃなくて、アイネーミディアが提供している、アイザックシムを使って、オートウェア速攻実験できないか、ということも、トライしてみました。こちらは、ロボティクスシミュレーター、アイザックシムを使っておりまして、オートウェアの、走行実験ができることが、確認できました。現実に近い、品質の、3次元、天群、ポイントクラウドや、カメラ画像を、取得することができますし、IMUも、分かりますので、しかも、アイザックロスの、パッケージのおかげで、全ての、センサー情報が、ロスのインターフェースで、取得可能ですので、このように、ローカライゼーションしたり、将来的には、プラニングに応用したり、ということも、可能であることが、分かりました。今後の展開なんですけれども、今回は、開発時間が、実質1ヶ月ということで、全てやりきることは、どうしても、難しかったんですけれども、まずは、アイザックパーセプターや、ノバカーターに関しては、ステレオマッチングの、推論のところが、やっぱり、改善が必要で、どうしても、今、床面近くの、障害物を見てしまうと、誤った障害物が、出てしまう、っていう、不害もありますので、そこの部分を、性能改善していきたいな、っていうのと、ステレオカメラが、今、3個、前と、左右の3個を使っているんですけれども、さらに、背面も含む、4個のステレオカメラを使って、専用コシスティズを作る、ってところにも、トライしていきたいな、と思っておりますし、音やインテグレーションの方に、関しましても、まだまだ、開発段階でありますが、より、リードミニア、ドキュメンテーション、充実していき、ビジョンのビデオ、大手屋、ちゃんと動くように、っていうところ、大手屋自体の設計改善も、必要なのかな、と思っております。これまで、どうしても、3Dライターを、通信とした設計になっている部分を、ビジョンでも、親和性高く動かせるように、していきたいと思っております。そして、最後、ISACSIMで、実験を行ったんですけども、シミュレーション環境は、既存の、最初のサンプルを使っているので、それを、ちゃんとオリジナルものを用意して、走行実験できるのか、ってのはやっていきたいし、ぜひ、屋外でも、実験していきたいな、と感じております。以上をもちまして、ISACSIMと、大手話を組み合わせた、ノバカーターの自動運転の講演を、終わります。ご静聴ありがとうございました。ご視聴ありがとうございました。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。チャンネル登録をお願いいたします。 wouldn't抖 know what lまずはinoff beings Oroneessen Andrews si abundan dis分け,チャンネル登録をお願いいたします。買ったようにお願いいたします。まず、チャンネル登録をお願いいたします。