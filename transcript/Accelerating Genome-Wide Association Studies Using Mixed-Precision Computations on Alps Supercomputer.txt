 Toyota Toyota Gladys Here Johnny It is The Thank you. Thank you. Hi, hello. I am Rababna Omari, a postdoc at MIT, and I'm excited to share this talk with you today. Joining me is Hazem from the Extreme Computing Research Center at KAUST. Together, we will be presenting our talk titled Accelerating Genome-Wide Association Studies Using Mixed Precision Computations on AOP Supercomputer. We are actually a team of 10 from NVIDIA, KAUST, St. Louis University, and MIT. Our team includes two genomicists, highlighted in red, while the rest of us come from computational and computer science backgrounds. While this session is pre-recorded, the whole team will be available to answer your questions. So, feel free to engage in the chat. We structure our talk around the three A's. Application, where we focus on predicting genetic predisposition to diseases. Incorporating advances in modeling the interaction of multiple genetic variation, which is the epistatic effect. Our approach scales up to 300k real patients and 13 million synthetic patients. Algorithm. We employ adaptive precision algorithm, balancing computational efficiency with accuracy tuning. And our approach utilizes up to five data types, including four floating point precision. The third A is architecture. We brought our development to four of the world top 10 supercomputers. Leveraging FP8 and Integer 8 tensor cores to achieve 1.8 exaops on Grace Hopper GH200 superchips. Genome-wide association study, or GWAS, is a genotype to phenotype mapping. GWAS takes as input a training population. Those members have been DNA sequenced and characterized by environmental factors, which represent the genotype. With the known diseases and traits, which is the phenotype. GWAS is able to predict the propensity to these diseases and traits in a test population, on the basis of its sequencing and environmental data. The quality of GWAS can be assessed by comparing the prediction against the actual. You can think of GWAS as a forward solve in an inverse problem, which is used to detect specific genetic variation relative to a reference genome responsible for a certain good or bad phenotypes. It is characterized by a Manhattan plot at the bottom. One plot for each phenotype, showing which location in the genotype are correlated to it. The first GWAS was conducted soon after the completion of the human reference genome. It had one phenotype, retinal macular degeneration, which is the leading cause of blindness. It surveyed 96 patients and probed at 116k genotypes. Seven years ago, the Gordon Bell Prize went to a GWAS calculation in opioid addiction in veterans, surveyed 882 patients, but looking at 28 million genotypes. You will see that the number of patients is the dimension of a kernel matrix to be factored, and the number of genotypes is an inner dimension of an inner product that goes into the formation of each matrix element. So, the 2018 GWAS covered potentially wide variation between a relatively small number of patients. Our study compromises 300k patients over 43k genotypes, and looks at five diseases phenotypes. We have extended it to 13 million patients, enough to fill up the memory available for our data sparse implementation. Our next GWAS target is a bred wheat, which is the source of 19% of human nutrition, and subject to numerous climate diseases. Wheat is an interesting target because its DNA is five times more complex than human DNA, hence stressing once again the inner dimension of the algorithm. Here, just to define some terms to which we will refer in our talk. I'll just mention single nucleotide polymorphism, or SNAPS, which is the substitution of nucleotide, such as an amino acid, at a specific location in the genome. MSPE is simply the mean square prediction error of a phenotype over the test population. The first correlation coefficient is a measure of the covariance of two variables, which ranges between minus one and one, with the positive values indicating a correlation, negative, anti-correlation, and zero, no correlation. The main significance of this work, apart from the performance achieved through low precision tensor cores in today's GPU, is its multivariate feature, which gives the ability to take into account interactions between multiple SNAPs. Since a phenotype may depend upon one gene expression triggering another. This is a recent development that applies a kernel technique to standard regurgitation. This approach maps the data to a higher dimensional space where associations will be clearer. You might be familiar with the kernel method embedded in support vector machines. For example, in 2D, there is no planar cut that separates the red and the green points. When lifted up to a third dimension by expantiating the negative of a distance from the center, a cutting plane appears. Our highlights include leveraging four generations of GPUs, using integer eight tensor cores for genotype distance calculations, exploiting data sparsity in dense kernel matrices to enhance efficiency, expanding population sizes into the million, far beyond what's the current state-of-art GWAS software regime can handle. This expansion is a direct response to rapidly declining cost of DNA sequencing. We point out that the future market for the 13 million patients GWAS could include 104 of the world's countries. Those entire populations could be sequenced. The genomes of the majority of these under-resourced populations have never been entered into European or American medical studies. The attributes that we present are large populations, scalability and performance of a recently developed kernel form of GWAS on the full pipeline, exploitation of low precision tensor cores with quantifiable trade-offs in accuracy, portability to multiple supercomputers with different generations of processors, delivering 1.8 X-Ops. These are the software computers that we run on. Science run using encrypted data on our own machine. Scaling runs for the compute-intensive anonymized linear algebra phase across many systems. And a full pipeline runs using synthetic data on Alps, separately studying the scalability of the two compute-intensive phases of the pipeline, as we will see later. We use by now conventional tile-based linear algebra based on task graph for the compute-intensive association phase. Our algorithm signature is the ability to convert the data types on a tile-by-tile basis to optimize precision for both computation and message passing. This data-sparse dense linear algebra approach has powered our last three Gordon-Pill finalist submissions since 2022. A combination of low precision for small magnitude blocks, those trialing mantissa do not affect the computation when combined with large magnitude blocks, the data types of data types of data types of data types of data types of data types. And low-ranked decompositions for smooth blocks, effectively balancing accuracy and efficiency. The data types of data types of data types of data types of data types of data types is the master of ceremonies to maximize concurrency and redistribute imbalance load from the algorithm adaptivity. It consumes a task graph at a node those data dependencies are satisfied, and batches tile off to distributed shared memory nodes. It's a very important thing to know that the data types of data types of data types of data types of data types of data types of data types of data types. As you can see between the blue and the yellow bars of the black well on the right. If you go back to FP64 and Volta, this shows a three order of magnitude rate increase in seven years, but only if you can follow the precision downward where they surface for AI. The good news is that for many problems, including GWAS, you can. Okay, let's get into the algorithm. As we mentioned, the standard GWAS model involves a large number of SNPs relative to the number of samples. And this high-dimensional data poses challenges, including multicollinearity and an increased risk of overfitting. Richard Grishin can address these challenges by introducing a binary term that shrink the effect sizes of the SNPs. The model is a large number of samples, making the model more stable and robust. It's implemented as well in Regene, which is a widely used software tool for GWAS. This is the objective function of Richard Grishin, and this is its closed-form solution, which can be translated into solving a system of linear equations with a large dense-patient SNP matrix. The computation here involves symmetric rank k update, adding regularization, matrix multiplication to compute the right-hand side, followed by Chalice-Key-based solver. Kernel ridge regression further extends ridge regression by using a kernel method to model complex nonlinear relationship among SNPs and between SNPs and the trait. This is the objective function of kernel ridge regression, and this is its closed-form solution, which can as well be translated into solving system of linear equation. Here we need to build Gaussian RPF kernel using similarity measures between individuals, and as well we need to add regularization, to install the system using a Chalice-based solver, which we call it here association phase. In the genotype matrix, the SNP can be represented by integer values 0, 1, or 2, as the green tiles here, followed by a few columns of co-founder data, as the purple tiles, which is stored in a single precision. So, this multi-precision nature of GWAS encoded dataset allows to effectively utilize hardware features, for instance, NVIDIA tensor core. In ridge regression, the first step involves computing the covariance matrix using plus 3 operation, specifically CERC. The algorithm called mixed precision gem for tiles containing integer genotype data, and single precision gem for tiles containing floating-point co-founder data. The resulting symmetric matrix can then be factorized using Chalice-key decomposition after adding the regularization term. Chalice-key factorization is the most time-consuming step here. This decomposition can be performed in a full precision, or using banded mixed precision approach, which assigns different precision to each tile following Nick-Hayam formulation. In which if the Furbinian's norm of a tile is sufficiently small compared to the scaled and normalized Furbinian's norm of the entire matrix, then the tile can be computed in a lower precision, without compromising the overall accuracy. The kernel regression algorithm can be divided into three main phases. Build phase, associate phase, and predict phase. Hatem will go into the details of these three phases. Thank you, Rabeb, for introducing the three-phase kernel regression methodology. The first phase is the build phase. The next phase is the take-by-phase additions. The first phase is the build phase. This is rather slow as an approach, and we have to do something about it. Out of that matrix, we can then exponentiate every entry, and this is how we get the covariance matrix. In terms of precision, we use multiple, integer 8 when we deal with those integer entries of the matrix, FP16 or FP8 depending on the underlying hardware architecture, and FP64 and FP32 to deal with those entries that are non-integer. The second phase, the associate phase, performs adaptive mix precision initially, where we identify in a tile-centric way which precision should we use for each of those tiles. We can then execute the Cholesky-based solver against a list of phenotypes. We eventually solve the problem and get the weights that are also coefficient of the mapping from the kernel matrix into the phenotypes. The third phase, the predict phase, this is where we have to perform inference. We are able to bring a new cohort as testing datasets, and we rely on the build phase to calculate the interactions between those new datasets and the training datasets we used initially, and we are able then to determine the likelihood for each of those patients to develop this and that phenotypes. So, this is how we surf the AI wave with low precision arithmetic in the context of GWAS. We first look at precision assessment after constructing the kernel matrix for a real dataset comprising more than 300k patients and 43k genotypes. And if you have an A100 in your backend, well, you can activate FP16, and it turns out that our matrix, kernel-ridge-regression matrix, is resilient to that. Well, if you have GH200, you can even activate FP8. So, it turns out that this GWAS application, by nature, really can exploit low precision arithmetic. So, if we look at the impact of low precision on the mean square prediction error for kernel-ridge-regression versus ridge-regression for the asthma phenotype, well, this is the MSP we get. So, the lower, the better. That's when we do everything in single precision. But then when we introduce, you know, half precision, we see that the MSP does not really get lower for ridge regression. We are able even to have this adaptive procedure where we decide on a tile basis which precision we should use. And yet there, we are able to maintain a similar MSP, although we are much more productive now with this adaptive ridge regression for mixed precision. When we introduce kernel ridge regression instead, we are able really to lower, you know, the MSP. So, that is something really interesting and that was, in fact, the goal for us to study kernel-ridge-regression versus ridge-regression. We further augment our qualitative assessment by looking at the Pearson correlation between the ground-truth phenotypes of the testing dataset of the UK Biobank patients and the predictions under the ridge regression and the kernel-ridge-regression models. For the same FP16 precision, the kernel-ridge-regression results are more highly correlated with the ground-truth than ridge regression, up to four times more, thus demonstrating its capability to model more complex phenotype relationships. Here, we evaluate the accuracy of ridge regression and kernel-ridge-regression using synthetic datasets generated by MS' a tool for simulating genetic data. We generated four synthetic datasets. We showed the MSP for adaptive ridge regression combining FP32 and FP16. Then adaptive kernel ridge regression with FP32 and FP16 as well. And finally, adaptive kernel-ridge-regression with FP32 and FP8. The results emphasize the previous finding that kernel-ridge-regression demonstrates superior predictive performance compared to ridge-regression across all synthetic datasets. Kernel-ridge-regression outperform ridge-regression in terms of Pearson correlations as well, with the FP32 and FP16 configuration showing the highest correlation. When using kernel-ridge-regression with FP8, the Pearson correlation and prediction is slightly sacrificed. However, this demonstrates that FP8 precision offers a favorable trade-off between accuracy and computational efficiency, making it a promising approach for large-scale genomic studies. So let's revisit the build phase, which is the workhorse of kernel-ridge-regression. It has the Euclidean distance calculation, which account for most of the elapsed time. It relies on scalar operations and operates on two data types, the integer as well as the floating-point 32-bit entries. So can we accelerate it on tensor cores? There are some prior work on this front, using double precision for general matrix. So we leverage that existing work and apply it for mixed precision for symmetric matrix instead. So let's look at the tensor core accelerated distance calculations. We expand the squared Euclidean distance. And to better understand how we do this, you know, we have first to consider three patients, A, B, C, and two traits. So each of those squared terms, we make them appear by looking at the square of each of those patients' traits. We do that for patient A, B, and C. So then we can calculate half of all pair distances by leveraging the symmetry of the operator, saving in memory and obviously in time to solution. So we then matrixize that operator and generate it on the fly. And that's where we can see then the cross term showing up. And basically, it turns out that we could map this tensor core accelerated distance calculation into a tile-centric mixed precision level 3 BLAS function called symmetric RUNK update or CIRC. So we can also see that the other side of the system is going to be able to do that. We also run on diverse resources to demonstrate software portability. On Summit from ORNL with NVIDIA V100. On Leonardo from Chineca with NVIDIA A100. On Alps from CSCS with NVIDIA GH200. We also run on Frontier ORNL with AMD MI250X. All of the sciences we run it on Shein 3 and IBEX. Those are systems at Kaust. We host at Kaust. We also had early access to a system called Fromage from NVIDIA. It was an excellent tasty system from which we could run our preliminary experiment. Let's look at the performance breakdown of the build phase on Alps. We run on 256 GPUs all the way up to 4096. GH200 on matrix size starting from 2.6 million all the way up to 10.4 million. We achieve the performance speed up to 12x and this is 75% parallel efficiency. Let's look at the associate phase on Summit V100 GPUs moving from 256 all the way up to 1000 nodes. We can see the huge advantage of enabling FP16 calculation reaching 5x all the way to 6x performance speed up compared to running double precision only. On Leonardo with A100 we can see a performance boost between 64-bit FP32 and half precision around 3.5x performance speed up as we increase the matrix size and the number of nodes all the way to 1000 nodes of Leonardo A100 GPUs. This is approximately 50% performance higher compared to Summit V100 GPUs. On Alps, we also ran all the way up to 1000 nodes of those GH200 and we can see huge performance speed up by now integrating FP8 calculation enabled by those hardware feature tensor cores that support you know, FP8. We get up to 5x, 5.6x sometimes performance speed up compared to when you run FP32 only. This brings dramatic performance speed up, you know, to computation that would otherwise run in FP32 only. This is the associate phase looking at V100 from Summit, you know, A100 from Leonardo and GH200 with FP8 on Alps. The performance boost is tremendous, so 50% as I mentioned between Leonardo between Summit and Leonardo and a factor more than three between Alps and Leonardo. We are looking at the performance scalability for the associate phase and we normalize the performance per GPU for the weak and strong scalability executed on Leonardo supercomputer. So as we increase the number of GPU and the matrix size for weak scalability, we achieve almost a perfect scalability. When we look at the strong scalability, we observe a performance drop. This is mostly because we are not able to saturate anymore the GPUs given the low precision, you know, arithmetic which achieve a high throughput. So we spend most of our time actually feeding those GPUs via the network and moving the data around. So when we look at the performance scalability now on Alps for the associate phase, again, we normalize the performance per GPU. We observe again a perfect weak scalability and when it comes to strong scalability, we see the same pattern that we observed for Leonardo where we are not able to saturate anymore the GPUs as we strong scale and we become mostly network bound and, you know, limited by the bandwidth of the network to move data from one GPU or one node to another one. Nevertheless, we achieve 3x performance compared to Leonardo here by engaging FP8 from apps. So now let's look at the large scale kernel ridge regression based multivariate GWAS. So the overall workflow which has the build and associate, those are the breakdown, and we look at the overall performance now with the kernel ridge regression on 1000 nodes of Alps and almost double of that on Alps again. And we reach, you know, for a matrix size of 11 million more than 1.8 exaops for the build, almost 900 petaflops for the associate, and all in all, we're getting 1.4, 1.5, you know, exaop when we combine both stages in a single workflow. So now we perform our hero run where we compare Alps versus Frontier, Leonardo, Summit. So we look at the associate phase where we could run it on systems we had access to, and we also look at the performance, the maximum performance we could achieve on this number of patients, a matrix size 13 million, and with the number of SNPs 20 million. We achieve in terms of the performance of the associate phase more than 1 exa flop on Alps, which is higher than Frontier, Summit and Leonardo, on various number of GPUs. And this is quite impressive and significant in particular, when you see the number of GPUs involved on Frontier, Supercomputer and Alps almost, you know, a little bit more than full time and the number of GPUs. So that already give a good dimension of the performance throughput that GH200 bringing on the table. And when you look at the performance of the overall workflow, the kernel region regression, we achieve more than 1.8 exaop on Alps. So that's five order of magnitude, you know, faster than the state-of-the-art CPU-only region-y software. So as a summary and implications, we develop a capability software tool that performs a multivariate GWAS to detect complex epistasis using kernel ridge regression. We cast distance calculations to 10 circles for the Gram matrix. We accelerate computation using mixed precision and leverage the new FP8. We demonstrate accuracy superiority of kernel ridge regression over ridge regression. We achieve 1.8 exaops on Alps with 13 million patients. Moving forward, we want to leverage the spatial locality from the 3D genome of atomic contact maps. We improve the detection of combined effects from complex threats. And exploit data sparsity using low rank matrix approximation. This is our motto, do linear algebra, see the world. Thank you so much for listening and we are happy to answer any questions. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.