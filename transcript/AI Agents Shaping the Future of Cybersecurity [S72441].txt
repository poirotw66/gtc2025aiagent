 Wow. Look at this turnout. I am just so incredibly humbled to see so many people here turning out for this session. We are here before Jensen's keynote, and therefore I might get the honor of welcoming you all to GTC. It's an amazing time to be witnessing the AI revolution, and so I'm really excited to welcome you all here. I'd also like to thank our events team who moved this panel twice because of the demand. It was so great. It kept getting over capacity, and so now we're here. This demand speaks to the maturity of the technology. Last year we had this panel, and it was all about generative AI, and companies were just experimenting with AI and what it could do for their enterprises. This year we have real adoption to speak of, and so that's really thanks to the advancement in reasoning capabilities brought forth by Agentec AI. So before we start, I would like to level set this audience in terms of what Agentec AI is. I know by the end of this conference, everyone will be experts in Agentec AI, but for the high-level business leaders in the room, this may be the first time that you're hearing about it, and so I am going to take an example from Andrew Ng, who shares what is an explanation of Agentec AI that I really liked. So AI that you've seen today is, you know, ChatTTP is a very popular one that everyone uses. That is using zero-shot prompting, and what this is equivalent to is asking someone to write an essay from start to finish without ever using the backspace. It's pretty good, but it's not perfect, and what we find is that if we apply an Agentec workflow, we're allowing more iterative process and dynamic, and we break down the task into multiple steps, allowing for an AI, in the example of an essay, to create an outline, to plan, to research, to draft, to revise, you get a much better output. And so there's a benchmark called human-evalued coding, and it shows that you can actually take an older model, apply Agentec workflow, and you'll get actually better, higher accuracy than using the latest model. This performance improvement speaks volumes to the technique, which is absolutely critical for enterprises to adopt AI, right? And so I would like to actually set the stage in terms of some statistics in this AI adoption. Gardner has a research out that says that in 2018, 2028, which is only three years from now, this research was out in 2024, but one-third of enterprise software applications will include Agentec AI. That's an increase from 1% last year. One-third. Next statistics is AI agent machine customers will replace 20% of interactions with human-readable digital storefronts. So anyone here who has connected cars, you know, a smart refrigerator, all of that will be automated through AI agent systems, right? You can get your tune-up, your replenished supplies, anybody who's using Alexa or Google Home. You're going to see that those interactions are now going to be automated. And then for any of us here who have white-collar jobs, we will see 15% of our day-to-day interactions, decisions being made automatically. So we may wake up in the morning and a lot of decisions are already made. And this is because we're able to improve situational awareness, which as humans, we're not able to understand all the constraints of our company as an agent would be able to. And so it's clear that we can produce amazing results with AI, but with such a powerful tool for use of good, there's also bad actors out there that are able to leverage exactly the same tools. And that leads me to welcome our panelists here who are always thinking about protecting enterprises from cybersecurity threats and to make sure that we're all always thinking one step ahead of the adversary. So I'm excited to hear a broad range of perspectives from, you know, AI solutions to AI infrastructure to how the workforce is adopting AI. And so I'm at the forefront of the AI revolution. We have Rachel from Trend Micro, Alon from Wiz, and Susan from Siemens Energy. I'd love to start with Rachel. Would you please introduce yourself and your area of research and expertise? Yeah, sure. Hello, everyone. And my name is Rachel Jing. I'm Chief Enterprise Platform. I'm Chief Enterprise Officer at Trump Micro. I'm living in Dallas, Texas, and I've been with Trump Micro for 16 years already. And it's been a great journey and amazing experience to work at Trump Micro, a company that's been in cybersecurity game for over 35 years already. And we serve more than 500,000 customers in the globe. And I head up our enterprise product management group, which means that I have the opportunity to work with all the people all over the world, America, Asia, and Europe, and everywhere. And my job is to work with our executive team and talented people. And together, we form up the strategies and innovation ideas. And we also turn all the ideas to solutions and products to protect our customers. And today, I'm super excited to be here and talking with all of you and share some thoughts and also hear what's on your mind. And thank you for having me today. Thank you, Rachel. Alon, please. So, hi. My name is Alon Schindel. I'm the VP of AI and Threat Research at Wiz. I've been with Wiz for the past four years. Wiz is a cloud security company. We protect more than 50% of the Fortune 100 companies. And for my role at Wiz, I joined Wiz. Wiz is only five years old. So, I joined Wiz when it was a significantly smaller company, started a research team. And we could have seen the AI journey during this period. If you think that the chat GPT was released only a bit more than two years ago, you can think about this amazing LLM revolution that we are seeing. And a major part of it is happening in the cloud. And we see a lot of similarities between how cloud started and how cloud was adopted to how AI is being adopted. And the focus of my team is the research for both the cybersecurity perspective, the risks of AI, of the usage of AI, and also research how we can use AI for security. So, we have both of these perspectives. And we are trying to help and learn with our customers as this revolution is happening, how we can do more with AI to protect them, but also what are the risks that the use of AI can pose to organizations that are using it. Thank you. Susan? I am Susan Farrell. I'm VP and Global Head of Grid Cybersecurity for Siemens Energy. I recently joined Siemens Energy about 10 months ago with a focus on a brand new startup within the organization, and that is to really focus on the safety, resiliency, and availability of our grid. As companies are transforming, the grid operators transforming from brownfield to greenfield. And it's really interesting what we're doing as part of that is building digital twins that represent the assets, that represent the whole grid environment. And, yeah, I'm really interested in sharing our journey in doing that. Thank you. So, my first question is for Rachel. I know as a cybersecurity company, your customers cut across all industries. Are there any industries in particular that you find to be most receptive to AI adoption? Thank you for the question. We do have a lot of customers. They are in different industries, and we see AI really, really shaking things up in multiple industries. And, firstly, let's talk about healthcare. And I think healthcare really gets a lot of benefits coming from AI. And AI is helping healthcare to transform and their, you know, how they approach the digital or the personalized treatments and the diagnostics. And also for the patients. And they can look up information now very easily using natural language search. And for the healthcare workers, they get assistance from, you know, the AI-powered, like, AI-powered system. And they can do the auto insurance form. And these are all benefits to the healthcare. And also, I think AI really helps them kind of you just focus on the patients because all the paperwork. I can help you. AI can get through all the papers and identify, you know, the new ideas and identify what kind of compounds are the best, you know, are the best for the patients. And also, we have a lot of finance customers as well in the finance. And this is really thanks to generative AI and the large language model. And they made, you know, their daily operations easier. And several use cases, typical use cases we hear from finance customers is they use AI to identify the fraud and manage their risk and also improve their customer service process. And I got some chance that two weeks ago in Seattle, I talked, I was in AI forum, that's a conference. And when we were doing workshop and I were in a table with all the finance leaders in different countries. And one of the common things I hear from everyone is AI is really helping them and everyone is investing on that. And they are building their LLM model. And also, everyone talked about, oh, I'm working a lot on, you know, how to aggregate the data, clean up the data, because we all know AI is a data problem. And so, they also utilize AI to help their internal operations. And some people say, I feel this AI can equal to 50 people already. Yeah. But there's one interesting thing is there's one challenge. Almost every finance leader say, one, it goes to expand the AI usage to external users. And they feel the kind of hold on there because we know sometimes AI could be unpredictable. Sometimes, you know, AI result is not consistent. And we all know that if there's one mistake in financial area, it could be big loss. So, they kind of start still thinking about how to roll out externally. So far, they feel, oh, I still need to wait. But at the end, almost every financial leader say, if you're looking at how fast AI is improving, they believe eventually we will get there. So, that's the financial. We have a lot of transportation customers. They do trains. They do planes. They use a lot of AI. And they use AI for their, like, route planning and also do some predictive maintenance and also do some, like, customer service and, like, pricing comparison. And one of our trained customers told us that they adopted 35 AI applications for their internal and external stuff. And what does it mean? It means AI is kind of, they already highly, highly utilize that already. And the last industry I think I want to talk about is the federal government. Yeah. And the federal government, we hear more and more AI usage. And the federal government is definitely one of the, you know, biggest users for AI today. And also, we see very, a little bit dynamic. And also, it's a very interesting time. And some government departments, they are okay with the public cloud. But we see more and more countries and more and more federal government customers. They ask for sovereign AI. They ask for private cloud. Even they ask for, I want to run everything in my isolated environment. And there's several questions that I pretty often hear about. And I also found these questions are also coming from other industries as well. And it's kind of, where is your AI? Are they safe? What are your security measures? Yeah. So, Rachel, that's exactly what we're faced with at Siemens Energy as well, right? You look at a highly regulated industry like the electric sector, right? That's right. So, where do you utilize AI to benefit, you know, the safety, the resiliency and availability aspects? So, that's actually a year ago when I was listening to the NVIDIA GTC online. I learned about the Morpheus. Yeah. And it was really something that was kind of interesting to me in the fact that they were actually, you developed it to utilize internally. So, NVIDIA created Morpheus for the DevSecOps of NVIDIA digital twins. So, I found that really, really fascinating. As a company, we're really encouraged to utilize AI anywhere we can. So, if we can utilize it from a DevSecOps perspective, that might be a good foundation to utilize it then for customer implementation. Yeah. I think you found the same thing in the finance too, right? Yeah. Yeah. So, go ahead, NVIDIA. I just say, Chau will be very happy because you talk about Morpheus because Chau is program manager for Morpheus. And we also do a lot of Morpheus for our anomaly detections. Yeah, go ahead. Yeah. I didn't ask them to say that. But, Alon, I know that, you know, speaking of finance, industry adopting AI, I know that that's probably one of your larger areas of adoption in the cloud. Can you speak a little bit about how they're using AI? Because I think that's very regulated. Yeah. So, what we see, yes. Most of the visibility that we have is to cloud, to the newer parts of the infrastructure of a large enterprise. And what we see there, we had a survey this January, and we saw that 85% of our customers already use AI technology. And I know that AI existed before LLM, but, like, we've seen in the past two years a significant increase in the adoption. And when we see this adoption, we have to think about the different categories. So, for one category is, like, more the experimentation. And this is the stage where we saw most companies a year, a year and a half ago just, you know, you see single instances of either AI models or AI services in their environments. You see some more, and you see, like, on the other side, the more advanced use cases where you can actually see that AI is being used in production for these teams. And so, if we're asking whether, you know, the hype around AI is real, so, yeah, I mean, it's not hype. I mean, we actually see AI everywhere. And from, actually, the DevSecOps side, it's interesting because this is an area where you see the adoption of the new technology, but you can also see the challenges where these, like, new teams have now to understand how to use the new technology. They haven't used it before. And there are new teams that actually deploy code to production environments. So, the AI engineering teams, data science teams, they become significant part of the production environments of customers. And when this happens, we need to ask, like, two questions. Whether the security teams know how to protect all these new type of models, whether they know what are the risks. And from the other side, whether the AI engineer, data scientist, like, all these new teams that are now under pressure to deploy more and more AI capabilities, as Rachel said before, like, everyone wants to use it wherever they can. Whether they understand the risks when they now deploy a new model to their environment, whether they understand what does it mean that they might expose the data. If they don't protect their training data properly, they might expose the data. And we have seen most of the risks, the AI risks that we've seen around are risks that are not actually about the AI. It's not like a new AI vulnerability, nothing too fancy. It's just exposure of data that, I mean, it's a risk that we already know. And we have also seen supply chain issues, whether you have a new model in your environment, whether you know where this model is coming from, have you scanned this model to understand if there is any maybe backdoor in it. So, like, all of these risks that we already know from, like, you know, traditional security, cloud security, now apply to a new domain. And, like, what I see is that, like, the kind of, yeah, the work, the collaboration between the AI teams and the security teams is the key to make sure that AI adoption can happen fast, but also securely. Yeah. We actually found out that by just running continuous integration and continuous development on committed code, right, for the digital twins, that it revealed a lot of vulnerabilities that were not discovered in your traditional software composition analysis tools. And it was faster. So, if you can create an automated software bill of materials, if you can do continuous integration development, all of a sudden now you have much faster adoption. It's like, wow, that happened so quickly. It is definitely an interest of ours to do secure by design. So, that means that what we build for commercial, for deployment, is something that can be used holistically as well. If you look at the digital twin for being used not only for asset, for mechanical asset integrity, but also for cybersecurity, right, now you get a better picture of what, in our case, the entire grid operation looks like. And, of course, you have a lot of things connected to the grid. You have the new AI data centers. You have large industrial cybersecurity users. So, it does give you a much more secure environment. From an AI perspective, we see that as better insights. And since you're able to do it on-prem, as well as hybrid and cloud, you can test firmware updates. You can test different new deployments of assets to an environment before it goes to production, which you can't do in an industrial environment. You can't do pen testing in an active production environment, but you can do it in a digital twin. And so, that's exactly what we're focused on. I was really excited to have Susan on this panel because Siemens Energy is one of the early adopters of AI technology and seeing how it's being leveraged in the workforce. And I was really excited to hear that even though oftentimes we think about AI technology as a little bit of an aversion to it, right? Skepticism, at least. Yet, your team has strong excitement around advancement. And I would love to hear some of the factors that contributed to this positive reception. So, you know, it all starts with executive championship. Our CEO, Christian Birch, I'm in grid technology, so that's Tim Holt. I'm in digital grid, that's Anand Chautry. Everywhere you go, there is an enthusiasm to adopt AI. It's like, how can you use it? What can you use it? Push it. We're installing an AI lab in Florida, in Orlando, to test not only how we can improve our own operational excellence, but also, you know, how can we benefit our customers? So, it's really exciting. You're just constantly encouraged. We also rolled out an internal innovation tool called Orbit. And all employees, no matter what your role is, you're encouraged to submit ideas. How do you use AI? How do you use different technologies to benefit the industry? I also found the same thing with us. I mean, when, you know, any new model comes out, we are always trying to test it out internally. And people love trying to replace their own jobs, right? They just see how much more productive they can be. And it's really incredible, the results that they've seen. So, I'm glad to hear that even in the OT space, you're seeing the same thing. Rachel, you mentioned sovereign AI. And I would love for you to use this opportunity to educate us on what sovereign AI is, because I think it's a term that we've heard a lot. And I think it's also coming from a wide adoption in government agencies. But would you take a moment to explain that to us here? Yeah, sure, sure. I think I can talk about, you know, what we see about sovereign AI and what cybersecurity can play a role there. And so, what we see is we see growing demand coming from our federal government customers. And not only from one country, not more and more countries. It's an interesting time. And they are asking for my data. My AI needs to be within the border. And that is how the AI and the digital sovereignty come out. And, but, you know, when it comes to, say, let's make sure all your AI projects to be successful and stay secure, cybersecurity is absolutely essential there. And I think cybersecurity matters for a bunch of reasons for sovereign AI. And the first is about, you know, cybersecurity can help all the AI projects to looking at protect them from the external threats. When I say external threats, it could be cyber attacks. It could be unauthorized access. It's super important for the sovereign AI project because they are handling all the sensitive information, all the classified information. And AI is about the data. And so, that's one. And the second, what we see is, you know, one customer say, federal government say, oh, I need to build the sovereign AI. And it's not just about, okay, you know, protect from all the attackers. It's also about how they can follow the local rules, the local standard. Because different countries, different regions, we all know they are kind of defined different ways. So, cybersecurity is also very important here to help our customers to understand their environment, make sure they are compliant. They are following the compliance requirement from their region, their, you know, their country. And thirdly, what I see is about, you know, we all know AI only as good as the data it's trained on. So, data is so important. And so, that's also why recently you hear more and more data security, data visibility is needed, right? And this is also something cybersecurity can play a key role here. Maybe you will agree with this as well. Yeah. And we need to show customer where the risk data is and where the data is and how the data is movement. And also looking at build the visibility and also help customer to understand, you know, if there's any, like, pampering to their model. Which means that hackers can, you know, they can mess AI algorithms. And then all the data become not trustworthy and all your AI result is not trustworthy. So, this is so related. And also, I think there's one, this is interesting time, I say, because I also see that cybersecurity needs to be very flexible in terms of deployment. Customer, you are in the public cloud, I'm there. Customer, you are in sovereign private cloud, I'm also there. Customer, you say, okay, I only can work in the isolated environment. That's okay. I can bring the full cybersecurity stack into your isolated environment depending on what you need. So, sovereign AI is real now. And it's kind of everyone spends a lot of money to build the AI data center and the GPU farm and how to make it secure, how to make it be within the border. And it's so hard to predict, you know, how the world is moving. But so far, what we see is the sovereign is really everywhere. Yeah. They need security as well. Do you see some countries further ahead in this than others? Are you able to? No. We already see some countries and Europe and Canada and, you know, different countries. Of course, in the U.S., we also have a lot of, you know, federal government-related server and private cloud project. We have a lot of projects there. And that's also why when they set up this server AI, actually, this is not just like one server or one machine thing. This is the whole ecosystem. And from our perspective, we do cybersecurity. We need to look at, you know, what your infrastructure looks like. And I need to protect your infrastructure. What your data looks like. I need to protect your data. And what your AI model looks like. I need to protect the model. And who are using your AI? And I need to protect the access. And so it's kind of about the different layers of protection. And it's not only like server. It's also endpoint. And even, you know, inside the environment. And how I can build the centralized visibility to see what happens there. Yeah. We have our work cut out for us, huh? That brings me to a question for Alon, right? Like, we've seen the adoption of AI. I don't know if it's equal or even higher than our adoption of cloud. Are there any lessons that you saw from cloud security that you're bringing over to AI security? Yeah. So it's a great question. It's great to continue, Rachel, with that. So first, yeah, when we see the adoption, I mentioned number four, that 85% of environments, they have AI. It's actually larger than Kubernetes. I mean, if you think Kubernetes, it's a technology. It's now it's part of almost any modern environment. And the adoption rate of Kubernetes is lower than the adoption rate of AI. So you can see how significant it becomes. And, yeah, I really believe that the first question that we should ask is about visibility. Most of the AI issues that we've seen, and I'll keep emphasizing, are more about, you know, the data. I mean, we saw a data leak. Our team, the research team at WIS, we found a data leak in Azure that was, like, part of the AI team. And they had the training data, 38 terabytes of training data that was accidentally exposed, and everyone could have accessed it. Luckily, we found it. We reported it to them and have them remediated. And we also found recently a similar example with DeepSeq. So a database that was used by the DeepSeq team was just left exposed. They exposed it, like, two hours, I think, only a few hours before we found it. And it shows, again, like, the problem with AI. AI is based on training data, on other, on cloud infrastructure. And if you make a single mistake there, you'll expose your whole environment. You let other people, yeah, I mean, change your data, influence your models, steal your training data, your sensitive training data, steal your customer data. So when you think about, if you need to think about a framework to how you secure AI, how you secure AI applications in your organization, how do you secure AI agent or agentic frameworks, you should first think about this level, about the visibility, whether I know where AI is in my organization, who uses AI, where is the data, can I model the whole AI pipeline from the training data to the actual model and fine-tuning jobs? Then you need to understand if you have, you can map the different risks to all of these components and prioritize the different risks. I think one of the main learnings from us from the journey to secure cloud environments is that it's not only about, you know, creating lists of all of these issues. You need to understand the context and you need to understand whether the training data contains sensitive data in it, whether you have some sensitive data that is being used to create a model or to fine-tune a specific model, whether this data is in maybe more sensitive environment, whether it's part of just a test environment, and then maybe the data is not really interesting, it's just open-source data that is being used, or whether it is more sensitive. And like when you have the context, you can prioritize the different risks to AI. And I believe that all of these, all of these principles apply both to cloud and to AI. And this is how you should start with AI and have one example from one of our large financial customers that when DeepSeq was released, DeepSeq R1 was released. First, like we saw that across our customer, it was adopted in really unbelievable pace. We saw it one week after the release of R1, we saw it in 7% of our customer environment. Like we saw the actual model, that they downloaded the model from Hug and Face and tried to use it, which is, I mean, you know, really unprecedented adoption of a new technology. But, you know, it's not something that was authorized by the different teams. I mean, just probably, you know, engineers, they wanted to try, experiment with that. But the security teams were not happy that, I mean, to learn that the model is being used so fast. And with this financial code, they just, they wanted to send who is using AI. And they found three instances of the model. And like they talked with the engineer and asked them, okay, can you please, you know, don't test it in a sensitive amount. We want to review the model before we know it. And here we are talking about, it's an actual supply chain issue. It's not about, I mean, there's nothing about AI. It's just about running code models, AI models are, you know, code. Like in the end, it's code. You need to make sure where the code in your environment is coming from. And that's it. So they saw that there are three instances. They wanted to stop the use before they actually review it. And I think that this is the whole story. It's like supply chain, data security, you know, all of this stuff. Of course, there are new novel AI risks, but mostly it's about the principles that we already know from other security domains. You can also use AI to protect AI, right? And that's exactly one of the things that we're using the cyber AI agents for is to really look at root cause, look at zero-day vulnerabilities, even look at, you know, CW1039, which is malicious AI code, looking for those root causes. Also, what we're looking at is blending the cyber AI agents from Morpheus with NVIDIA Bluefield and actually be able to combine and look over that entire corpus of data and learn from it, right? What are some of the patterns? What are some of the anomalies that you're seeing? How can you isolate some of those devices at a point of maybe even an insider threat, right? So it's really using AI to protect you as well. Yeah, there are amazing opportunities now with AI because it's about making you walk faster. And, you know, you can ingest significant amounts of data in a second and, you know, take data from different sources and really try. And I don't think that we should first think about replacing anyone, just about empowering more these teams and enabling capabilities and bridging some skill gaps that we see. And, like, we say it all over, we've experienced and added some capabilities to our product just for these use cases to, you know, enable, like, making very complex query languages. Now, easy, we can just, you know, type in a free text, whatever you want to search and search it in your environment or, yeah, or just kind of helping with triage of a security alert. So, like, all of that, these are amazing use cases. And we can really see that it makes impact on the cybersecurity industry. Do we have a couple more minutes? I'm just trying to think if we need to let me know when I need to get to questions, Q&A from the audience. But I have one more question for Susan because I know you already touched on Digital Twin, but I think the work that you've been doing with NVIDIA has been really exciting. And so I would love for you to share some of the insights in terms of commercializing this Digital Twin product. Yeah, it really is very, very fascinating, the fact that we're able to show value very quickly. It is something that's not taking years of research and development, but actually being able to show steps. So one of the things that we're working on is Digital Twin at the asset level, then Digital Twin at the entire grid level, right? So we're looking at blending what we're doing from a threat detection perspective, a solution that's, you know, getting close to commercialization, as well as the cyber AI agents and being able to blend that from a commercialization standpoint. And it's one of those things, too, that it's so unique that many customers are willing to pilot it and to see if it's going to work for them. So it's kind of a slower risk, right? A digital twin versus the real thing. Yeah, yeah. But then it allows you to do all of these scenario plannings and everything. So that's pretty awesome. I think we're able to get to audience questions. I'm wondering where it goes. Do we have? I think there's somebody up here. I'm hoping we have somebody with a mic. Yep. Hi. Come on over here. Hi. This is Sean from M37. Quick question. On the cybersecurity, there's, like, twofold. One is that in this new age of AI, do we need to change things, like, fundamentally from brought up? Because the kind of the threat we're facing today in the age of AI, like, do you need to, like, think of it, take the whole thing from a different perspective? Just because this thing is so powerful, so new. That's the first one. Second one is that since this is a GTC hardware conference, right, I mean, are there anything we need to do on cybersecurity combining with the hardware? Like, combining the software and hardware in this new AI age when it comes to cybersecurity? Do you want to think about, take the first one? I'll take the second one. Yeah. So, thank you. It's a great question. I think that from, I mean, today, it's mostly, as I mentioned before, I mean, I see it as, like, trying, actually, to stick to known principles. AI is super powerful. It's true. It enables a great experience. But, again, every real threat that we saw related to AI, every risk, every exposure, vulnerability that we saw was actually more about, you know, the whole ecosystem and not AI itself. So, I think when we're trying to think about AI, modeling, like, the threats, like, with existing frameworks can, I mean, can help. Of course, there's also some portion of it that, like, new types of risks. But mostly, it's, I mean, you can use and stick to just extend the frameworks that you have today to AI and make sure that you have the visibility, that you can, you know, make sure that you secure it from data perspective, identity, network exposure, you know, all the different pillars of the traditional security areas. That, I mean, that, I think, would take you to, I mean, a good place. I think every AI vulnerability that we found or vulnerability related to AI is actually that, like, just sticking to the known principles would evolve. But, you know, AI is moving so fast. So, this, everything that I'm saying is true for now. And we are learning, like, we keep with, like, this research, we keep investigating the different risks that AI brings with. And it's, everything is, I mean, everything can change so fast. And I don't think that we can say that it will be, what I'm saying now will be true in a year from now. We keep learning about the threats. But for now, I think that it's not about revolutionizing anything in the security space. I would like to add something for the AI threat part. And I think AI is not only for cybersecurity vendor to use. And hackers are also smart. They are also using AI. And, for example, previously, they generated a phishing email. And they did a lot of social, you know, hunting and degenerative phishing email. Now, with AI, it's so easy to generate 10,000, you know, kind of targeted phishing attack. And also deepfake. And this is something new with the AI risk. In the past, there is nothing called deepfake. It's only like phishing. It's only like malicious mail. And now there are some new types of the threat. And so for cybersecurity companies like us, and we are also facing some new AI risk, which means that our research, our threat research team needs to expand their knowledge to looking at all the, you know, new form of the risks and threats. For example, we need to have the solution to prevent the deepfake. We need to detect it. And we need to have the solution to detect, you know, all the phishings. And just to give you an example, like Trump Micro. Actually, we did AI back to 2005. And we built the industry first anti-spam machine learning engine to looking at this. It's kind of cybersecurity. You can also use AI to do that. And then later on in the 2010s, and we built, like, writing-style DNA to detect the compromise minds of the account, also using AI. And we used computer vision to looking at the phishing detection. This is also using AI. These are all patented AI technologies at that time, like 10 years ago. So the hackers are learning. We are learning. Sometimes it goes to, we say, AI compete with AI. Who can use AI better? So it's going to very interesting world and time. Actually, our CEO was also hit by a deepfake, one of these deepfake attacks. And yeah, I agree that it's like this is a completely new domain thing for companies. And, like, it's more about how attackers use AI and not, like, the security of the infrastructure. But yeah. Yeah. And when the moment the news come out, the financial loss, the number is coming out in the news. Oh, my God. This is real. So real. Yeah. That's all the time. We have left for questions. Can I have the panelists say their final some words? Okay. So I want to close on a positive note. And so I would love for each panelist to actually speak about kind of the area of excitement for them in AI and where they see potential. Let's start with Rachel and then come over. Yeah. So like I say, like, 20 years ago, we started using AI. It's just a different level of AI and doing a lot of cybersecurity. And then when generative AI, you know, showing up and we started to, I think every vendors are starting to build some, like, assistant collaborator for security team. And one of my C-level customers say, hey, with this kind of AI assistant collaborator, I feel I got one more employee. He's never sleeping, never complains, just working and super smart, super knowledgeable, have a lot of expertise and helping me. So the time is really, you know, different. And think about all of these agentive AI and AI agents and what the goal we want to achieve. We want to be more proactive. And you want to be proactive because you want to stay ahead of all the problems. So the future is proactive. And so I believe AI agents and agentive AI are the things that can really help our customer, help you to be more proactive. And why you are sitting in this room and you look at the title, child, you know, do this session. This is agentive AI, AI agents to help, you know, to change all the cybersecurity. And I believe proactive security starts here, starts this room. Thanks, Rachel. Alon? So for me, I think that, like, the pace that we see with innovation with AI is really unprecedented. And, like, we should think not about, like, what we can do now, about, like, what AI will enable us to do. Assuming that, you know, we are going to continue to see faster models, smarter models, like, more complex models. And so, like, for us, you know, first assumption is AI, like, what we call commoditization of LLMs, that, like, we will have better. So whatever you might, I mean, every bottleneck that you have today might be solved in a year from now. And we should learn how to use the AI agents. I mean, from what I see now, like, everyone, like, you see mostly experimentation, think that agents can help you and, you know, make sure that your teams can focus on water methods the most or even have, like, more efficient teams because you can, you know, let the agents do some other work, you know, generate or, like, use them to walk on your tech. So, like, yeah, I'm also thinking that today what we see is only the beginning of this revolution and what we should think and we should plan and you should make sure that your teams plan. Like, you know, we have, we already have these agents. We already have, you know, smarter LLMs. And, you know, start walking when you think how the world is going to look in a year or two and because we are only in the beginning of this revolution and we'll have really, everything is going to look differently in, you know, three, four, five years from now. I've heard that the impact is so great because this is really a revolution in thinking, right? It's a new way of thinking and thinking is applied everywhere. It's not just, like, fire, electricity, you know, it's about thinking. So, Susan, I would love to hear from you and where you're really excited about AI going. So, it's really kind of interesting. This is a tribal effort, right? It's, if you are co-creating, co-collaborating, what we're finding is working with universities, working with those bright young minds that are thinking things from a different perspective, really working with government agencies, working with different consortiums, and really combining our knowledge, right? And a lot of times it's combining data in the, with what I do with the grid cybersecurity, working with different grid operators and they're offering, you know, large corpuses of data of transmission and distribution data so that we can combine that data along with our cyber agents and see if we can find anomalies. What are some of the things that we can learn from that? I think also it's important to put guardrails around what you want to accomplish with AI so that you can measure false positives and false negatives because that can only take you a little off track, you know, if you exhibit too many false negatives and false positives. So I think those are the major things that we're looking at right now. I love that last note of just ending on collaboration, right? And I think that that is the NVIDIA way is to be very open and transparent about where we're going with AI. And I'm really, and this really shows the collaboration in terms of all of us with the good guys, right? Thank you very much to our panelists. And thank you for all the insights. And I look forward to that. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.