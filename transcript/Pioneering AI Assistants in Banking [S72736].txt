 They Thank you. Thank you. I'm Julia and I'm Executive Director at Finance Informatic. In my session, Pioneering AI Assistance in Banking, you will learn how we built one of the first custom-made personal AI assistants in banking, operated in-house and designed specifically for the employee workplace of saving banks. Today, we will explore how AI is transforming the workplace in banking. First, I will introduce Finance Informatic and its role in shaping the banking of the future for Germany's largest banking group and its 15 million customers. Then, we'll dive into AI assistants at work, sharing how they enhance daily routines for 200,000 employees. Next, we will look at integrating AI with core banking, covering architecture, data and compliance. Finally, we'll focus on the human side of AI and people-centric AI transformation, ensuring user-centric design and AI literacy at scale. So, let me quickly introduce you to our company. We are Finance Informatic, the digitalization partner of the Saving Banks Finance Group. Many people don't know us, despite the fact that every second person in Germany comes into contact with us daily. We operate the largest finance cloud in the EU banking sector. In terms of revenue, we are among the top three IT service providers in Germany, and we employ over 6,900 people in our team FE. The Saving Banks Finance Group is the largest financial group in Europe and the market leader in Germany. The group consisting of 343 saving banks, 5 regional building associations, 6 savings banks, 6 public insurers and 1 asset management firm, and some more other clients. Our company, Finance Informatic, is part of the Saving Banks Finance Group with around 400 legal entities. We are a so-called internal IT service provider. With our central core banking system, we have one IT standard for all the 400 legally independent companies of our banking group. And we introduced customer-orientated standard processes and applications. These are used in all online channels and in our branches. As the central digitalization partner and technology provider of the Saving Banks Finance Group, our mission is to deliver the technology that makes modern banking possible for around 50 million people. This means for a significant part of the German society with its 80 million inhabitants, ultimately in every second household. Obviously, the next big value driver in banking will be AI. But where is the value of AI? It's not in the technology. It's in the use cases. The speed of any AI transformation is the number of AI use cases you can implement in a year. If you compare the Saving Banks Finance Group to a fintech or a startup, there are much more potential AI use cases to look at. Instead of a single, well-defined target group, we are looking at a large and diverse customer base of 50 million people. Also, the Saving Banks Finance Group consists of 400 separate legal entities. In technical terms, this means every AI solution must have multi-client capability, including separated and secured data management. When it comes to channels, fintechs like to focus on the digital direct-to-consumer channel. We have that too. Of course, our smartphone app is the most popular and most widely spread banking app in Germany, with almost 18 million users. But we also have retail banking branches in every major town, with bank advisors serving customers on-site. And finally, as a universal bank, we offer all financial service solutions. Meaning all products and services from accounts and payment to complex products like mortgages and corporate financing. With such a big playing field for AI use cases, what is our strategy? Where do we start? One of the biggest efficiency potentials for AI is the future workplace. We have 200,000 employees in the Saving Banks Finance Group supporting the banking business and branches in every major town in Germany. A significant number of Saving Banks Finance Group customers still visit branches for personal advice and service. Realizing the AI potential for these 200,000 workplaces is an important cornerstone of our overall AI strategy. Our AI strategy aims to have two cornerstones. The AI platform for the employee workplace and the AI platform for the end customers. In both areas, we have strong technology foundations. Our central digital banking platform is already an integrated part of the employee workplace. And with around 200,000 Saving Bank Finance Group employees and 400 legal entities, there's a huge potential for AI use cases. The AI-powered employee workplaces give us a chance to build knowledge and experience. About how to build AI use cases in a way that drives value and efficiency. That is user-centric and that is very secure and transparent with regards to German and EU laws and regulations. For banking in general and for AI applications in particular. No? No? Let me share how we approach the AI-powered employee workplaces. The first efficiency potential for a banking workplace is easy to imagine. Even for a modern bank employee, there are still hundreds of routine tasks that are still performed manually and that every Gen.AI large language model can do better and faster. Analyzing, writing, summarizing, you name it. For one task alone, you only save a couple of minutes. But if 200,000 employees do several of these tasks every day, these small time savings become a big deal. It's the millions of microtransformations in the daily work that will redefine all previous standards for digital acceleration. The scale of this change will be like another iPhone moment. But this is just the beginning. Agentic AI is not only the next level of technology after generative AI. Agentic AI is also the next big potential for the saving banks. We think that Agentic AI can be an even bigger game changer than Gen.AI. And therefore, it is also our next big focus area this year in terms of technology. In addition to having AI assistants for general tasks like reading and writing, we will now move into making AI assistants domain-specific task experts. Agents will get the ability to interact with existing workplace software and underlying banking systems, and the ability to read, process, and write data in those machine-to-machine interactions. And instead of giving AI a single task, agents will become partially autonomous and take over multi-stage workflows, also known as processing. Gen.AI makes the job of a bank advisor more efficient. But Agentic AI redefines the whole job description. Routine work will disappear. Instead, new skills around AI literacy prompting agent management will be needed. This allows that much more time can be spent taking care of customers. And this is the actual USP of a retail and corporate bank. But how do we explain this shift to decision-makers at the saving banks? We explain the switch from Gen.AI to Agentic AI. We know how Gen.AI can help bank employees with tasks like this. Write an email for me. For next level, AI assistants, we add three additional factors. First, context and intent. We give AI a precise understanding of what users are working on and what they want to do next. Second, knowledge and guidance. We give AI assets to specific knowledge of the saving banks. Third, processing and partial autonomy. We enable agents to carry out multiple process steps at once. When we add those three things, the AI assistants feel more like this. Instead of a user writing a prompt, the AI will proactively offer assistant based on the usage context. AI will include data it gets from existing systems to include information like names and customer status. AI will understand the steps and checklist for any given process. For example, it knows which customer documents need to be requested for a loan application. And it may even consider personal customer characteristics like preferred language. This is the difference between generative Gen.AI and agentic AI. But this also means that human in the loop becomes more important. As soon as AI gets more access and more autonomy, transparency, traceability and explainability need to be ensured accordingly. How does this increase efficiency for the organization? This is how we explain the economic impact of AI agents in simple terms. On the left side, you see a bank employee completing a multi-step task. For example, filling out the form for a loan application in the banking system. Each red dot represents a step the employee needs to make. During this workflow, they have to gather information from multiple data sources and documents. They have to switch between specialized applications. Maybe they also have to open and use the email client for customer communication. That's still a lot of manual step even for a digital workplace. On the right side, you see agentic AI in action. The bank advisor will simply ask the AI to fill out the application form. The agent will autonomously assist documents and systems and find the needed information. The bank employee will double check before submitting the form. As you can see, a lot of human work is shifted to the agent. The human gets some new tasks for human in the loop control. But the bottom line has a significant net efficiency gain. When we talk about AI assistant for the workplace, we are not talking about your typical AI copilot. AI assistants at the workplace can take many forms. On the left side, you have the standalone applications like a typical AI chat. Then you have AI working as a background process. AI completes tasks in the background and the results are then delivered into the regular workplace application. On the right side, you have two forms of AI integration into the workplace software. Structural integration means at defined points of the workflow, the AI has a defined task in a very narrow context. And additive integration means AI features that are optionally integrated, like assistance for a customer email. In just under 12 months, our AI assistant, the so-called SAI pilot, was deployed across 60,000 employees within the saving bank's finance group. SAI pilot has transformed daily workflows handling tasks such as queries, drafting, and summarizing tasks. And it has access to domain-specific knowledge, like for example, process documentations and internet. So our saving bank's employees get support in very specific questions, like how to deal with errors in the cash posting. The adoption rates and usage data show that the AI assistant is actively reducing manual effort and improving efficiency. Feedback from employees indicates higher satisfaction with routine tasks. This success paths the way for broader AI adoption within finance informatics and the banking sector. Now let's look ahead to 2025 and what's coming next for the saving bank's AI assistant. The biggest milestone? A full rollout to all 200,000 employees across the saving bank's finance group by end of the year. This means AI will become an everyday tool in banking operations, helping employees streamline their work even further. This will also be the year in which we will gradually introduce agentic capabilities. We will start with multimodal capabilities like speech-to-text, archiving and quality assurance. Later, a partially autonomous agentic AI will be able to take over complex multi-step workflows. With more autonomy given to AI advanced, human-in-the-loop integration becomes more important. Therefore, 2025 will not only be an ambitious year for our AI engineers and developers, but also a significant learning experience for people working with this new generation of AI assistants. Now let me show you a video with an example. Essential parts of these functionalities will come in this year, but it also gives insight into the vision that outlines our ambition for the next level. In this example, our AI assistant will change the daily work routines of people working in the regulatory review of investment advisory and services. These quality assurance managers currently have to review the recording of telephone-based investment advisory services, meaning they have to pick a significant number of recording samples manually. Then they listen to these recordings, each of which lasts around 30 minutes to 1 hour per recording. They review the recording and if they identify errors, they have to inform the responsible bank advisor and initiate quality improvement measures. All of these routine tasks are currently done manually. This will now change with our AI-driven regulatory review of investment advisory services and quality improvements. Our AI pilot will now support this automated transcription and evaluation of recordings in accordance with regulatory requirements as well as the creation of reports and recommendation of improvement measures. But let's see it in the video. The purchase of the securities will be executed via Zedra Electronic Trading Platform. You can imagine this new process will change the daily work of our quality assurance manager, Milo, as many of his routine tasks are automated wherever it's possible. We expect significant time savings per case. With the learnings from these multimodal capabilities and from the usage of AI to review the advisory services by comparing it to quality assurance checklists. In the future, we will be able to provide real-time quality assurance for the telephone-based investment advisory services as well. Now, let's move on to the technology behind all of this. One big decision for AI infrastructure is, do we run it in the public cloud? Or do we run it on-prem in our own data centers? For us, the real question is, how deeply do we want to integrate AI with our core banking systems? Our answer? Very deep. We already provide all entities of the saving bank finance group with one centrally managed core banking system, the so-called OS Plus platform. And this banking system is safely running in our own data center. We can only achieve the full potential of genetic AI for the workplace and beyond if we enable AI to use and work with the data and processes in the banking system. Now, I want to introduce you to our architectural target picture with the building blocks of our multi-agent AI applications. Bank employees have very specialized roles and capabilities. High-impact AI assistance needs to be just as specialized. This is why our architecture must enable decomposition into multiple AI agents with specialized capabilities. Each AI agent has access to several key components. Let's go through them top to the bottom. To manage complex queries, we use an orchestration and reasoning engine. The engine evaluates reasons and plans how to process a user request. The knowledge libraries include a vector database, the session context, and, in future, a knowledge graph for an even better structuring of information. These elements allow the AI to remember, retrieve, and use relevant information efficiently. Next, there are generative capabilities. These enable AI to perform information retrieval, text generation, and function calling. For example, the AI can generate a response fetched information from the knowledge library or trigger automated actions. Following up, the perceptive capabilities are also very important for the banking workplace. They ensure compliance by guiding agents through structured workflows. Based on flow contracts, the agent decides how to proceed in a well-defined manner allowing a lot of control. Including here is also a natural language understanding unit. That maps the user intents to allowed actions in a given context. Finally, the integration allows AI agents a seamless interaction with enterprise software and databases. It does so either by system calls, system capabilities, touches mathematical operations, or by calling higher capabilities directly. By decomposing tasks for specialized roles like this, we create a system that is highly efficient, scalable, and adaptive. Especially the perceptive AI capabilities are very important for the agentic AI to work in a controlled and compliant way. Because of this, let's have a closer look at the perceptive components before we move on to this backend infrastructure. Now, let's talk about how we ensure compliance and control in AI-driven business processes. Using perceptive capabilities, AI can trigger predefined business processes through a structured and deterministic mode. This means that even though AI uses dynamic language models, the actual execution of business-critical tasks remains fully controlled and traggable. This is especially important for compliance. We must be able to track and control every automated action. In this picture, the orchestration and reasoning engine ensure that every request follows meaningful steps. On the left, you have examples for generative capabilities. These may include questions answering data analytics or handling out-of-scope queries such as talking about the agent's favorite color. So, generative AI can analyze data, retrieve relevant information, and generate useful responses. But generative AI needs to be guided, especially for business-critical tasks. This is the role of the perceptive AI. It enables us to define structured workflows for specific tasks. These are stored in the conversational process repository. For example, we can define a conversational flow for conducting a customer conversation review. In this flow, we can specify how system calls may be done and whether the user can interfere. The natural language understanding unit ensures the intended execution of the flow. On the right-hand side, you see how our workflow configuration for this looks like. AI agents integrate with external APIs, AI tools, and other AI agents to execute workflows efficiently. This structured approach ensures that even within an AI-driven system, we maintain full control, compliance, and reliability in every business process. Finally, let's talk about the AI backend that powers all of this. Our AI applications run on a scalable on-prem AI infrastructure designed for high performance. This backend consists of First, large language models. Our infrastructure supports foundation models, specialized large language models, and multimodal models. This flexibility allows us to optimize AI for different banking use cases. Second, a powerful NVIDIA AI stack. We use Tweeten Interference Server that optimizes GPU's utilization and allows for the reduced hardware cost while maintaining high performance. We are planning to integrate NVIDIA NVIDIA NIM for efficient AI model deployment and execution. This ensures that AI responses are fast and reliable even under heavy workloads. Third, open source model compatibility. Our setup is designed to support a range of open source models like Mixed-Alt, LAMA, and RISP-A speech-to-text. This allows us to integrate the best available AI technology while ensuring we use the right model for each task. More powerful models consume significant resources. So, whenever a smaller model is sufficient, we use that instead. We don't need a cannon to shoot a sparrow. This prevents unnecessary compute usage, allowing us to scale our infrastructure efficiently. And fourth, high-performance hardware. Our infrastructure started with NVIDIA H100 GPUs and is now being extended with NVIDIA H200 GPUs. The usage of AI Assistant is monitored on a regular basis, tracking the number of bank employees using AI features and the frequency of their use. Based on this data, we plan the scaling of our AI infrastructure accordingly. By running our AI models on secure, on-prem hardware, we ensure full data control, compliance, and high performance. This AI infrastructure enables us to deliver scalable, reliable, and efficient AI solutions to our customers. In the last chapter, we will focus on the human side of AI in a people-centric AI transformation. Ensuring user-centric design and AI literacy at scale. Successfully managing AI transformation is not just about implementing a new technology. It's about empowering people to work with AI effectively. As we introduce AI assistance into banking, one key factor stands out. Transformation must be people-centric to succeed. So, how do we create value with AI while keeping people at the center of this transformation? Let's explore our key insights and learnings. AI can automate processes, increase efficiency, and handle vast amounts of data. But in critical areas like banking, we must ensure that human expertise remains at the center of decision-making. That's why we follow a human-in-the-loop approach. But it's not done with announcing this buzzword. It's essential to enable humans to be in the loop. And this makes transparency, traceability, and explainability so important when it comes to AI. At the same time, AI literacy for all employees is crucial. Only if people understand how AI works and where their limits lie, we can successfully balance automatization with human insight. Also, for us, human-in-the-loop is not just a best practice, but a regulatory need. Guided by institutions like European Central Bank, German Banking Supervising, and the EU AI Act and GDPR. How AI is transforming the way we work is a complex process. It begins with simple, everyday skills. How does regular employee transition from being a routine Googler to an equally routine prompter? It goes deep into the specialized work processes, where we are gradually but consistently integrating AI AI along our entire toolchain, especially in software development. And it doesn't stop there. We are now beginning to consider agentic AI assistance as an integral part of our workforce. Essentially, as co-workers who work for and with us every day. When it comes to AI, we must actively guide and shape this profound transformation that affects all employees through use cases. That are often very different and, in some cases, still entirely unknown. From my experience, the key success factors to making progress here is learning by doing based on specific use cases. This means defining use cases that truly support employees in their daily work, ensuring AI literacy across all levels and embedding a culture of collaboration between humans and AI. This is why our communication and support for employees aims to ensure that our AI literacy does not end with the use of AI tools, but instead empower and encourage as many people as possible to play an active role in identifying and implementing AI potential. Another key learning from our transformation for us is customer experience the main driver of innovation. To explain that a bit, customer experience means staying very close to repeatedly changing customer needs. And this is essential because it is not the birth of a new technology. That is crucial for the success of a technology-driven application. What truly matters is creating added value for customers and acquiring large-scale adoption. When new tech becomes the new normal, that is why our top priority remains, delivering customer-centric value that enhance the everyday work of saving bank finance group employees and improves the experience for their customers. At the end of this presentation, let me share the key takeaways. Our perspective, AI is not a new strategy but a catalyst for transformation. Gen AI and agentic AI have the potential to deliver millions of micro-transformations to the employee workplace. This is done by freeing employees from root charts and giving them more time for meaningful customers' interactions. For this, we build a framework of highly specialized AI agents. This is done by using AI, the AI, the AI, the AI, the AI, the AI, the AI, and the AI. This level of AI assistant is only possible if AI is deeply integrated with the core banking system. And can only work in our regulatory environment if we have full transparency and control of all data and AI outputs. And an AI transformation like this needs to succeed on two levels. On the technology level and on the people level. To succeed on the people level, we make our AI transformation people-centric from the start. By empowering everybody in the organization to participate. By facilitating their AI literacy. By enabling them to create AI use cases for all areas of their work. And for success on the technology level, we value our partnership with NVIDIA. With NVIDIA technology, we can run and scale AI precisely in line with our strategy and requirements. We can run and implement the software and the software and the software and the software and the software. We can run and implement the software and the software and the software and the software. Let me end by thanking NVIDIA for the opportunity to share our perspective. I am looking forward to further exchange here at GTC. Thank you so much. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.