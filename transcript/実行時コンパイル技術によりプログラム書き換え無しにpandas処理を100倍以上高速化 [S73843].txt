NECの荒木です。実行時コンパイル技術により、プログラム書き換えなしにPandas処理100倍以上高速化というタイトルで発表させていただきたいと思います。まず最初に発表の概要についてご紹介します。Pandasはデータ分析において非常に頻繁に用いられるライブラリです。一方、その処理速度は遅く、データ分析処理のボトルネックとなっていることが知られています。この問題を解決するため、Pandasプログラムを高速に実行するライブラリとして、我々はFireDuxというものを開発しております。このライブラリは、ライブラリ内のジットコンパイラで、実行時に高度な最適化を行うことで高速化します。また、個々の処理の実行にNVIDIA様のQDFというライブラリを用いておりまして、GPUによる高速な実装を活用しています。本講演ではFireDuxの仕組みを紹介し、これによりPandasプログラムがGPUを使って簡単に高速化できることを紹介します。それでは、このライブラリでやりたいことを理解していただくために、まずデモをお見せしたいと思います。このデモでは、CPU上で動作するPandasとGPU上で動作するFireDuxで、同じプログラムを同時に実行開始します。これにより、GPU上で動作するFireDuxがPandasに対して圧倒的に高速に実行可能であることを示したいと思います。それではデモを開始します。右側がGPU上で動作するFireDuxですが、もう一瞬で動作が完了しています。0.36秒かかったということが示されています。左側がPandasなんですけれども、こちらまだ実行に時間がかかっています。これ結構時間がかかるので、間少し飛ばさせていただくんですけれども、これで実行が終わりました。実行にかかった時間は52.2秒ということで、GPU上で動作するFireDuxはPandasに対して圧倒的に高速に実行可能であるということが示されたかなと思います。それでは発表の構成になります。まず最初に自己紹介をさせていただきまして、その後今回の対象であるPandasとは何かについてご紹介したいと思います。その後、今回ご紹介するFireDuxのアーキテクチャについて、その内部のPythonフロントエンド、最適化パス、GPUバックエンドについてご紹介したいと思います。最後に評価、それから利用方法についてご説明したいと思います。それでは自己紹介をさせていただきたいと思います。私、荒木拓也と申します。1999年、東京大学大学院の博士課程を修了いたしまして、同年に新入社しました。2003年から2004年までは、アメリカのアルゴンナショナルラボラトリーというところで、客員研究員をさせていただきました。研究といたしましては、プログラミング言語、列分散処理、データベース、機械学習等を行ってまいりました。学会活動としましては、情報処理学会理事を、2017年から2018年度までさせていただいたこともあります。現在はNECのセキュアアシステムプラットフォーム研究所、グリーンAI研究グループで、主管研究員をさせていただいております。それでは、今回対象としておりますPandasについて、ご紹介していきたいと思います。Pandasは、データフレームと呼ばれるデータ構造を、簡単に操作できるライブラリです。データフレームとは、行と列の二次元の表形式のデータで、各列が特定の変数や属性を表現するものです。左下にあるような、こういうものですね。Pandasでは、データの取得や変換、分析を行うことができて、データの取り込みや前処理に利用することができます。例えば、ロードストアであるとか、ビジュアライズ、あるいはデータフレーム同士を結合したり、いらないところをフィルタリングしたりとか、こういうことができます。こういうデータフレームの処理に用いるライブラリとしては、Pandasが標準ツールとして最も利きだというふうに言われております。Pandasってどれくらい使われているの?というふうに思われるかもしれないんですけれども、実際のデータ分析では、表データというものはよく活用されています。例えば、顧客データであるとか、統計データ、センサーデータなどですね。こちら左下のほうには、ビットコインの1分ごとの価格情報を例に挙げておりますけれども、こういう時系列で変わるようなデータなんかにもよく使われます。こちらの総務省の調査研究なんですけれども、分析に活用しているデータの例ですね。ここで印をつけているのが、表形式が主に利用されているデータなんですけれども、多くのデータにおいて表形式が主に利用されているということで、これによってもPandasもよく使われているのではないかというふうに考えることができます。Pandasの拘束はどれくらいニーズがあるのかなんですけれども、こちらデータ分析のフローを示しています。データをまず収集して、データレイクというところに溜め込みます。その後データ整備という処理を行って、機械学習用のデータを作るわけですね。そして再に機械学習を行って、その結果のモデルを予測などに活用すると。こういうフローになっております。このデータ整備のところにPandasがよく使われるわけですけれども、実はここがデータ分析にも取り抜くなっていると。ここでは探索的データ解析や学習用のデータの作成なんかをするわけですけれども、単純な整形だけじゃなくて複雑なアルゴリズムを用いる場合もあって、実行時間がかかると。世の中ではデータ分析や前処理が8割になって記事があったりとか、あるいはアナコンダ社のサーベイではデータサイエンティストの時間の40%以上は前処理にかかっていると言われておりまして、ここの部分の高速化には非常にニーズがあるのではないかというふうに思います。この高速化するとどういうメリットがあるかなんですけれども、まずデータ分析の効率の向上ですね。データ分析にかかった時間7割が先にできるということになると、データ分析に集中できるということになりますし、あるいはクラウドコストの削減もありますね。これは実際に実行している間にハードウェアのクラウドコストがかかっているわけですので、10倍速くなったらクラウドコストが10分の1になると。ここでコストメリットがある。あるいは最近よく言われるのがCO2排出量削減という課題がありますけれども、ハードウェアをたくさん使うと、その分電力を食うわけでCO2を垂れ流すということになるわけですけれども、実行時間が減るとこれも減らすことができるというわけで、こういうふうに言ってもらうというわけになります。それじゃあPandasなぜ遅いのかなんですけれども、ここでは3つほど理由を挙げております。1つ目はCPUによるシングルスレート実行ということが挙げられます。Pandasはたくさんコアがあっても1つしか使わないので、スレートが遅いと。もちろんアクセラレーターにも対応していないので、今回行っているようなGPUに対する対応もあります。次がE画実行モデルというふうに書いておりますけれども、関数呼び出しの時点で実行を行われます。これは普通の実行の形態になるかと思うんですけれども、RDBのようなシステムですと、クエリプランナーというものが処理の全体を見渡した最適化を行うわけですけれども、そういう機能はPandasにいないので、その分遅くなっているということが明らかになります。3番目なんですが、これは遅い書き方ができてしまうと。結構Pandas、Pythonで書くと記述の自由度が高いんですね。そのために効率が悪い書き方でも動作してしまうと。動いているからこれでいいやということで、でも何か実行速度遅いなみたいなことになって、実行時間が遅くなるということも理由の一つとして挙げられるかと思います。そこで我々はこのPandasを高速化するために、Firedaxと呼ばれる高速データフレームライブラリの開発を行っております。Firedaxでは、ライブラリ中に埋め込まれた実行時コンパイラで、使い勝手やAPIを変えずに高速化するということをやっております。ユーザープログラムがありまして、Pandas APIを使って、Pandasを使って、こういうプログラムがあったときに、FiredaxではこのPandasのところをFireDaxに置き換えるわけですね。APIは同じなのでプログラムは同じで、Firedaxの中には実行時コンパイラがあって、これがプログラムを高速に実行すると、そういう仕組みになっています。それではこのFireDaxがどのようにして高速化を行うのかという仕組みについて、ご紹介したいと思います。一番最初のPythonフロントエンドというのがありまして、これはPandasのAPIを提供しています。これがIRビルダーというものを使って、データフレーム用中間言語、IRというものを作ります。これについて後でまたご紹介しますけれども、これを使って最適化パスが最適化を行うと。この中では処理全体を見渡した最適化、および遅い書き方を改善する最適化を実施します。これによって先ほど挙げました2番目、3番目の速度課題を解決するということになります。そしてここで作られましたIRをですね、IRエクセキューターというものがバックエンドを使って実行します。ここでGPUバックエンドというものを使ってGPUで実行するわけですけれども、NVIDIA様のQDFというライブラリを活用して、GPUバックエンドで中間言語を実行します。GPUを使いますので、位置の速度課題を解決できるということになります。こちらのQDFについては、また2ページ以降で説明したいと思います。それではデータフレーム用中間言語、IRなんですけれども、これはデータフレームの要素処理を命令としたドメイン特化型の中間言語、IR、インターミディエイトリプレゼンテーションでIRになります。これはですね、例えばこういうPythonプログラムがあったとします。これはReadCSVでデータを読んで、ローリングを行って平均値を取って、クローズという列を取り出して、その一番最後の1000行だけを取り出してプロットする。こういうプログラムなわけですけれども、これに対応するIRというのは右側のようになっていて、ほぼ1対1に対応しています。ReadCSVですと、ReadCSVというIR、ローリングして平均値を取るものについては、ローリングアグリゲートというIRがあって、列を取り出すものについてはプロジェクトというIR、テールについてはスラスというIRがあると、こういう形になります。このように1命令がデータフレームの操作を持つようになる、こういう中間言語になっておりますので、データフレーム特化の最適化を行いやすいという形になっております。このIRはLLVMというコンパイラのフレームワークがあるんですけれども、これのサブプロジェクトであるMLIRという、独自の中間言語を定義できるコンパイラフレームワークがありまして、こちらを利用しております。そのため、いろんな最適化とかをコンパイラフレームワークの機能を使って実現できるので、効率的に実現できているという形になります。次にNVIDIA様のKUDFですけれども、こちらのNVIDIA様のLapidsに統合されているデータフレーム、操作用のライブラリになります。LapidsはGPUで高速化されたデータサイエンス向けのオープンソースライブラリ集になっておりまして、こちらがLapidsのページになっておりますけれども、こちらに行っていただくとダウンロードすることができると。KUDFはGPUを用いて高速化されていて、またPandasオートのPythonインターフェースを持っているので、これを使って今回はバックエンドを実現したという形になります。それではPythonフロントエンドから見ていきたいと思います。Pythonフロントエンドでは実際にデータフレームを処理するのではなく、Define by Run方式と呼ばれる方式で中間言語の生成を行います。このPythonフロントエンドはPandasと同じAPIを持つという形になります。以下、フロントエンド部の動作について紹介していきたいと思います。Define by Run方式による中間言語の生成なんですけれども、次のように動作します。まずこちらのプログラム、先ほども挙げた例ですけれども、例えば一番最初、Read CSVを実行します。ここでは実際にRead CSVというCSVファイルの読み込みを行うわけではなくて、FileX内部でRead CSVオプというものが生成されます。このような形ですね。これはどういう実装がなされているかなんですけれども、Read CSVという関数の定義の中で、IR Builder Builder Opという関数が呼ばれて、このOPだけが作られるという形になります。そしてそのOPを含んだデータフレーム相当のデータ構造を返すという形になります。次にRolling、そしてMeanを呼び出すわけですけれども、これによってRolling AggregateというOPが生成されます。そしてCloseという列を取り出すという操作ですけれども、これが呼び出されるとProjectというOPが生成されます。そして手入れが実行されると、SlicesというOPが生成されて、一番最後の専用だけが取り出されるという形になります。ここまではOPを作るだけで、実際に実行しなかったわけなんですけれども、特定のAPIが実行されると、中間言語の実行を返すと。これまで作ってきたOP、IRをまとめて実現実行するという形になります。ここではプロットなんですけれども、プロットをしようとすると、実際に計算をして、データを生成しないとプロットできないので、ここでこれまで貯めてきたOPを実行するという形になります。このプロットみたいな関数が、いくつか評価ポイントの一つになっていて、他にはReplなんていうのもあります。Replというのはプリントの中で呼び出されるようなものですね。プリントしようとすると、結果が必要になってきますので、これまで貯めたOPを実行するという形になります。以上がフロントエンドの動作なんですけれども、互換性向上の仕組みとして、フォールバックというものがあります。これはFireDuxが対応していないPandas機能が呼び出された場合に、中間言語を作らずにPandasを直接呼び出す機能です。というのは、Pandasは結構仕様が複雑なんですね。そのため、FireDuxで全ての機能を実現するのはなかなか難しいというわけで、もしFireDuxが対応していない機能の場合は、Pandasを直接呼び出して、ここによってPandasとの高い互換性を実現するという形になっています。一方、フォールバックを用いると互換性は上がるんですけれども、性能は上がらないと。Pandasをそのまま見出してしまうので、性能は上がらないという形になります。我々としては、FireDuxの対応機能を増やすことで、フォールバックを減らすという活動を進めております。次に、ここで作られた中間言語に対して、最適化パスについてご説明したいと思います。この最適化パスでは、ここで作られたIRをより良いIRに変換して、高速化すると。そのために各種のデータフレーム、高速化テクニックを実装しています。以下のスライドから最適化パスについて、代表的な例を紹介していきたいと思います。まず最初の最適化ですけれども、プロジェクションプッシュダウンと呼んでいる最適化になります。これはどういうものかと言いますと、例えばユーザーがこういうプログラムを書いたとします。このプログラムでは、サンプル.csvというデータを読み込んで、B列でソートします。結果がソーテッドに入って、このソーテッドの中のA列だけを取り出して、結果とすると。こういうプログラムです。このプログラムをPandasで実行すると、もしこのサンプル.csvの中のデータが、たくさんレスがあった場合に、このソートバリューズBでソートしたときに、全部のデータをソートしてあげるわけですね。その結果、実は必要なのはA列だけでしたというわけで、この辺の他のレスのソートは無駄になるという形になります。そこで、このプロジェクションプッシュダウンの最適化では、必要となるレスだけを先に絞り込んでおくと。この場合だとA列とB列だけにしておいて、B列でソートしてA列を抽出してあげるということで、この無駄なソートを省くということを行っています。これをどのようにして実現しているかなんですけれども、最適化部はIRの中のプロジェクション、レスの抽出を見つけると、これを可能な限り前出するということで実現しています。例えば先ほどの例ですと、これは中間言語になりますと、ほぼ一体一対応していて、Read CSVがあって、Bでソートバリューして、Aをプロジェクションで取り出す。こういうIRになります。最適化部はこのプロジェクション、これを見つけると、できるだけ上に上げようとするんですね。ソートバリュー図があるので、これは一つ挙げられるかなということで、ソートバリュー図ではBを使いますから、プロジェクションのAとBを含む、新たなプロジェクションをここに追加します。Read CSVはデータの読み込みなので、超えられないので、これはここで終わるんですけれども、こうしてあげることで、プロジェクションをソートバリュー図の前に入れることができて、このような最適化が可能になると。これはIRですけれども、対応するプログラムを考えてみますと、Read CSVでデータを読んで、B列だけを取り出して、これに対してソートバリュー図を実行し、A列を取り出す。こういうプログラムになるという形になります。こうしてあげることで、余計なA列のソートがなくなって、高速になるという形になります。次の最適化はパターン最適化と呼んでいるものです。これは特定の命令の組み合わせを、より良い組み合わせに変換するという、サイティック化でございます。例えば、A列がヌルの行を削除する。こういうことをやりたいとします。プログラマーはこういうプログラムを書く場合があるんですね。これはどういうことかというと、A列に対して、Is Nullというのを呼び出しています。このIs Nullというのは、NullだったらTrue、そうでなかったらFalseというものを返すわけですけれども、それのNotを取ると。そうすると、NullでないところだけがTrueで、NullのところはFalseという、そういう配列ができるわけですね。これをDFの引数に与えてあげると、Trueのところだけ取り出すというマスクになりますので、これでフィルターしてあげると。こういうプログラムを書く場合があります。しかし、Nullの行を削除するというだけですと、DropNAという関数がありまして、これを呼び出すだけで実は実現できると。こっちのほうが圧倒的に高速なので、パターンサイティ化では、こういうパターンを見つけると、DropNAに変換するという形になります。別の例ですと、TimeStamp列からNenを取り出すというものがありますけれども、TimeStampの列に対しては、DTというアクセッサーがありまして、これを使うといろんなことができるんですけれども、その中でStripeTimeというのを呼び出しますと、文字列の形でNen紙なんかを取り出すことができます。ここでは%Yとしていますので、Nenを文字列の形で取り出して、AsTypeを使って文字列のNenをインテジャー、整数に変えるということをやっています。しかし実は、Nenをインテジャーで取り出したいだけでしたら、DT.Earでいいんですね。こうしてあげたほうが、わざわざ文字列を作成して、それをインテジャーに変換するにも早いという形になります。コンパイラはこういう変換を自動的に行ってくれるという形になります。最後の例が、グループ倍サムした結果をソートするというものなんですけれども、プログラマーがA列でグループ倍し、サムしたとBでソートバリューするというものになります。これはグループ倍というのは、ソートイコールトゥルーというのがデフォルトになるんですね。この場合、Aがグループ倍するですので、A列でソートされます。でも、その後ソートバリューズBを行っているので、A列でソートした結果というのは、結局バラバラになってしまうんですね。なので不要であると考えて、グループ倍の引数にソートイコールフォルスというのを明示的につけてあげます。こうしてあげると、余計なソートがなくなるので、早くなるという形になります。これもファイダクト内部のコンパイラが自動的にやってくれるという形になります。以上の例を見ていただくと、プログラマーが実際にこういうプログラムを書くのかなと思われるかもしれないんですけれども、これらの例は実際のプログラムから抽出したもので、実際に起こり得るという形になります。こういうパターンを現在13個ほど実装していて、いろいろ追加しているという段階になります。これは先ほど申し上げましたLLVM、MLIRというコンパイラフレームワークを使っているので、容易に実装できています。新たなパターンを追加したくなったときでも、パターンを実装の中に登録するだけで実現できるので、簡単に最適化のパターンを追加することができるという形になっています。最後がGPUバックエンドになります。こちらはこれまで作成したIRをIRエクセキューターが実行するわけなんですけれども、バックエンドで中間言語の確認を実行するという形になります。この中間言語を一旦返しているので、容易に複数種類のハードウェアをサポートすることが可能で、我々はもともとCPU版を作っていたわけですけれども、今回GPUバックエンドというものを作りまして、GPUを用いた実行が可能になっているという形になります。以下、GPUバックエンドの実装について紹介していきたいと思います。GPUバックエンドの実装なんですけれども、バックエンドの実装方法としては、各IRの処理を実装すればよいという形になります。この各IRはこれまで述べてきたとおり、ほとんどPandas APIと一体値に対応するというようなものになっておりますので、Pandas APIで実現可能な処理です。一方、COODFは最初のほうにご紹介しましたけれども、Pandas相当のAPIを持っていますので、IRの実装としてCOODFのAPIをそのまま利用するということで実現しました。これによって、COODAで直接IRを実装する必要がなかったので、CPUバックエンドに比べると非常に容易に高速かつ高品質なCPUバックエンドを実現することができました。一方、COODFが提供する関数の実装は、実はPandas処理とは微妙に異なる場合があるんですね。これは性能目的としては意図的なものである場合も多いかなと思うんですけれども、我々、FindaxとしてはPandasの互換性を優先しているので、Pandasと同じ結果となるように調整しています。それはどういうときに結果が異なるのかなというのをちょっと例を挙げたいと思うんですけれども、一つ目は結果の型が異なるというパターンですね。例えば、デートタイム型の列に対してDT.Earを呼び出すと年を得ることができるんですけれども、PandasではInt32型になるんですけれども、COODFではInt16型になると。これはおそらくGPUはメモリがあまり潤沢ではないので、メモリを節約するためにより少ないバイト数で表現しているのではないかなというふうに思います。これは一例なんですけれども、これ以外にも結果の型が異なるという場合も結構あります。これぐらいだと年というのはどうせ16ビットで表されるので、大きな問題ないかなと思うんですけれども、型が異なるとですね、この結果を使って何か演算をしたときにオーバーフローなどが起こってですね、互換性上の問題が発生する場合があります。我々としてはPandasとの互換性を重視しておりますので、COODFで処理した後に型変換を実施して、Pandasと同じ結果になるように変更していくという形になります。もう一つの違いがですね、欠損値の扱いが異なるという場合ですね。Pandasでは欠損値は基本的にノッターナンバーで表現しています。不動小数点のなんですね。一方、COODFでは欠損値は特別な値、NAという特別な値として扱っています。これによって演算結果が異なる場合があるという形になっています。例えばですね、シリーズとして、1.0、3.0、欠損値みたいなリストからシリーズを作って、このシリーズの各値が2.0よりも小さいかどうかをチェックするような、こういうプログラムを書いたとします。Pandasの場合は、1.0は2.0より小さいのでトゥルー、3.0は2.0より大きいのでフォールス。3番目は欠損値なんですけれども、なんと2.0との比較になって、これはフォールスを返します。一方、COODFはですね、トゥルー、フォールスと一緒なんですけれども、最後、欠損値との比較は必ずNAになるんですね。ここにも書いてありますが、COODFではNAとの比較結果は常にNAになるんですけれども、Pandasはなんとの比較になるので、フォールスが書いてくるというわけで、結果が異なるという形になります。実はPandasでも欠損値として、PD.NAというものを使うと同じ結果になるんですけれども、普通はなんを欠損値として使うので、結果が異なるようになってしまうという形になります。Findexでは結果がPandasと一致するように、こういう場合でもバックエンド側でレザー結果を変換するということをやっております。それでは評価についてご説明したいと思います。こちらの評価では、データベース用ベンチマークとして著名なTPCHベンチマークのPandas版を利用して評価を行いました。こちらのグラフはですね、縦軸がPandasに対する速度向上率になっております。横軸はですね、こちらのベンチマーク、クエリというものが1番から22番までありますので、それぞれのグラフを表示しております。クエリによって非常に高速化できたものと、そうでもないものってあるんですけれども、平均すると124倍ということで、Pandas平均100倍以上の性能向上を達成できたのではないかなというふうに思います。それでは次にですね、QDFとの比較について紹介したいと思います。これまでQDFはPandas相当のAPMを持つというふうに紹介してまいりましたので、それだったらQDFと比較したらどういう性能になるのかというのが気になるかと思いましたので、こちらで紹介したいと思います。こちらではQDF Pandasというモードを使って評価を行いました。これはPandasとの互換性を向上したQDFのモードで、もしQDFは対応していない機能を使っていたら、Pandasにフォールバックすることで互換性を向上するという、そういうモードでございます。ファイルアックスで行っているのと同じような仕組みですね。このモードで実行した結果はこちらのグラフになるんですけれども、先ほどのグラフの右側にQDF PandasのPandasに対する速度向上率を並べたものになっております。いくつかのクエリはですね、ファイアダクスの方が非常に高速になっております。こちらはですね、最適化の効果によって処理量を大きく減らしているということが原因かと考えております。以上によって平均で約5倍程度高速になっております。それでは最後にPolarsというライブラリとの比較について紹介したいと思います。Polarsというのはお聞きになったことがある方もいらっしゃるかと思うんですけれども、Pandasとは異なるAPIを持つデータフレーム用のライブラリになっております。こちらの高速であることが知られていて、GPU版も提供されているので、こちらとの比較について紹介したいと思います。こちらの結果のグラフになっておりますけれども、先ほどと同様、PolarsのPandasに対する速度向上率を右側に並べております。見ていただくと分かるように、いくつかのクエリについては同じぐらいの性能向上率になっているんですけれども、いくつかのクエリについては、Firexの方がPolarsよりも高速であるということで、平均するとFirexはGPU版Polarsよりも若干1.7倍程度高速であるということが分かるかと思います。ユーザーからの利用方法なんですけれども、こちら非常に簡単になっております。インポート部分を書き換えていただくだけでよくて、ユーザーの皆さまがimport pandas as PDというふうに普段プログラムで書かれると思うんですけれども、これをimport firex.pandas as PDというふうに書き換えていただくだけで、Firexで動作いたします。しかしこれも嫌だという方のために、インポート部分の自動書き換え機能というものを提供しております。これが我々インポートフックと呼んでいるんですけれども、これはPythonの起動オプションで出演することができます。例えば、program.pyの中でPandasを使っているとすると、python-m firex.pandasとしていただくだけで、プログラムの中のimport pandas as PDがimport firex.pandas as PDに自動的に書き換えてくれると。あるいはJupyterノートブックを使われている方もたくさんいらっしゃるかと思うんですけれども、こちらの場合はMagicコマンドで指定することが可能です。loadext firex.pandasというふうに書いていただくと、この中でimport pandasとしてある部分が自動的にimport firex.pandasに書き換えてくれると、そういうものになっております。入手方法なんですけれども、まだ開発中で、2025年中にリリースの予定になっております。一般、CPU版はPyPIで公開しておりますので、使い方と先行して試していただくことは可能です。PIPインストール、Firexでインストールできますので、もしよろしければお試しください。リソースです。GoogleなどでFirexで検索していただくと、いろいろ出てくるかと思うんですけれども、こちらはウェブサイトになっております。ユーザーガイドのエンチマークや開発状況など、こちらで発信しております。また、GitHubのほうでは一周の管理も行っておりますので、何か問題があればこちらでデポートしていただくと。あと、SlackではQ&AやZASLANなども行っておりますし、QTwitter、ExではDS情報の発信なども行っておりますので、フォローしていただければなというふうに思います。それでは最後にまとめを行います。本講演では、Pandasプログラムを高速化するダイブラリー、Firexについて、その仕組み、評価、使い方について紹介いたしました。FirexはQDFをバックエンドとして利用することで、その機能性能を保管し、より高いPandasとの互換性と、より高い性能を提供します。リリースされた際には、ぜひお試しください。最新情報を希望される際には、ご連絡いただければ幸いです。以上で発表を終わります。ご静聴ありがとうございました。