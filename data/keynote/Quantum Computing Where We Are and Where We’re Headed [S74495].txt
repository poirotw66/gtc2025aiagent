 Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords Transcription by CastingWords robotics, factory robotics, factories that are going to be robotics to build, orchestrate robots that are going to build products that are robotic. Incredibly complicated set of computing and libraries and algorithms and models. And we approach it in a way as if we are deeply integrated into the ecosystem and industry and we care deeply about them, and yet we don't build robots. We don't build quantum computers, but we are deeply integrated into the quantum computing industry and we create libraries. Q2Q is a programming model for hybrid, classical, accelerated quantum. We have QQuantum libraries that help you simulate quantum circuits and DGXQuantum to do error correction of quantum computers. We partner with them. We support them. We help them in any possible way. And, you know, but try not to say anything that trips them up every now and then. And so anyways, we care deeply about this ecosystem and I'm really, really happy to bring our partners, many of our friends. There are many that are not here and the reason for that is because, you know, we had to do this in three panels. There were so many people. The quantum computing industry, as you know, a new computing platform is not easy to create. And we didn't create CUDA computing ourselves. We created the architecture. Of course, we created computers. We dedicated ourselves to a very, very long roadmap of compatibility and dedication to helping developers and creating libraries and tools and evangelizing and so on and so forth. But in the final analysis, the CUDA accelerated computing ecosystem was built by all of us. That's what GTC is about. In a lot of ways, this is just the beginning of the quantum computing ecosystem. And it's really terrific to be able to celebrate it with all of our friends and partners. And so I'm going to invite many of them on stage. I just want to let you know that there were many that we couldn't. And I want to thank all of you for your partnership and your friendship. And we'll try to invite you next time. But before I do that, we're making an announcement. I'm making an announcement today that NVIDIA is starting. Now, I'm saying this as if this announcement is coming as a result of. I just want to let you know that we were going to make this announcement before this. Okay? So you don't make it. The cause and effect, physics matter here. Okay? The cause and effect in this case is completely unrelated. We're announcing that NVIDIA is going to open a quantum research lab in Boston. It's going to have a... Yep. It will likely be the most advanced accelerated computing, hybrid quantum computing research lab in the world. And it's going to be located in Boston so that we could partner with Harvard and MIT. And some of our partners are going to be in there initially. But many others will be working in this quantum research lab in the long term. Quantinuum, quantum machines, and QR are going to be the inaugural partners with us to build this quantum research lab. And so I'm very happy about that. And we're going to get that going as soon as possible. And so now what I'm going to do is I'm going to introduce some of my CEO colleagues. And please, please join me to welcome them. Alan Baratz, D-Wave. Alan. Peter Chapman. Ian Q. Peter. Thank you. Let's see. I think the next one is Loic. Henriette. I think, right? Isn't Loic? Okay. Welcome. And Rajiv. Rajiv Hazra. Quantinuum. Rajiv. And Subod. Subod, come on stage. We're getting. Nice to see you. So I think, I guess the first thing is, sorry about that. That was funny. That was, you know, for everybody. We do? Hang on a second. Come on, Mikael. Goodness gracious. I left Q. I right behind. Sorry about that. So it reminds me of a joke. It reminds me of a short story. This is nothing like you. So anyways, I was left behind. This was in 1995. And we had just started NVIDIA, the 3D graphics ecosystem, a whole bunch of 3D graphics companies. It was like a new 3D graphics company per week. And we were the first one to start. But after a couple of years, there were like 50, 60 competitors. And we started, we created an architecture, which we chose a technology which was exactly wrong. Okay. And so even though we were the first company to start, because our technology was exactly wrong, we were about to go out of business. And this financial analyst, industry analyst that follows the industry, he kept a list of all the companies that were building 3D graphics. And so anyways, we were, and it was being published every single week. And then one week it came out and we were left off that list. And so I was left behind. And I said, why did you leave us off the list? He said, well, I thought you guys went out of business. But you guys are doing great. Sorry about that. Great story. Great story. All right. So, so, so, so listen, so each one of you have, some of you have chosen different approaches. I mean, there are quite a few different approaches to quantum computing. And, and maybe, maybe what we could do is we start by having each one of you, and just remember, there were a whole bunch of us. So, so each one of you take a moment and talk about your approach and why you did it. And since, Mikhail, since I almost, I almost left you behind, why don't you start? Thank you. So, first of all, thank you for hosting us. It's amazing to be here. Thank you. And, you know, also thank you for your contribution to this emerging quantum ecosystem. So, we are building quantum computers literally from single atoms. And we assemble them and control them using arrays of laser beams, using basically techniques like holography, techniques similar to those used to project, for example, to beam. The, you know, computer kind of images to the big screens. And the key advantages is that the atoms are basically God-given qubits. They are all identical. They have, they're extremely well isolated. You know, we can preserve quantum states for a very long time. But also, we can use light. We can use lasers to control these atoms, basically position them at will and move them around, including both during the computation process itself. And in particular, it allows one to build, allows us to build a processor where connectivity is basically a living organism. It evolves during computation itself. And this is very special. So, this allows us to build systems now which have thousands of qubits. It allows us to deploy for the first time these techniques of error correction, which you mentioned, and execute algorithms with the so-called protected logical qubits. Yeah, that's great. And this is, yeah, it's a very special approach. And we're in a very special time using this approach. Yeah. Thank you, Mikhail. Go ahead. Let's take turns. Go ahead. So, thank you for the opportunity. So, at Regatee Computing, we develop superconducting gate-based quantum computers. We are based in Berkeley here, and we also have a fab in Fremont. So, why superconducting gate-based quantum computing? Gate-based because that's how we know how to do the broad world of computing. That's how classical computers run. Why superconducting? That's an area where, along with us, there are many other companies, including some big companies like IBM, Google, Amazon. As well as the government of China is investing heavily in superconducting gate-based computing. The reason we like superconducting is primarily because of its advantages in scalability and gate speeds. We are using fundamentally a silicon chip, so we know how to scale up once we, because of the leverage of semiconductor industry and five decades of experience there. And because we are dealing with electrons, our gate speeds are in tens of nanoseconds, and that makes it very easily compatible with the CPU-GPU ecosystem, which is the way we think quantum computing is going to come along. So, we feel very good about scalability and gate speed. The challenge and Achilles heel, if you will, of superconducting quantum computing has always been fidelity. We get noise because of this intrinsically engineered devices in the chips, just like CMOS technology. And historically, that was in the low 90s and mid-90s when the qubits entangled with each other. The two-qubit gate fidelity is what we call it. What's been exciting is in the last few months, ourselves, along with some other companies in superconducting like IBM and Google, have made some very important strides. And now we are in the 99 to 99.5 percent two-qubit gate fidelity, which is commensurate, comparable with the best over here in pure atoms and other areas. So, we maintain the advantages of scalability and gate speed, but now we feel very good about where we are with fidelity. So, that makes it a lot more attractive. Within this space, we differentiate ourselves by an open modular approach. So, we have designed our stack so if we find a more creative solution out there, whether it's an error correction from a company like Riverlane or KudaQ from NVIDIA or quantum machines for control systems, we can easily integrate that into our stack. As opposed to some other companies like IBM or Google who have designed it in a mainframe approach. We believe an open modular approach is the right way to build an ecosystem while we are in R&D. So, in the overall journey, our flagship system is an 84-qubit system with 79-anore second gate speed. It's available to anyone on AWS and Azure right now. We believe it's one of the best. But frankly, it's not good enough yet for any practical use, as we talked about earlier. And we think we are roughly above... Well, don't give up yet. Don't give up yet. Here, Rajeev, why don't you start? Thanks, Jensen, for hosting us. So, at Quentinium, we build quantum computers using the trapped ion modality, as it's called, and a particular architectural approach called QCCD or quantum charge couple device. The beauty of this approach is it produces the industry's highest fidelities, triple nines and beyond. There are a lot of challenges in quantum computing, as you know. However, coherence time, scalability, fidelity, these are some of the most challenging properties. And as you're thinking about and listening to these different quantum computing approaches, just listen for those words. I think they're consistently being used anyhow. And it helps you understand the pros and cons or the challenges and the opportunities associated with each one of the technologies. Okay, go ahead, Rajeev. So, thank you for filling it in. Basically, we have the industry's highest fidelities. You asked about what's our approach to it. Our approach is to extend the QCCD architecture into higher levels of scale. So, we will have 50 logical qubits, so highly reliable qubits this year, 100 logical qubits in about 18 months, and we see a clear path to millions of qubits early in 2031, 32 timeframe. Another part of our approach is not just building the science of it. Our approach is we work on really, really challenging problems. So, it's like living on the edge. We work on them with hardware and software we build and with customers. So, we aren't trying to create a solution looking for a problem, but start with the notion of what big hairy problem are we going to lunatically go attack? And then build our capability across hardware and software to be able to do that. And I hope we get a chance to talk a little bit about what else is out in the industry today that is a beautiful company. Well, welcome to GTC. We have a lot of hairy problems here. All right. So, thank you, Rajeev. Yeah, Loic, go ahead. Thanks a lot for hosting us. At Pascal, we build quantum processors that leverage the neutral atom technology. So, quite close to what Michel Leukin and Cuera is doing. This technology has several key advantages, like scalability. We can trap and control many of those qubits right now, thousands of them. And also, it's easy to control them with laser light. And it's a relatively recent technology compared to trapped ions and superconducting qubits to develop quantum computers. Actually, it's more recent. But there is a lot of progress and a lot of momentum in terms of gate fidelities and scaling of this approach. At Pascal, what we are also committed to doing is working very strongly on engineering of those devices to turn them from lab experiments to real industrial products. I think we all agree here that usage and adoption is very key for the entire quantum community right now. And at Pascal, we really want to deliver on that promise. So, over the past 18 months, we have delivered four machines worldwide, including one in France and CEA, GenC, and another one in Germany, Uli Supercomputing Center. So, that's about it for Pascal. We work with neutral atoms and focusing very strongly on engineering. That's terrific. Thank you. Go ahead, Peter. Please tell us about your company. So, I'm the chairman for INQ. We're a trapped ion company, like Continuum. Trapped ions actually were used back in 1995 when they were looking at atomic clocks. Atomic clocks and our technology have a huge overlap. And back in 1995, a team at NIST and one of the co-founders of INQ did the first ever quantum logic gates. And all of that craziness that you see coming all started in 1995 from that experiment. So, we're now 30 years into this investment in trapped ions. So, very similar to other modalities. We use individual atoms and we use lasers to do computation. We're down at 0.02 nanometers. So, when you look at the silicon industry, they're way, way up there compared to where we play. We play with individual atoms. So, these, the advantages to our technology is one is you can have a room temperature quantum computer. So, it can fit in a rack. And to be honest, it looks kind of boring compared to what you probably imagine. Because it will be rack-based room temperature. The other advantage, because we use optics and lasers, is that you can network them together to do distributed quantum computing to get to larger numbers of qubits. And you can reuse the existing infrastructure of the internet using fiber optics. And then, as has been mentioned, trapped ions have the best average two-cubic-eight fidelities. And so, in that sense, they lead in—and that's a fairly large advantage because it means that the amount of error correction that you need to do will be less than maybe some other modalities. But each one of—and I just say since 1995, it's amazing how many different modalities have showed up, three qubits, and the amount of progress that's been made. So, it's really quite exciting from that point of view. And it's great to see the leading companies on stage here today with us. So— Yeah, thank you, Peter. Alan, go ahead. Thanks, Jensen. So, we are a superconducting company, similar to Rigetti. We believe that superconducting provides the best balance between qubit fidelity or the quality of the qubits and gate speeds, time to compute. But we're actually quite unique from everybody else on this panel and pretty much everybody else in the industry because we use annealing technology as opposed to gate model technology. Without going into the details, annealing is a much easier technology to work with. It's easier to scale. It's much less sensitive to noise and errors. And probably the best proof point for that was in a paper that we published in Science last week where we performed a useful computation, properties of magnetic materials that would take nearly a million years to compute classically. And then this week we actually put a paper on the archive where we showed how to use that computation to create quantum proof of work in a blockchain. So, the idea would be that you would use the quantum computer to create the hashing function and you would use the quantum computer to validate the hashing function. And we now have this running on four of our quantum computers as the first distributed quantum application where, in fact, we're generating hashes, we're validating hashes. And we think this could be a very interesting, much lower energy consumption approach to blockchain. You know, every time that somebody in the quantum computing industry achieves a milestone, it stirs up a fair amount of controversy among the others. Did you stir up any controversy in your achievement? Because at the moment, I think the achievement to controversy ratio is literally one to one. So, the answer to the question is that I've received a lot of positive feedback from my colleagues in the industry. Just, it was exactly like me when I did it. That having been said, and only since you asked, and I don't like to name names, but I will. There was a paper that came out of some researchers at the Flatiron Institute in New York. This is a really solid research team. And what they were able to do was advance the state of the art on a classical computation in tensor networks. And what they've been able to do is to show that for the smallest instances that we computed, which we also computed classically on GPU clusters, they could do it a little bit faster. Now, they made some claims about how that undermines the results, but not at all. I mean, we computed multiple lattices, multiple size lattices, multiple evolution timeframes, multiple properties on the lattice. And so, this is a very strong result. It's actually been in the public domain for over a year now. Yeah, that's terrific. So, I guess the question that stirred up a fair amount of excitement is really about, you know, what is the definition of usefulness of quantum computing? And when do we expect that? Before we answer to when do we expect that, maybe we'll build up to it. You know, what are some of the early applications you think, and we'll start back in Mikkel again. What are some of the early applications you think that would be worthy of the endeavor of a quantum computer, number one? And number two, you know, how do you define usefulness? So, maybe I will start kind of at a high level. So, quantum computer is really a fundamentally new scientific and engineering tool. And if you look at the history, you know, of science and technology, whenever you come up with a new tool, the first thing that you use it is to really kind of advance the science and actually make scientific discoveries. And, in fact, quantum computers literally allows us to go into corners of the universe where we have never been. And, you know, if you go to these corners responsibly, you always find something interesting. So, and what kind of I mean by that is that I believe there is a huge potential to use the machines which are already existing already now or kind of which are being developed in the near term to really kind of advance this kind of scientific frontier and actually make new discoveries. There has been already discoveries made using quantum computers, but to be maximally honest, there were very few. And the way how many of us kind of are thinking about is that now we are in the era of this kind of quantum discovery where we can use these machines to actually really, you know, mostly kind of exploring physics of complex systems, maybe of, you know, related to things like also chemistry, material science. And the field is now really ripe for using these machines to kind of really make, to really push into this kind of science directions and really start making discoveries. Often they are things which maybe are not necessarily directly commercially relevant. You know, for example, understanding properties of systems away from equilibrium. I mean, a lot of world around us is not in equilibrium. And these are the kinds of things where, you know, I expect a lot of progress will be made within next few years. And often these are the things which actually then translate to applications. And often they start new industries in a way which is not possible to predict. Yeah. You know, and that's where I think that's why this field is on a special point right now. Yeah. And so that's a trapped ion perspective. What about a superconductive perspective? It's a neutral atom perspective. Neutral atom perspective. It's a small differentiation. So, you know, following on what you were saying, I mean, I agreed with every area that you, you know, the fundamental premise that scientific discovery is going to be taken to a new frontier. But we're seeing applications today. As I said, we kind of focus on what is the big problem for a customer or a partner we want to solve. We are seeing applications in the area of chemistry on, you know, how do you get to new refrigerants, right, that have certain sustainable properties. How do you generate hydrogen from water more efficiently without needing platinum as a catalyst for the reaction? In biology, we are looking at how peptides bind, right? So these are very specific instances. And doing that gives us a good way to understand two things. What algorithms do you need to attack it with? And then what capability do you need in the machines at a certain point in time? And you ask the question of what is the performance standard? Like, you know, I come from a classical background. You had performance per watt, then you had performance per watt per dollar. We're getting to a point where if you look at it through the lens of big problems you want to fundamentally solve with the figure of merit of either solving it more accurately or solving it more accurately and with less energy and cost, then we are getting to the point of what is your scale of computation. That's usually qubits, number of qubits, but also what fidelities and error rates you can sustain to make those qubits useful, right? I'm not saying there's a perfect ratio of those things, but they're generally leading us to say, how useful is your powerful quantum computer? And that can only be done through the lens of looking at big problems and saying, how do you solve them with the help of a quantum computer, not necessarily replacing a classical computer with a quantum computer. Yeah. Rajiv, one of the areas that I do wonder is whether quantum computing is just simply poorly positioned. And let me take a swing at it. You know, there are so many things in an industry which is built on fundamental sciences, and quantum computers, in its broadest sense, can be the ultimate instrument for understanding the basic sciences that affects that industry. However, because it was described as a quantum computer instead of a quantum instrument, people have a notion about what a computer is. You know, it should be able to run Excel super fast. And you know that every respectable computer should be able to run Crisis, the game. And so there's a common sense about what a computer is, and it's attached to memory, it's attached to network, it's got storage, it should be able to read and write. And there's a programming model associated with the computer that I wonder if it's just the wrong mental model. And as a scientific instrument is extraordinary, Mikhail, as you say. And that the opportunity to understand science deeper along the way is extraordinary. But to position it as a quantum, as a computer per se, and to hold it to the standards of a computer per se, that we all understand, you know, what is. You know, I wonder if that could be a reframing and allows this entire industry to be much further along, frankly, in that reframing as a scientific instrument for very important industries. Go ahead. Go ahead. Go ahead. For example, let's see you talking about some people, you Michael from across the bermuda? When it's being used, NTDDOCMO, to improve cell tower resource utilization. I mean, it's true that there are many applications I would never try to run on a quantum computer. But for applications that require extensive processing power, these machines are very powerful. And I think go well beyond just instrumentation or measurement. Sorry. I'll jump in. It's okay. Yeah, I'll jump in on that. I was I was actually just trying to help. We saw your help. You know, you know, let me tell you, let me tell you the mistake. You know, this this whole session is going to be like a therapy session for me. It and and so a long time ago, a long time ago. I somebody asked me, so what's accelerated computing good for? And I said, I said, a long time ago, because I was wrong. That that this is this is going to replace computers, this is going to be the way computing is done. And, and everything. Everything is going to be better. And it turned out I was I was number one wrong and unnecessarily wrong. You know, it's better to be narrowly focused on something and be extraordinarily good at it. But the moment you cross that line and start talking about the traveling salesperson problem, then it became unnecessary. Because that problem is obviously being solved as we know it today. And Uber cars are, you know, taxis are showing up, you know, maybe they're three, three seconds later, 30 seconds later, whatever it is, but they show up. And, and I do think that that I wonder if we hold ourselves to a bar to solve a problem that is unnecessary that's unnecessary for quantum computers to solve, quite frankly, to change the world. And it takes it takes focus away from something that you uniquely do. And quite frankly, sooner than later. Anyways, that was just my swing at it. Go ahead, Peter. Well, here at the show, we're actually have several applications, which are showing quantum is now one of them is with answers. And you might know one of their products, which is LS dyna, and runs obviously with GPUs today, we announced that we've integrated our quantum computers with LS dyna, and a 12% increase in performance in modeling a blood pump. And so this is the first, I think the first time actually quantum with production software, we also announced with Nvidia AWS, and AstraZeneca, a 20x improvement in a chemistry application. What's amazing about it is that we did that on 36 qubits, our existing system today. By the end of the year, we will have 64 qubits. Every time you add a qubit, you double the computational power. So that's two to the 28 increase in a single generation of chip, which is roughly 260 million times more powerful. So by the end of the year, one would expect for things like LS dyna, and for chemistry applications, to suddenly have huge performance increases. And so we're working right now on these applications, which, to be honest, probably all of you use, to now be able to have significant impact using a quantum computer. I do think that your statement about 10 years is, we think of ourselves as like 10 years where you were 10 years ago, we hope that obviously 10 years from now, we'll be up there with Nvidia as well, in a rarefied club. So but it does take a long time to go from, you know, it's kind of a startup to where you are today. And it's, it's completely fine to sit down and say for the computer industry, for the quantum industry, it's going to be another 10 to 15 years to get to where Nvidia and all the other giants are. It's just not going to start then it's going to start it's starting today. You're going to be much, much larger than Nvidia. There's no we're, we're, we're going to be a relic of the past. All right. So, so if, if, um, it seems like there, one of the things that's really interesting is that, that, um, there are so many different approaches to quantum computing. And, and it's, it is, uh, uh, so diverse in its approaches. Uh, why is it that this industry doesn't, doesn't quickly discover a more promising approach, uh, as you see each other's work and naturally, you know, through evolution, uh, people select the best approach and then everybody started to advance the old, the whole industry in a unified way, uh, much more quickly. You know, as I observed this industry, it's, it's surprisingly diverse and, and, uh, there's thousands of flowers blooming, uh, you know, when does it become a garden? I'll just, I'll just say on, actually, if you look across us today, there's a number of people you heard are using individual atoms, lasers, and all the rest of it. And so we actually have more commonality than most people expect often. And so I would think that, um, uh, I would hope that in the future that there is more sharing and maybe even the ability to work together because the promise of quantum computing and what it can do for mankind is so significant. It's actually larger than any one of the companies that are here sitting on stage today. And so, um, you know, I think that, that mankind has a whole range of significant problems to be worked out and we need quantum computing to be able to solve it. So, um, it is, we're still obviously new ways to be able to build qubits are being found every day. But I think that over the next couple of years, we will start to coalesce to probably two, maybe three different approaches. Um, and some of us will probably come together because we do share basically the, the underlying technology. And so it makes sense. In many of the problems that you've described, uh, uh, the, the, uh, the precise answer is not exactly known because as you know, fluids are quite chaotic and, and, um, uh, hard to know exactly what the right answer is. And in those kinds of examples, uh, using AI for emulation can give you, you know, tens of thousands of X speed up orders of magnitude speed up from where we are today with principle solvers. Uh, how do you guys think through that? What is the, what is the point of solving that problem when, when, um, classical still has orders of magnitude of progress in the next couple of years ahead of it? Well, there's orders of magnitude of progress, but at the same time, there are problems that are just, you know, impossible to solve classically today. Um, you know, there are problems in the area of drug discovery, there are problems in the area of global weather modeling, but even just the application that I shared, um, which is the basis of our paper a week ago, which is computing properties of materials. You know, we use frontier, which is basically one of your systems, massively parallel supercomputer at Oak Ridge national lab, and would take millions of years to perform the computation. So the point is there are still hard computational problems that are out of the reach of classical and AI isn't going to address those problems either. They're just out of the reach of classical. Right. Exactly. Go ahead, Rajiv. So I'd like to my, yeah, go ahead. Sorry. Go ahead. Actually, it's interesting that it took us 30 minutes to get to AI, but from our point of view, where we see it, um, quite interestingly is, and it's an extension to your question on whether we should call it a computer or not, is, you know, these quantum devices or tools or instruments, as you call them, are expanding the ability for us to access data to train these AI engines that previously was not possible. So if you're going to solve a chemistry problem today, humankind's max ability is defined by things like density function theory or other approximations to the quantum space, the world of that information that we haven't had. That's like, to me, trying to train autonomous vehicles by giving them city grids of, you know, 500 feet squared and not having the detail of lanes or other things. So what we see is this concept of, you know, computer brings in, I have a computer A versus a computer B. So A must run the thing faster than B for it to be better, at least technically, until you tell them what the price of A is. We don't see it that way. We see it as what can A and B do if A is established, classical, you know, well-honed frontier models. How are we training those models? And are we enabling those models with the data so it can now continue to be agentic and continue to reason and continue to do things that otherwise we'd be pulled in back to do, right? And we call that gen, not AI, gen Q AI. And that's kind of breaks the paradigm of a computer competing with another computer. It's two computers now working together, two completely different ways, but they are input-output for each other. You know, the output of the quantum computer is the input into these LLMs and the training methodologies so you can have LLMs that actually understand things like ground state energy and ground state configurations of of molecules. So you can then use them to start doing perturbation theory on, well, is this molecule going to last inside my body and deliver the drug at the right kinetic, you know, paradigm or not? So that is how we see quantum as an addition of a tool or an instrument into what is already a developing and rapidly maturing and improving compute paradigm. In the few minutes we have here, what are the things that we could do in the world of Accelerated Classical to be helpful to all of you so that we could advance your work much more rapidly? So maybe I will start. How about we start in the middle? Come on, Mr. Frenchman, let's go. Yeah, thank you. Yeah, I guess it's very important, as was said earlier, to couple as best as possible the various compute modalities like classical and quantum. For the moment, it's not really a matter of bandwidth or really being able to co-locate, to be able to do things fast because we're not there yet. It's not the pressing paradigm. At some point it will be a problem, but not now. Now it's really about identifying the key problems, the key domains on which we can collaborate and leverage the best of both worlds. And I fully agree with what you said about actually using a quantum computer, quantum processor, to process and create data on a problem which is in itself quantum, that classical struggles with naturally. And then use that advantage, natural advantage, in a workflow that is larger with the CPUs and GPUs and couple that quite well at the software level. I was just going to say, we use your GPUs to design our chips, to often do co-simulation, to make sure that the quantum computers are working. When we look to the future for quantum computing, it's going to be a set of classical systems sitting right next to a quantum computer. And the two of them are going back and forth. And so it isn't something where one is replacing the other. They're working together. And then if you look at the same things that are doing today, you know, we're applying machine learning to be able to figure out how to build optimization, not only for the quantum computers itself and how they run. So it is already a synergistic relationship between classical computing. And the strange thing is our quantum computers are almost entirely classical. The only quantum part happens to be a little chip and a couple of atoms at the center. The rest of it is entirely classical. So it isn't going to replace. I wouldn't short any NVIDIA stock at the end of this. So I think you have a strong position going forward. But I would expect that in the future it will be a QPU, a GPU, and a CPU all working together to be able to solve it. In fact, if I could just add a little something there. I think the – so first of all, you probably observe that NVIDIA accelerated computing is the largest volume parallel computer the world has ever seen. And yet we don't call it a parallel computer for that very reason. A long time ago there was an industry called parallel computers, parallel computing. And it was opposed to sequential computing. And the mistake of that approach, the mistake of that positioning is in fact, you know, Amdahl's law doesn't work that way. And there's no reason to replace something that does an incredibly good job. You should add to it and ride the wave of the momentum that's been created for it. And so that's why we decided to call it accelerated computing. But it's still a computer. And that really revolutionized how people thought about us and how we thought about ourselves and how we thought about our work. And I think the idea that this is a quantum computing industry or a quantum computer is less good than a quantum processor that's going to make every computer better. And so I – anyhow, go ahead. Go ahead, Rajiv. No, excuse me. I was going to say that some of the paradigms have to change in the way we are thinking about quantum processing or quantum computing. Some people have observed that think of a human brain and how it works. And that's closer to a quantum computer than our conventional thinking of HPC and how HPC should be integrating with quantum computers. We are dealing with analog inputs. We are dealing with analog outputs. We are dealing with simultaneous multiple variables at the same time, exactly like the way human brain and our neurons work. So fundamentally, we may be limiting ourselves by thinking of quantum computing in the context of classical computing and may have to start thinking broader and say what are the kinds of things we could potentially envision when a quantum computer is brought in conjunction with HPC. And to your question, how can we accelerate quantum computing development with HPCs? At the same time, how can quantum computing help Gen AI get to AGI? Those are some of the trickier things that we could use a quantum computer for. Yeah. Well, this is going to be the beginning of a great conversation for the industry. And it's a great pleasure for me to host all of you. And this is just the first of many, many in our series. And I'm looking forward to – Mikkel wants to finish. Maybe I want to – yes. Yeah, go ahead, finish. Yeah, so I think it's – like these are all great examples. And I want to go back to kind of the point I made before. And so basically quantum computer in a sense of like computation is not a hammer. It's like a scalpel. And what – it's a precision instrument. And what you basically want to do with that, and this is kind of our vision. If you really want to realize, you know, large-scale, useful applications, you have to think about this entire problem as a kind of co-design, where if you have a problem you want to solve, you want to basically solve as much as possible with the classical computers and identify hard quantum part. And then, you know, find an algorithm. Find a good error-correcting code. Find the right compiler. Find the right decoder. And it all has to be optimized with the specific architecture. You know, quantum architecture in mind. And in all of this process, what you want to do, you want to basically outsource as much as possible, at least at this time, to a classical part. And this could be CPUs, GPUs, depending on what you want to do. And, of course, at the end, you want to use an output of the quantum data, indeed, to train your models and improve them. That's how we see the real value of quantum computers emerging in the next couple of years. Yeah, that's really one very productive use case. Yeah, thank you, guys. Thank you. Okay, how about we just have to be very quick. Next year, this time, what are we going to be talking about? And so let's just quickly go through. Go ahead, Alan. Next year, this time, what do you hope that we're talking about so I remember it? How quantum is helping you to do better model training and inference with lower power consumption? Okay, go ahead. Peter? First, quantum applications in production helping customers taking workloads. And I hope that we'll see kind of along the same lines the first prototypes of a new kind of AGI based on quantum. Loic? Talking about the learnings that we got from all the usage of all the computers, the processors that are being deployed today in the field. Yeah, Rajiv. I agree with the previous speakers' theme on we will see in the next year the first real tangible use cases of an AI agent working with, in conjunction with a quantum computer, doing things it couldn't have otherwise done before are done with tremendous amount of trial and error. Okay, Subhan? I hope a year from now we are at a point where there's a little less skepticism about quantum computing and we start talking about how exactly will it be valuable in the data center and we can show some real life cases. Go ahead, Michael. It will be different. So what I want to see is 10 new scientific discoveries in physics, chemistry and biology and maybe other areas which would be delivered by the quantum machines. Okay, well, guys, let's go make it happen. All right, you guys. Thank you. Thank you. Thank you. All right. Our second panel. Our second panel. Thank you. Thank you, guys. Either way. Either way. Don't worry. Yep. Don't worry. Don't worry. Okay. Our second. Our second. Thank you. Thank you very much, Brigitte. Our second group. Ben Bloom from Atom Computing. Neutral Atom Qubits. Go ahead, Ben. Come on in. Hey, Ben. I'll shake all your hands in a moment. Matthew Kinsella, CEO of Inflection. Neutral Atom Qubits. Hey, Ben. Thank you. Thanks for coming. John Levy from Seek. Superconducting Qubits. Hey, man. Nice to see you. Tho Pernan, CEO of Alice and Bob. Alice and Bob. You have the good pleasure of having to explain the nature of your company name to all of the non-quantum people for the rest of your life. Alice and Bob. Okay. QCI, Rob. Showconf. Supercomputing Qubits. Nice to see you. And then PsyQuantum's Pete Schilbot. Single photon qubits. Hey. How's it going, Pete? Yeah, sit down. Sit down. And so very quickly, how about let's go through again. Let's start from this side. And what is your approach and why did you choose it? Yeah. So my name is Ben Bloom. I'm one of the founders of Atom Computing. We build quantum computers with neutral atoms. You heard a little bit about neutral atoms earlier. So I'll reiterate some of the good points and hide some of the bad ones. But generally, we can make very, very large numbers of qubits. So we're one of the first companies to breach 1,000 qubits. And we can do this with very, very high fidelity. So we can also do operations with these qubits that are just very, very, very coherent. And it also allows us to do things like have all-to-all connectivity, which allows for a variety of quantum error correcting codes and applications to be run on the system. Yeah. Go ahead. First of all, thanks for having us, Jensen. Yeah, it's great to see you guys. Guys, it's great to be up here with you. This is going to be fun. At Inflection, we are actually also building our quantum computers using neutral atoms. And I think Ben did a great job explaining that, as did folks on the last panel. So I'll just say that neutral atoms are a highly flexible technology. And that's because they take place entirely at room temperature. And so because we don't need a freezer, you can actually shrink. You can cost down. And you can field deploy this technology. And so what we do, I actually brought a prop here, is we can trap our qubits in these ultra-high vacuum cells. And then they're atoms. These qubits are atoms. And then we can arrange them and do interesting things with them with lasers. And we think, as I think Misha said in the first panel, atoms are nature's perfect qubits. But they're also nature's perfect clocks and nature's perfect sensors. And so we actually point this core atom technology at those three areas, clocks, sensors, and computers. And you can think of them as sort of a continuum of complexity on what you can do with neutral atoms, with computing being the most complex and clocks being the least complex. And we're following a tried-and-true monetization and market development strategy of monetizing those areas where we actually have true quantum advantage today, like clocks and sensors, and using those learnings, because there's a lot of leverage. All the underlying components are the same. Those learnings and those gross profit dollars to help us push the limits and get to, ultimately, quantum advantage in the computing world. And so that's what we do. And we are doing interesting things in the computer alongside your fantastic quantum team, Jensen, Sam, Elisa, and Jinsong and others. Yeah, appreciate that. Thank you very much. Thanks, Matt. Yeah, go ahead. So I'm John Levy, the CEO of SEEK. SEEK stands for Scalable Energy Efficient Quantum Computing. And what we've heard today is that there are multiple ways of building quantum computers with different kinds of qubits. But what we also know is qubits alone don't build a full-stack computer. You need to be able to do readout, control, multiplexing, reset, error correction, GPU integration, the full stack. And so at SEEK, that's what we do. We have actually built digitally-controlled computers. This is an example. This is SEEK Orange. And it's the world's first digitally-controlled and digitally-multiplexed quantum computer. And we're putting all the core functionality of a quantum computer on a chip. Now, the only way that we can do that is if we're incredibly energy-efficient. And you talked in your keynote about the importance of energy-efficient systems. And so if you think about building a regular quantum computer, say, doing superconducting, you might use two to five watts of power to run a quantum computer just to control a single qubit. We've gotten that down to three nanowatts of power. So we're energy-efficient. And the last part is that we're all digital. And so that enables us to avoid one of the major sources of noise, crosstalk, in quantum computers. But it also enables us to connect to other digital chips like GPUs and CPUs. So our notion is to create a platform for heterogeneous compute where we basically take this idea you were saying in the previous panel about computing and accelerated computing. And we think that the way to accelerate computing is to seamlessly integrate the way you've done it with NVLink and a GPU and a CPU, a QPU. And that's the infrastructure we're building. Yeah, that's terrific. Thank you. Yeah, to you. Yeah. Thank you. Yeah. Thanks, Sean. So at Alice and Bob, we're superconducting chip designers. We design superconducting qubits for error correction. And you know, in quantum, error correction is all you need. So our technology, the CAT qubit, has a first layer of error correction directly built within the qubit. And it's so powerful, so hardware efficient, it slashes the number of required qubit for impact by up to 200-fold. Think about it for a minute. And that's not only reducing the cost and complexity of the system. It's shortening the timeline significantly. If you think of it as in terms of Moore's law, it's nearly a decade of head start we're getting. And so, at Alice and Bob, this is how we're turning decades into years. Yeah, that's terrific. Hi. Yeah, thanks for having us, Jensen. Thank you. This is really a fun event. So I'm Rob Shulkoff. I'm one of the founders and chief scientists of Quantum Circuits, which is in New Haven, Connecticut. We're a spin-out from Yale University where a lot of the superconducting folks were trained and some of the main ideas came from. And I'm glad, Tia, you brought up the issue of error correction. I think that's a good thing to talk about. At Quantum Circuits, we believe error correction is the key to obtaining useful quantum computations. And we actually have a bit of a different take. It's somewhat similar to what Alice and Bob is pursuing. But, you know, our mantra is correct first, then scale. So we don't want to make, you know, machines with millions of very noisy qubits and then try and figure out how to program those or how to build the error correction as a software layer on top. What we're doing is we have a new paradigm within superconducting circuits. It's a thing called the dual rail qubit. And that's got essentially error detection built in at the hardware level. And so that's got a couple of advantages. We get all the speed and scalability of superconducting devices, but now we're starting to see performance that rivals the ions and the atoms. And that's trying to sort of, you know, square the circle and have the advantages of both of these different types of technologies. And so, you know, we think that that enhanced fidelity we can get by detecting the errors is going to get us to use cases in the near term that are, you know, interesting, especially for this kind of scientific discovery that was mentioned in the previous panel. And it's also a way for us to scale more efficiently to fault-tolerant machines. So we want to, you know, scaling is going to be the key, but we want to not just do that in a profligate way. We want to scale in a way that's really giving value and suppressing the errors dramatically. And I think the main challenge for the field, whatever the technology is, is to show that error correction really works, and we can suppress things down to levels that have never been seen before with physical qubits. That's terrific. Thanks. Thanks. Pete, go ahead. Yeah, thanks a lot for having us, Jensen. I appreciate it. I really hope they're paying you well to make sense of all of this complexity. Yeah, so I think it's fair to describe PsyQuantum as sitting on the extreme end of the spectrum of quantum computing companies, in that from the very beginning, we've just been singularly pig-headedly interested in building the very large-scale, universal, fault-tolerant, million-qubit scale machines that, honestly, the whole industry is always known would be required for genuinely commercially useful applications. And the approach that we use to build that is we use single photons. We use single photons, so particles of light. We made the first demonstration of two-qubit gates by our CEO, Jeremy, 20-plus years ago in Brisbane using those photons. And now we put those on a chip, repurposing the silicon photonics technology that was originally developed for data center applications, and which I was really excited to hear you speaking about in the keynote. We think that gives us profound advantages in overcoming the scaling challenges that face our field, manufacturability, cooling power, connectivity, and control electronics. And that leverage has put us in this position where we're now breaking ground in the next few months on very large-scale data center-like quantum computers in Australia and in Chicago. Yeah, that's terrific. Thanks, Pete. You know, one of the things that's really quite challenging for people who are working around the industry and certainly observers of the industry is, of course, the science is very different in many of the different approaches. And there are quite a few different approaches. If there were just two approaches, you know, you could wrap your heads around it. But there's quite a few different approaches. The science is new. Of course, every aspect of the engineering, the manufacturing, all of it's new. Even the programming model, how you think about programming these things are new. Comparing them is difficult. For example, on the one hand, the last audience was already talking about usefulness of their computers in running industrial software. On the other hand, there's some common sense about the number of qubits necessary to have a productive and functional system. And, you know, we're at 36 or X number of qubits at the moment. And now, Pete, you're talking about a million qubits for a fault-tolerant machine and a productive machine. And so how do you bridge that gap from where we currently are, you know, what's the current state of the art versus where do you think, you know, we reach a plateau, not a plateau, but a phase shift? You know, it's likely not likely to be a very specific point. But the usefulness of these quantum computers will become more and more and more useful over time. You know, when do you kind of see that transition happening? When do you guys all see that? Where are we today? Where do we kind of likely, you know, where we would say, yeah, that's a really good quantum computer. That's a great, you know, during that time, it's going to be, we're going to be having, we're going to have quantum computers all over the place. And when is that phase shift happening? How do you guys see it? Well, I think that it's really important to just keep scaling. I think that Pete's probably right, that some of the biggest problems you have to work on that are actually going to change the world are going to require millions of qubits. And so you have to make sure that you are scaling your quantum computer really, really fast. We don't want Moore's law scaling of factors of two or root two. We want factors of 10 and we want it every few years. And that's what we do at Adam Computing. I think that, you know, in the end, there are people who are using quantum computers now, who are making progress, who are finding useful problems. But I think when you talk about utility scale, these things that are going to change the world, you have to get to a million. I think it's important also, Jensen, to define terms too, because there's, not to confuse things, there's physical qubits and then there's error-corrected logical qubits. And error-corrected logical qubits are really the key to the kingdom here. And so the ratio of physical qubits to error-corrected logical qubits, it once was thought to be 10,000 to 1. It's probably closer to 100 to 1 or now. So you're going to need multiples, the number of physical qubits, and then run error-correction software on those to get those logical qubits you need. But I think to answer your question, the consensus is around 100 logical qubits, you can start to do interesting things with quantum computers that classical computers can't yet do. You know, I mean, it's interesting to think about how to scale these quantum computers, because, for example, there was a really wonderful paper that Google did in late November around error-correction. And if you looked at the Willow chip and the setup, it was really a great demonstration of doing error-correction. It also, each qubit, if I'm not mistaken, required five separate cables. And if you think about trying to scale a system with a million qubits, I mean, are you going to really have five million cables? So I'm using this as an example, because there are so many things like that in quantum computing that we need to solve. So we're solving that by doing, you know, multiplexing and by doing chip-to-chip integration so that we can solve that problem. But it's one of a thousand engineering problems. And so it's really a pick-and-shovel approach to taking each one of those and trying to solve them. And we can't just solve one of those problems. We have to take a comprehensive view and solve them all. And I think there's probably broad agreement that unless we can figure out how to build quantum computers on a chip, we're never going to get there. So that's the kind of, I think, major goal is to scale on a chip. Yeah, Theo. Yeah. I think that, I mean, the academic community has it figured out pretty straightforward. It's 100 logical qubits, as you mentioned, with error rates remaining, what, one per million at most? Because logical qubits are not completely error-free. I mean, your classical transistors still, from time to time, happen to make an error. Now, the thing is, not every physical qubit is born equal. And so the size, the complexity of your system to get to 100 logical qubits might vary a lot from one platform to the other. From hundreds of thousands of physical qubits on some modalities to just a couple of thousands on others. And to answer your timeline, when does this shift happen? I think it's by the end of this decade, for sure. So 2030. And there, this is where you see the inflection of the exponential power. Because, you know, an exponential curve, you zoom out, it's dead flat, and then it's a hard wall. So we're in this inflection, or just the beginning. And by 2030, you'll feel the wall climb. That's terrific. Yeah, go on. Yeah, it's an interesting question. I think, you know, it's a bit of a fallacy that quantum computing is going to be, like, in development, and then there'll be a flip of a switch, and it's everywhere, and solving all the world's problems. It's really going to be more like a knob. We're going to be turning up the volume steadily. And, you know, we can start to hear the music now. And eventually, everyone will be able to hear the music. But I think also, you know, I liked what you said in the earlier panel about kind of these are different than regular computers. That's a completely different paradigm. So, like, a thing that we're doing now is we're really learning how to program these machines. And we also have to learn how to deal with the errors that are always going to be in quantum computers. We're never going to have perfectly fault-tolerant digital computers that, you know, work as reliably as a GPU or a CPU does, because they're going to be used for special purpose things. And you get the answer right one time, and then you know the answer to a question you never had. I think the right analogy is to think of, like, the early days of electronic computing with vacuum tubes, right? And, you know, it was imagined that we'd only use them for cryptography or maybe modeling, you know, bombs. And it also wasn't understood, like, you know, von Neumann had to come up with the von Neumann architecture, right? And the idea of a compiler was new. And so, you know, I think we're in the era now where the machines are powerful enough that we can do that kind of discovery of what it is to program things. And, you know, we're going to see applications of these things that are not what we anticipate today is my guess. Yeah. Well, it's really great that you said that. I think one of the things that we hope for and we'd like to be able to contribute is to help discover those programming models and help invent that programming paradigm. You know, I think there is an unnecessary expectation, and it actually sets the industry back, frankly. Unnecessary expectation that somehow the quantum computer is going to be better at spreadsheets. And that's – it's an unfortunate expectation. It's an unnecessary expectation. The reason why we're involved in all this, because we have such incredible great grand hopes for you, that we're going to go discover new ways to solve very challenging problems, but not so that we can go solve food delivery, okay? Because I really think that that's fine. You know, I really wish my burger would show up an extra three seconds earlier, but I could live with it. But there are some things that simply won't get solved without quantum computing. And I do think that the framing, our collective framing of quantum computing is going to be really helpful for the industry. And so – Can I just follow up on Rob's – on your comment about, you know, if you go back to the – let's say for a moment, just as a thought experiment, this is 1946, and somebody dragged you to the basement of the University of Pennsylvania, and you wanted to see the ENIAC. Do you think that anybody at that point said, oh, I'm going to use this to remotely call a car that's going to optimize the route, that's going to be able to pay for me to do it remotely, and I'm going to be able to get and communicate that to my friends in more or less real time? Like, that wasn't what people were thinking about. They were, you know, tracking missile trajectories on application-specific devices. And I think the idea of creating an open space to explore it and discover it is exactly where we need to be. And that's what we need everybody to be working on. Yeah, that's really terrific. Thank you. You know, I do want to say, actually, I think one of the big changes between a classical computer and a quantum computer, or at least how we understand it now, really is this idea that a quantum computer is a big compute resource. And a lot of the classical computers and a lot of the ways we use classical computers are kind of big data resources. And I think it's going to take the combination of classical computers and GPUs and everything to actually understand how do you even use a big compute resource. Like, if we succeed, we're going to build a bunch of supercomputers that are really, really good at understanding the physical world. And we have to figure out how to use those efficiently and actually how to bring them into normal everyday processes. Yeah. You know, when you spoke earlier about scaling, I'm excited by the fact that you're not limited by Moore's Law. You know, there's a Moore's Law, of course, as you know, it's not based on a fundamental law. There were some principles that were involved in it. But one of the things that is really great to see from the industry here is the rate of the scaling is not a factor of two every couple of years. Because at that rate, it will take 30 years. And we do know we need to scale. And if you look at the past 10 years of scaling, it's not an indicator of how fast you guys are actually scaling now. Because of the new science and the new methods that you guys are using for quantum computing and these quantum processors, you're scaling a lot faster, frankly. And so can you guys talk about scaling and where do you guys see what's enabled you to scale faster? Of course, Neutral Atoms is an architecture that allows you to do that better. But what's the technology that allows you to scale better today? And where do you see scaling in the next 5, 10 years? I mean, I think the answer is that we can use classical computers. So we're learning how to build control devices. We're learning how to use light efficiently. And we can just trap more atoms, control more atoms. And we start off with clouds of millions of cold atoms. We have the ability to, you know, load 10 to the 7, 10 to the 8 atoms per second. That are just ready to be qubits. And it's up to us to go and figure out how do you build the control infrastructure around that. And that's, you know, classical computing. It's photonics. It's RFSOCs. It's all these pieces of equipment that are now just able to be bought by us. And it's the interface between your processor and our processor. Is that interface sufficiently well designed at this point? No. I mean, I think that every step of the way, we're trying to make our systems faster. And, you know, GPUs and CPUs will have to get closer and closer to those actuators. Because at the end of the day, everything is just governed by the speed of light. And you want your computation to go really, really fast. So any physical distance between GPUs or CPUs that are understanding the errors that are occurring in the system is just going to slow down the quantum computation. And just rounding out the neutral atoms, and then we'll let the other guys talk about scaling their modalities. But like Ben said, the number of physical qubits for neutral atoms isn't really the bottleneck. Because we can put millions of qubits into this little device here. It's really just our ability to control those precisely with lasers. And then basically error correct those codes, error correct those qubits. And so it's interesting in that when you think of scaling, it's not putting more physical hardware in there. It's really just more precisely controlling these, you know, God-given nature's qubits with lasers. And what's the latency that we have to achieve? You know, it's probably associated with the coherence time of these qubits and the time it takes for us to do error correction or whatever control algorithm and send some signal back to you. How much time do we have in that round-trip loop? Well, the good news is really it's the ratio from how much you can get done to the actual coherence time of the underlying modality. Neutral atoms have quite a long coherence time relative to other modalities, but we're talking, you know, microseconds. Yeah, so we actually think that in our technology is applicable across all quantum computing modalities in whole or in part. But when we focus on superconducting, we think that you need to be able to have less than one microsecond latency in order to do error correction before the next error can show up. And so our goal in our ability to connect to, you know, GPUs and to your GPUs is to get to the sort of 500 to 800 nanosecond range so that we can actually have, we can take advantage of using a GPU for global error correction. So we think we can parse it by doing some on-chip, some with a pre-decoder operating maybe at 100 millikelvin or a kelvin, and then do the rest with a GPU doing global error correction. But again, we have to, that latency question is really, really critical to being able to do that, you know, on a timely basis before the next error shows up. Yeah, milliseconds is easy. Microseconds is challenging. Nanoseconds is hard. And so that's kind of... So we're already... Yeah, so we're in the hard space. Yeah, exactly. That's okay. That's okay. We like hard. Yeah, so the goal, again, is like, you know, again, I'm down to 500 to 800 nanoseconds is really our goal. Yeah. It's not just about latency, by the way. It's also about throughput. Because if you have a large error-corrected computer, you have a pretty big stream of results coming back telling you where the qubits went wrong, how you have to adapt your algorithm to steer it back to the correct answer. And, you know, that's a multi-scale problem. So you probably have to do some amount of classical compute with very tight latency. And then there'll be, you know, more complicated computations that you have a little bit more time because you're doing multiple rounds of error correction. Yeah. So this is a very interesting thing to explore. And I'm sure that... It's very hard. Error correction is a very hard problem. You know, throughput doesn't scare me. Latency and throughput requirements together scare me. And, you know, well, it's exciting. I mean, an essential thing for any of these modalities to really, you know, work and to scale is going to be to build the special purpose classical computer that is the control system and drives it and does all this magic of error correction. This alone right here, this control loop, error correction control loop right here, is a really exciting computer science problem. And this is an area that I hope all of us together can make some real breakthroughs in the next several years. You know, as everybody knows, throughput, independent of latency, is not an extraordinary hard problem. Latency, independent of throughput, is not an extraordinary hard problem. The two of them combined is an extremely hard problem. And, in fact, I was talking about it in my keynote. I mean, this is large-scale inference of AI is a problem kind of like that, especially when you want to interact with the AI. But go ahead, Pete. Yeah, Jen, so I think more than one of us on this stage has got themselves in trouble by making comments on timelines, of course, and found ourselves in difficult positions and so on. But, like, I really appreciated the other piece of your quote, which went missing, which was that we've got to scale up by 100,000 X, by five orders of magnitude. And I think in our field, of course, that is really hard. And in our field, unfortunately, I think there is a lot of wishful thinking from people desperately, and I understand, I'm sympathetic, desperately hoping that we can make the machine useful before it's useful. But you have to scale up by about 100,000 X. And it's natural to say that that's a multi-decade exercise for human beings. It feels that way in the dead of night. But you, of course, have extraordinary demonstrations that it doesn't have to be a multi-decade exercise. XAI, Colossus, they built a 100,000 GPU cluster, famously, in 112 days. How did they do that? What miracle did they deploy to get that done? The answer is the trillion dollars in 50 years that has gone into the semiconductor industry. And I came back a couple of days ago from Global Foundries. I've been raging about the insane leverage that we can access there for eight years without ever having actually stepped inside the fab. And I was extremely lucky to get in there a couple of days ago. And it's a religious experience because you see just how insane the capability of the fabs, the contract manufacturers, the OSATs, and so on is. And that has always been our thesis. And to your question on when, there are basic questions that you should ask. And this is a very complex field. Everyone is arguing for their particular technology. I'm no different. But there's a whole separate set of questions in addition to fidelity and so on, which is, can you tell me who your fab is? Can you tell me who your OSAT is? Can you tell me who's doing contract manufacturing? And where is the site where you're building the machine? And these are necessary but not sufficient conditions to actually being ready to build a genuinely useful machine. And it's very hard. But that is what we've really sort of spent our resources towards. And I think it's very exciting that you now see other players in the field taking steps into that same kind of regime. Yeah. In fact, you know, Pete, as you were talking, all of the things that you're mentioning are very sympathetic with us. Because recently, as you know, we introduced this idea called silicon photonics co-packaged optics. And the semiconductor physics had to be invented. The packaging technology, how you stack it, how you manufacture it, the entire supply chain. I introduced a whole bunch of new supply chain manufacturers. We were able to, of course, leverage many existing industries. If not for that, and we had to invent everything from the ground up, it would have been impossible for us to do that. And so in a lot of ways, you guys are doing what we did with silicon photonics CPO at a multi-scale challenge. The sciences have been being invented in your case. And so I think this is a really hard problem. However, exactly as you guys are saying, we have to find a way to carve a route, carve a road for you to be successful as soon as possible and almost every day as you scale up to this future of quantum computing. And if you look at the reason why we're here, we found a way to, one, explain our story in such a way that we didn't set a bar so high that we couldn't reach it. On the other hand, select the problems that we could solve in quite a unique way early on. And in a lot of ways, NVIDIA democratized parallel computing, if you will. But I did that on the backs of computer games. You know, that was a great decision to find a problem that had a very low bar, if you will. You know, the fact that the 3D graphics we rendered in the beginning were not exactly right. And there were a few missing pixels. And there were some gaps in the Z buffer. And, you know, people kind of, they accepted it because it was a game for crying out loud. And so it gave us the opportunity to scale our economics, scale our technology, scale our footprint. And then, you know, we selected the right science, the right industries, field after field after field. And I'm hoping that for all of you, that you don't, that we don't have, we shouldn't be held, we shouldn't be held to a standard of computing, which, as you know, is quite high. The robustness of computing, the repeatability of it, the whole industry, everything is very, very high bar. We had to go find an industry where the bar is quite low. And I don't mean it's easy. It's extremely hard. But because there's no alternative to computing, the bar is very low. You know, a computer just simply can't solve it. Like, for example, you couldn't buy reasonably a personal computer in 1995 and play Quake without NVIDIA in it. You can't reasonably do that. And so that bar was, in fact, incredibly low, if you will. Now, of course, you guys are doing something much harder than that today. But I do hope that together we find a path for you guys to be successful sooner than later. And, Matt, you were saying earlier your approach, and I love it. Yeah. Well, we honestly took a lot of inspiration from you. You know, find the markets where you can provide true commercial advantage and address those. Get feedback from the market. Learn how to fulfill customer expectations. And then find the next one. And with neutral items, we're very lucky in that they are flexible where we can and we do have three orders of magnitude improvement over current standards and timekeeping and sensors, which are very large markets in and of themselves. But using that, if we say, you know, timekeeping was your gaming market, maybe. That's right. Using all that to actually get real feedback from the market and ultimately develop that commercial muscle that we need as an industry to actually sell these things for real use cases that people were going to earn a return on their investment. Yeah. And I also heard something really, really clever. And, of course, I knew about this in the work that you guys are doing, that you would stand on the shoulders of classical computers, extend it, and make it do something extraordinary. You know, we didn't replace the computer. We added to it. And the thing that I would explain to people, you know, in the beginning is we never – nothing was ever worse. Just turn me off. You know, but I don't make things worse. Parallel computing, as you know, violated Amdahl's law, and many applications made it worse. But accelerated computing, we did no harm. And one of the things that I really like, by adding these two – you know, GPUs was added to CPUs, and QPUs could be added to CPUs and GPUs. You keep adding something, and you made that computer more and more special, more and more capable. And so – Yeah, I mean, it's interesting that there are people who are now talking about and even whole conferences around quantum AI. And the idea of, you know, tightly integrating a QPU into a GPU and a CPU creates that opportunity. So let's explore the space. Yeah. Right? Yeah. Yeah, go ahead, Pete. Yeah, so I think – I mean, I very much agree with that sentiment. There is a caveat that I think is – that I hope you won't mind me adding. No, no, no, no. We love to talk about this idea that conventional computers are integrated with quantum computers, and we absolutely believe in that. There will need to be a large conventional supercomputer, GPU cluster, whatever, preparing Hamiltonians, preparing input to the machine. But when we talk about this, there's a very seductive idea, which is that the whole will be greater than the sum of the parts. And that idea leads to an interpretation that we don't need a good quantum computer, that we can take a not very good quantum computer, plug it into a big, amazed, as you say, insanely high-performance conventional computer, and that the whole will somehow be greater than the sum of the parts. And I think you have to be quite careful about that. I think that what I would ask for is a rationale that the whole will be greater than the sum of the parts. And in some cases, you can see a rationale for that. But in some cases, there is no reason to believe that taking a small, low-performance quantum computer and plugging it into an incredibly high-performance conventional computer is going to make things any better. It is going to make things worse. Yeah, that's exactly right. And in fact, that was one of the challenges, frankly, of accelerated computing. Yeah. Because we sat next to a computer, a processor, that was getting better by a factor of two every single year. And the R&D budget of that industry, of the CPU industry, at the time, completely dwarfed the GPU. Yeah. And so it was a million times larger R&D budget per year. Yeah. And so what are the odds that adding a GPU that's built out of such low R&D budget could add value to a system that sustains such enormous R&D budget? And so the answer to that, Pete, for me, anyhow, was I kept narrowing and narrowing and narrowing the application space. Makes sense. And I kept lowering the bar, if you will, for myself so that the problems that we solve are so specific, quite frankly. Now, the challenge, of course, and this is going to be a challenge for your industry as well. The challenge is if you end up flying in an application space and it's very specific, then the size of the market is not so large that could sustain your growth. And you have to ultimately find that flywheel. In anything that's in computing, which is what we do for a living, in anything that has a very, very high computation requirement, you need a flywheel to get you there. And so that flywheel starts with solving a problem better than anybody, eventually getting to high volume, which generates more R&D budget, which allows you to build something better, which allows you to get more higher volume. And that flywheel is insanely hard to go get. You guys understand. But I have every confidence that this way of solving problems that you guys are trying to solve, there are problems that are simply impossible to scale for classical. To the extent that we can find a way to lower people's expectation of us, narrow our own, you know, aperture of problems we want to ambitiously go solve in the beginning so that we could catch that flywheel ourselves. I am absolutely certain this is going to happen. And I have every, you know, hope and expectation that this team is going to do it. And I really love hanging out with you guys. If we very quickly, what do you think we'll end up talking about next year? Because I want everybody to come back. This is such a great show. And remember, this is our first time. So, you know, if we're a little clumsy, okay, you know, lower your expectations. But next year, it's going to be incredible. Yeah, let's go around quickly. What do you guys want to talk about next year? I think there will be some amazing demonstrations with quantum error correction in the next year. And I think that we're just seeing the industry expand so quickly that we'll be trying to tamp down expectations, like you said. I think there's going to be just such amazing velocity occurring with quantum error correction. Yeah, that's great. I think we'll hear a lot of great progress on continued increases in logical qubits. And then from our perspective, you know, with our commercialization strategy, we did about $30 million in revenue next last year. So we really hope to be telling you about a heck of a lot more selling some of these early, you know, early use cases for quantum. Yeah, man, that's real money. Yeah, go ahead. First off, I like the premise of your question that there is going to be a quantum day next year. Yeah, absolutely. So, like, yeah. And I would say from our perspective, it's the integration of all core functionality of a quantum computer on a chip, full stack. Okay. Go ahead. Yeah, Theo. Yeah, for us, it would be error correction, better architecture. But most importantly for the audience is novel algorithm. There is so much room for innovation in quantum algorithm. I mean, we're seeing completely new subroutines emerging every couple of years. And think about it as someone inventing the fast Fourier transform all over again. It's paradigm shifting for whole industries each time. And so when we're looking for those niches you've been mentioning, those core algorithms, those kind of routines can completely change the reach and the impact of quantum computers and get this flywheel going. In fact, just, yeah, that's really terrific. You know, in fact, there's a misunderstanding that quantum computers are going to take classical algorithms and just make them go faster. In fact, the whole point is to invent new algorithms that are ideal for this new form of computing. Go ahead. Yeah, I'm going to talk about error correction as well because, then again, that's the key thing. And we've really entered an exciting phase where you can build machines on which you can run error correction routines. You know, for a couple of decades, you know, Shore discovered error correction the same year, essentially, he discovered his factoring algorithm. So we know that it's possible in principle. We know what the math is. But now this is becoming a practical discipline, right? So we can build and test things, and now you can say, oh, wait, this is the flaw my hardware has. So here's a code that's much more optimal. And, you know, oh, if that's a thing we can do and that makes for efficiencies in scaling, like, we can try and adapt our hardware to go in that direction. Yeah. So I think we're going to see a lot of progress this year. Yeah, I'm super excited about the whole area, and I can just tell, just from the downloads, the accelerating downloads of KuQuantum, the number of people who are using, who are discovering new quantum circuits to go, you know, simulate and discover new algorithms is growing. And so I'm super excited about that. And so, Pete, what are we going to talk about next year? Yeah. So, I mean, now we're making thousands of wafers of quantum chips in global foundries at a pretty high level of maturity. We're building large cryostats with no chandelier. We're stringing together heaps of optical fiber. And I really hope that you'll have us back next year. Yeah. Next year, I think I'll have to wipe the mud off of my boots before I come up on stage here because, as I said, we're breaking ground on these two very large sites, so like half million square foot kind of sites in Australia and Chicago. Pete, you look like a builder from Australia. Well, I'm trying my best. But, yeah, thanks very much for having us. All right, you guys. Thank you. Thank you. Next. Yeah, just I'll introduce the next crew. Thank you, guys. Really enjoyed it. Thank you guys very much. Really appreciate it, guys. And so this is our last panel. So it sounds like next year we're going to have demos. What do you guys think? Next year we're going to do demos. Okay, so the next panel is going to Simone. Simone Severini from AWS and Krista Sfori from Microsoft. Okay. All right. Hey, nice to see you. Nice to see you. Hi, Krista. Nice to see you. Welcome. Welcome. And so we had all these scientists here. And, you know, the thing about quantum computing is, you know, most of the CEOs I meet and I talk to, I can understand. And the reason for that is because we're in a computer industry. And, of course, there's always computer science, but there's not basic science. And basic science is hard, as you know. And quantum basic science is quite hard. And so most of the time you're talking to CEOs who are, you know, maybe refactoring the way that a computer is going to be architected or designed. But the basic technology is understandable. And maybe it's applied in a different way. But in quantum computing in this area, the science is new. The science and engineering is new. The manufacturing is new. The software programming model is new. The way you think about algorithms is new. And, of course, one of the areas that I was, you might have noticed, you know, I want the industries to succeed. And so I can't help but try to advise it. Not that I'm giving good advice necessarily. But to narrow its focus on application so that it's not held accountable to the expectations of other forms of computing. And now here, the three of us, we work in large companies, but yet you have quantum computing initiatives in your company. How do you guys think about quantum computing in the context of your overall computing, industrial computing business? What do you hope to achieve? What are some of the challenges that you see in ultimately making quantum computing successful? Yeah, so I'll start. Thank you, Jensen. Great to see you. It's wonderful to be here and to be with all of you as well. And when we think about quantum computing, you know, at Microsoft, obviously we have a large cloud, right? We have many customers. And it's really about that, right? We want to ensure that we are empowering our customers, you know, whether they're enterprises or scientists, right? Practitioners with the most powerful quantum computing at every moment in time. And so that means today and tomorrow, right? We are a platform company looking to bring forward a quantum computing platform to enable new scenarios, new applications, right? Emerging capabilities and disruptive capabilities. What technology did you choose? What technology did you choose? Did Microsoft choose and why? Yeah, so we have a couple of approaches, right? We both partner with other quantum processing unit providers, right? Quantum hardware providers. And then we also have a long-term investment in an approach called topological qubits, topological quantum computing, where we have just had a breakthrough announcement, in fact, in the last month. And then also this week at the APS March meeting for physics, where we shared more data on our approach around the topological qubit. And the idea here is that you encode the information non-locally, meaning our qubit isn't just a single point. That qubit, the information of the qubit is spread across a device design where it promises to protect that qubit more. But it also gives a very nice control profile. So we can use digital control instead of analog control. And it can simplify the amount of control requirements in the quantum computer itself. And so this is called the Majorana 1 chip that we shared last month. Okay, we're going to come back to you in just a second about applications and how you think about computing platforms and that kind of stuff. But Simone, if you could help us understand, you know, what approach did AWS select? Why did you guys do that? And how do you see quantum computing in the overall context of your computing strategy? Sure. Thanks for having me. It's a great opportunity. And this is my first GTC. It has been a wonderful week. So I'm going to tell you something very boring. You heard it already a few times today. We built quantum computers based on superconducting technology. So we give strong emphasis to error correction. So we believe that error correction is really going to be important for quantum computers to deliver their long-term promise. So I'm not saying that quantum computers so far are useless. Actually, they're extremely useful to learn a lot about how to build quantum computers for the future. We announced recently a superconducting chip called Ocelot. You know, Ocelot is a kind of wild cat. The name is between Schrodinger cat and oscillator. So scientists came out with this name. So... That's clever. That's almost as clever as NVIDIA. So Ocelot demonstrates error correction in a scalable architecture. And you've heard this term scalable, scalable, scalability. It's an important term. So now, why superconducting devices? So my mental model hinges on three terms. Knowledge, speed, experience. Knowledge, you know, there's a lot of experiments out there done with superconducting devices. In industry, in academia, proof of concept, proof of concept for error correction. So good basic knowledge, good background. Second is speed. They're fast. They use microwaves, so it's easier to implement error correction. And finally, experience. So at AWS, we have a good amount of experience with custom silicon, with semiconductors. Some of this experience can be translated to superconducting technology, at least from the operational point of view. Of course, we are open-minded about all other ways of building quantum computers. And we're very excited about progress that is happening across the board. Yeah. And Krista, back to you. The technology is still developing. It's making great strides. Frankly, if you just timed the milestone to milestone of the industry, the rate of milestone achievements is accelerating. And that's really terrific to see. But you still would like to find early applications or ways to think about quantum computer as you're developing it to make it useful, to find use for it as you go. How are you doing that? Yeah. So I mentioned our work on our Majorana, our topological qubits, where we're really focused on utility scale there, right? It has the right size, speed, and reliability and controllability to reach millions just in the palm of your hand, right, is what we're focused on in that technology. We're also working on types of qubits today that we are building to have 50 logical qubits this calendar year. So, for example, with atom computing, Ben Bloom was on the stage earlier in this session. With atom computing, we are working together to co-design the architecture so that we can enable the most and best logical qubits. And so when you look at upwards of 1,000 physical qubits, 1,000 neutral atoms in this platform, we can work on how we arrange them, how we move them, and to best enable, say, 50 logical qubits that have better performance characteristics than the underlying physical qubits themselves. Now, with those 50 logical qubits, then we can look towards showing the early applications, right? Around 50 qubits is where you can start to outperform classical computing. And then around at 100 logical qubits, you can start to outperform applications in the space of science, right, where you might be looking at different materials models, quantum magnets. And so our, you know, really our intention in this next few years is to work with 50 and then 100 logical qubits, you know, then built to several hundred, where we're really pushing the limits, you know, on the applications. At the 50 qubit area, what application space are you mostly focused on? How are you selecting your applications? Yeah, so, you know, definitely the most, you know, we believe the most promising set of applications is in chemistry and material science, biochemistry as well. And so in that space, you know, as we look at the rise of AI, right, the AI capabilities that have emerged are just immense and tremendous. We don't want to replace AI with a quantum computer, right? And I really view a quantum computer as an accelerator. It is something to accelerate the other compute we already have. We need to integrate it with AI and high-performance compute in the cloud, not replace it. And so it's really about bringing those together. In the next few years, I think it's all about using the quantum computer to produce highly accurate data. I used to think of a quantum computer as a standalone solution provider, right? I'm going to run a problem instance. I get a solution out. But that's not the right way of thinking about it, right? The other way to think about it is I'm getting classical bits out. What are classical bits? Data. What do I do with classical bits that, you know, are highly accurate for what they represent? I use it for training data. And we know that we can use lots of training data, right? We can use lots of data to train an AI model. And we can augment that model with small amounts of high-quality data. And we've seen this in different spaces, machine translation, right, other tasks, where small amounts of high-quality data can make a huge difference in the task you want to use that model for. And so in the space of chemistry and material science, I think this is an incredibly promising direction for quantum computers with 50, 100, 150 logical qubits, where those, again, those logical qubits have to be better than the physical qubits they're built from. Yeah, and Krista, I'm sure you guys all got it, but one of the areas that's super exciting is in the area of materials and biology, where we would like to train a model. We would like to train a model to train a representation of biology. But where does that training data come from? It's not like we have sensors and instruments. We're collecting data about biologies and cells and proteins. Now we could simulate that using a quantum computer and use that as ground truth data to then go train an AI model. And once we have an AI model, it's a lot more malleable. It's a lot easier to apply that we could use it to do all kinds of experiments with. Yeah, that's exactly right, right? The idea is to get a faster, more predictive, more accurate AI model. This is a classical AI model. It deploys in your current infrastructure, right, and it's fast. And so that's really the promise, right? You're using the quantum computer to produce data that you cannot otherwise efficiently get on this planet. Yeah. That's powerful. Yeah, Simone, go ahead. Same question. Yeah, so I like, actually, this perspective. So I attended your keynote. You've shown us a slide with four faces, perception, generation, agency, and physical AI. Of course, physical AI is about robotics, is about autonomous vehicles, but it's about our physical world, right? That's just a larger container for that. And as Krista said, what is the role of quantum computers in that phase, physical AI? Quantum computers are the only instrument we have today that we know so far for accessing that layer of physical reality, which is quantum physics. That layer of physical reality that is governed by certain laws that do not apply to the physics around us, that we experience with our senses. So quantum computers are going to be catalysts for scientific innovation that will allow us to discover certain things that are very hard to predict, of course. And in a way, we must build quantum computers, because otherwise that layer of reality will not be accessible to us. And quantum computers will work, of course, in partnership with machine learning and AI. In my opinion, in the fullness of time, we will do science together with machines. We will ask questions to machines. Machines will ask questions to us. There will be formal verification, formal reasoning, different types of compute. And quantum computers fit very well this picture. Yeah, I think the whole, you know, we have not been able to compute like nature computes in many cases, right? Nature is incredibly efficient. And I think of quantum computers as enabling us to take a step closer to computing like nature does, right? Being able to kind of see and understand electrons in a new way, right? We can't do that in all cases today efficiently. And so it really takes us a step closer. And then combining that with AI, you know, I think it will be revolutionary. Yeah. And, you know, this paradigm, if you will, of using the quantum computer to get the ground truth, to train a classical computer's AI model, which is much easier to use in the entire software stack and all of the applications and, quite frankly, very cost effective. So the training data that's going to come from that quantum computer will not be easy to get. Obviously, it required already the endeavor of humanity to get there. But now that you have that simulator, you could, within 50 logical qubits, be able to, you know, solve what otherwise is Schrodinger's equations. Now you can go train a model that we can easily apply. And we've now taken this incredible, valuable asset and we extracted it and we made it simple to use for all of the computing world. Indeed. You told us about AI factories. At some point, maybe we'll have quantum AI factories. That's right. Yeah, that's really exciting. And so we're currently at how many logical qubits? Yeah. So, you know, interestingly, one year ago, had I been on this stage a year ago, I would have said we had zero logical qubits that were better than our physical qubits that they were built from. And within the last year, we went, in April last year, we showed with Continuum four logical qubits. Then five months later, we tripled that number to 12 logical qubits. And then two months later, we again, you know, over doubled that and we showed 28 logical qubits with atom computing. And so, you know, now, right, that shows that progression. It goes back to the acceleration you mentioned, Jensen, in the field that we're seeing. And now this calendar year, we're working on the 50 logical qubits with atom computing. And the next generation of that system will be 100 logical qubits on a 10,000, you know, around 10,000 physical qubit machine there. Yeah, that's really incredible. That's really incredible. And so, Simone, one of the great capabilities of neutral atoms and approaches is the scalability capability of it. And all the things that you said about superconducting approaches, absolutely true. How do you do you see these approaches at some point merging? Or do you do you see a grand solution emerging from the industry where everybody said, yeah, that's it? You know, back in the old days in my generation, we had this thing called TTL to ECL. And we had eventually we all settled on CMOS. Okay. And during my generation, there was a lot of arguments and debates about ECL versus CMOS. And the reason for that is because ECL is essentially static current. It's always high, but it's constant. In the case of CMOS, it gets higher and higher and there's dynamic power instead of constant current power. And so there was a lot of debate about about which one was going to be better long term. But ultimately, CMOS won because it was scalable. And you could you could solve all of the other annoying issues, which is more transistors. And is your industry also discovering something similar to that, that maybe all of these challenging annoying issues ultimately goes away because of scalability and just had a lot of logical qubits? Yeah, you see, the short answer to your question is that I don't know. So the longer answer is there is some transition that is happening in the industry. Historically, people ask you how many qubits? So everybody, how many qubits? How many qubits? How many qubits do they have? How many qubits do you have? Right. It's an obsession. Right. You are the supermarket in the morning in front of tomatoes. A random guy comes and asks you, how many qubits do you have? So people ask this question less now, which is great. Yeah. Because people start. I'm laughing because somebody, you know, listen, they ask me how many flops I have. And it's driving me crazy, too. It doesn't matter. Everybody has its obsession. Yeah, that's right. So there is an interesting signal that is emerging at the moment, which is error correction. Last 12 months, number of different experiments done with different modalities, ions, neutral atoms, superconducting devices, more exotic devices. And this is probably a theme that is going to become stronger and stronger. And probably this will be the theme that will determine which of these modalities is going to emerge in the fullness of time. Yeah. Well, go ahead, Questa. Maybe I'll just say, you know, you mentioned flops. You know, here it's not just more is better. We need better also. Right. Right? Right. So as we talk about logical qubits, right, not all qubits are created equal. We need qubits that are able to extend how much computation we are doing. Right. And, you know, while we've had a discussion today about whether it's a computer or an accelerator, I mean, in the end, we need to do computation. We are not building a storage device. Right. That's not the intent. Our intent is to do computation we cannot do with all the other compute we have on the planet. And so that means that we need to improve the qubits. Right. The qubits, physical qubits fail once every thousand operations. A thousand operations in your computation is not enough. Right. We need to do, you know, we need to do computation that ultimately has more like a quadrillion operations. Right. And so there's a large gap to close there. We use error correction to close that gap. But when you use error correction to close that gap, you need more physical qubits as well. Right. You're using hardware and software to close the gap. And so the goal is to move as we as we look towards, say, you know, fifty hundred thousand logical qubits. It's not just the number of qubits that changes. When we save fifty hundred thousand, it's also the error rate. It's how good those qubits are, those logical qubits. That also changes and needs to change by orders of magnitude at each increase. So when we talk about a thousand logical qubits, we want those to be as good as one in a billion, you know, only one fall in a billion operations or much better. Right. At a hundred, you really want, you know, only one fall in a million. Right. Ten to the minus six is what we say. So we really have to increase that. And that, you know, that makes it a little more challenging. Yeah. Yeah, that's really true. Well, one of the things that I'm really excited about today and I was quite excited to do this event today, but I was also quite concerned about about how would we would take a conversation that is that is deeply scientific and very technical and ultimately connected to developers, which is what GTC is all about. about people who are trying to do hard science, people who are trying to create impossible applications and and start the journey of connecting the dots between the science and usefulness for them. And I thought we did. I thought the panel did a fantastic job today. There was several things that I think was proper properly and successfully conveyed that that the idea of a quantum computer is not to build a computer that replaces computing. But it's a QPU that is added to a GPU to a CPU to extend classical computing to do things that otherwise cannot. There are some domains, some useful domains that we can imagine. You know, you could reasonably you can reason your way through, for example, in the biology and chemistry applications and material sciences applications where we could use a quantum computer to make a classical computer way better to solve problems that otherwise cannot. For example, to create the ground truth for biology, to create the ground truth for atomic physics. And that enables us to use AI as we understand it today quite reasonably well and improving, you know, itself at a million times every couple of two, three years to now amplify the capability of AI to be able to use AI to solve the drug discovery, the material sciences, the biology applications, which if quantum computers singularly addressed, if that's all it did. Yeah, and that's the reason why we need to build these machines, right? So thinking about timelines are a question that you are familiar with, right? So how long is it going to take? Well, first of all, this is like the space program. The goal is going to the moon, right? But we are going to discover a lot of things on the way. You know, we discovered fireman's suits trying to go to the moon, right? This is going to happen with quantum computers as well. So it's a grand adventure, but we need to get there. And it's not zero one, right? It's not, oh, we have a quantum computer. We don't have a quantum computer. It's a journey. And lots of things are going to be discovered in science, in technology, as we get there. And in terms of timeline, you know, I mean, I myself, I grew up in Tuscany, like in a village in Italy. There is a city called Pisa, and there is a tower which is not straight. It's leaning. Well, that's, by the way, a result of quantum computing. Because a classical computer would make it perfectly straight. It took that 200 years. It took them 200 years to build this tower. Now, if they're doing a good job or not, it's discussable. But, you know, 200 years, right? Only a quantum computer could make a structure like that stay up for so long. So the point I want to say is that it takes time, right? And quantum computers are going to be so impactful that it's going to be a great party in the end. And we really need to work. And I think it's fantastic that Microsoft Azure and AWS is integrating quantum computing into its, you know, platform so that developers around the world can gain access to us sooner than later. And if everybody had to go build their own quantum computer to be able to enjoy this and, right, the instruments that you build, it would take so much longer. And now you've put it in the hands of browsers and anybody could use it. And I'm looking forward to 50 logical qubits very, very soon and 100 shortly after that. I think the progress of the industry is incredible. We had a great panel today. I know they're all friends of ours and friends of the industry. And in a lot of ways, although there are many competitive approaches, the industry is working so closely together to want everybody to succeed together. And so I think it's really great to see. I want to thank all of you for coming today. And if I had to be wrong to show everybody in the world that quantum computing is worthwhile to do and that the industry is built of amazing people and the work that the industry does is going to make a great impact. And if I had to do a mea copa in order for us to demonstrate that to the world, mission accomplished. Thank you all for coming.