皆様こんにちは。私は第一産協モダリティ第一研究所第一グループのステイズアット会議と申します。本日はデータ苦闘型創薬D4のこれまで、そしてこれからというタイトルで弊社のD4アクティビティについて紹介させていただければと思います。まずはじめに簡単ではありますが、弊社の紹介をさせていただきたいと思います。弊社は世界中の人々の健康で豊かな生活に貢献するというパーパスを掲げ、これを達成するために革新的医薬品を継続的に創出し、多様な医療ニーズに応える医薬品を提供するということをミッションとして創薬活動を続けております。ここには2030年ビジョンまでの流れをお示ししておりますが、2020年の頃にガン事業を立ち上げ、土器サバン拡大、リジョナルバリュー拡大、アストラズリンカーとのアリアンス、研究開発投資等を拡大してまいりました。その中で第5期中継を推進し、2025年ビジョンを実現し、成長ステージへ今向かおうとしております。2030年ビジョンでは、サスティナブルな社会の発展に貢献する先進的グローバルヘルスケアカンパニーを目指し、ガン流域のグローバルトップ10、さらなる成長の柱は収益の一つ、各事業ユニットが新生機品を軸とした収益構造、事業を通じたサスティナブルな社会の発展への貢献を目指しております。先ほどのビジョンを達成するために、弊社では現在、マルチモダリティ戦略をとっており、抗体をはじめADC、次世代合成薬品、拡散薬、バイスペシフィック抗体、細胞治療、LNP、遺伝子治療など、様々なモダリティを駆使し、アンメッドメディカルニーズの高い疾患へと、新薬を続ける研究開発を行っております。創薬標的や疾患的したモダリティの選択に加え、新規モダリティの開発も同時に進めております。また、持続的成長を実現するために、次世代の正常ドライバーを適切な評価、判断し、研究に取り入れるということもなっております。このような戦略を支える一つの柱として、D4も活用しているという状態になっております。弊社でも、リサーチDXを活用し、研究開発を家族化するということを目指しており、こちらに関しては、2019年より、定文書を中心として、データクソローズ創薬、D4のアクティビティをスタートさせております。DXを使いまして、研究を疾患探査の部分から、ヒットディスカブリ、そしてヒットトゥリード、リードオフィマリティション、プレイクリニカルまでを加速させるということを現在、目指して取り組んでおります。こちらのサイドでは、データクトモーター創薬のこれまでのヒストリーを簡単にまとめさせていただきました。D4の構想は、2018年よりスタートしておりまして、実際に創薬化学推進グループ、現在のグループの前身のグループのやつは、こちらが発足したのが2019年。この時には、ロケットスタートを目指し、エキスパート人材の獲得、並びに循環型の人材育成、こちらはこう実をいたしますが、そして、エキサウィザーズさんとの協業というのを行い、加速しながらチームビルティングするという戦略を取ってまいりました。この後、各プロジェクトへD4推進を進めており、データ利活用の推進、協業の進化、そして基盤を作ると同時に、実プロジェクトへの組み込みというのも、2022年には取り組んでおります。さらに、2021年にはD4創薬を定常的に実践するであるとか、データの可視化、解析基盤の強化、並びに人材育成の強化というのも進めてまいりました。最近になってからは、データサイエンス人材など専門性の高い人材を、さらに積極的に獲得する。また、合わせてデータ解析のみならず、積極的なデータ構造提案なども取り組んでいるということをやっておりました。2023年からは、大規模な計算環境の構築というところで、東京愛の参画なども進めております。2024年には、第一産協、RTのバリの統合等もあり、組織体制を新たに進化費環境の構築、合わせて先ほど申し上げました、マルチモダリティに対してのインフォマティクスの適用というのも進めております。こちらのスライドでは、私個人的に考えるデータ工藤型創造力を支えるものというのを、一枚のスライドでお示しさせていただければと思います。弊社は、サイエンスアンドテクノロジーを非常に大切にする企業ですけれども、こちらを支えるのは、人材、コア技術、組織文化であるというふうに考えておりまして、人材の部分に関しては、創薬のドメイン知識があり、かつ、ケモインフォのスキルセットであったり、ITスキルがある人材が必要かなと考えております。コア技術に関しては、これまで蓄積されてきました創薬研究のノウハウ、また、蓄積されたデータ、研究者の皆様の経験、そしてサイエンス力、また、これらを活かす上では、組織文化としてチャレンジマインドであったり、ダイバーシティ、また、デジタル活用へ向けての意識改革ですね。こちらの方も非常に重視して、全体を含めてDXを進めるという政策をとっております。ここからは、先ほどお示ししたヒストリーに沿って活動を紹介させていただければと思います。まず最初がD4、フェーズ1から2という基盤構築、利活用の部分ですが、こちらに関しては、DSの創薬環境に適したデータサイエンスプラットフォームを構築というところが重要なところでして、柔軟性と継続性を重視した基盤構築というのを進めてまいりました。こちらに関しては、伴走できるパートナーと基盤を構築し、OJTを通じて人材育成していくという戦略を採用しております。人材育成に関しまして、こちらのスライドで説明させていただければと思います。こちらの色が違う人の絵があると思うんですけども、青色はデータサイエンスプラットフォームなんですけども、もともとウェット研究者で、それがドライにコンバートした方。そしてグリーン屋ももともと情報科学専門の方。灰色がウェットの研究者の方。そしてそこから一定の期間、ドライを学んで戻っていかれる方。これを我々、DXメズケームと呼んでいるんですが、そちらの方を赤くしています。D4チームができた当初というのは、ウェットからコンバートしてきたドライの研究員、それの後はエキスパートの方、キャリア採用の方を取ったチームと、メドケームの方で構成されたチームとしてスタートしました。この方、特にウェットの方は、この活動を通じて、ドライの知識を取り込んでいって、数年経つと赤い、DXメドケームという方になるわけですけども、この方は1滴考えて、メドケームのラボに戻っていただく。また、それと入れ替わりで、新しいメドケームの方が来られると。このサイクルをぐるぐる回すことによって、ドライにも親和性のあるメドケームの方を、どんどん育成していくというスタイルを取ってまいりました。併せて、近年は非常にスピードが速く、AIのテクノロジーが進化していきますので、そちらに対応すべく、データサイエンスと、もともと情報科学専門の方をチームに採用しまして、さらに多様性に富んだチームで、現在、いろんなことを進めております。情報科学の専門家と、創薬科学の専門家が、同じチームで議論するということで、ウェットとドライの橋渡しが、非常にスムーズにいく体制になっているんじゃないかな、というふうに考えております。バンスド型の協業というところですけれども、こちらに関しては、古いプレスリリースをこちらにお示ししましたが、AIベンチャーのXAウィザードさんと、長い期間協業させていただいておりまして、まずは、低分子類、気持ちのデータ、クロータスドラガンの実現というところから、スタートしてまいりました。XAウィザードさんは、AIに非常に強い枠のみならず、創薬のドメイン知識もあるというところで、我々と創薬を介さずに議論しながら、いろいろ試行錯誤できるというところで、非常に適したパーツナーであろうという判断をしまして、協業を進めてまいりました。伴走型協業におけるAI基盤の構築というところで、こちらの成果物を何個かお示しさせていただきます。これは実際、協業した結果、得られた社内データを使って、論文化した事例ですけれども、7000ほどのカオーズと、社内の400の解明室のパネラスデータを用いまして、シングルタスク、またマルチタスクの学習における活性予測のモデルの性能を比較したというものになります。こちらでは、ディープラーニング、グラフニューラルネットワークを使った予測モデルと、トラディショナルなマシンラーニングモデル、具体的にはSVMですとか、ランダムフォレスト、ライトGVMといったモデルですけれども、これらを比較性能を検証したというものになります。また、併せてSARの解釈における説明可能性の検証というのもしてまいりました。詳細につきましては、こちらのACSオメガの論文をご覧いただければと思います。こちらの論文の中身一部抜粋ですけれども、この研究を通じて我々が得られた知見としましては、グラフニューラルネットワークは非常に注目されている研究、アルゴリズムであります。こちらのグラフニューラルネットワークを使うことによって、カイネースとリガンドの相互性の重要な部分というのを、学習しているということが示されました。こちらの予測の結果、結合、活性に重要であるというところを、赤くハイライトするような可視化をした例ですけれども、実際にカイネースのヒンジ部分と相互性をしているところであったり、インタラクションに重要な部分がハイライトされているということが見られました。また、マルチタスクとシングルタスク両方のモデルでの性能検証をしたのですが、マルチタスクが有効なケースというのは、類演構造があるカイネースに限られているという知見が得られました。こちらも非常にリーズナブルな結果かなというふうに考えております。また、合わせて、グラフニューラルネットワーク、ディープラーニングが、既存の学習手法よりも非常に優れているわけではないということも、この実験結果より得られました。例えば、LightGBMなどは、多くのタスクにおいて安定した性能を示すということが分かりました。このような様々な知見を加味して、新規学習パッケージ、EXA-CAMというのを開発し、それを自社のプロジェクトで展開するということを、その次に進めました。これはEXA-CAMを実際に利用している事例というのを、簡単にお示ししたスライドになります。EXA-CAMというのは、EXA-Wizardさんと共同で開発した機械学習のパッケージになりますけれども、それを社内のデータと合わせて使うことで、こちらでは、インハウスのデータを自動で取得して、EXA-CAMを使い、学習モデルを構築。ユーザー側は、アクセリスドローですとか、他のユーザーフレンドリーなスケッチャーの方から構造を書いていただき、ボタンを押すと、様々な速モデルが走って、結果が見えるという仕組みを作っております。ここがポイントとしましては、KEMISTの方については、裏側の難しいところは全然関与せずに、単にドローアーで構造を書けば予測データがやれるというところ、ユーザビリティを意識したツクインシティというところです。また、こちらのモデルを作る部分に関しましても、兵、グループ全員がコードを書けるわけではないのですが、パイプラインパイロットなどを利用しまして、コードを書かないでも、モデルは簡単に作れる仕組みを作っていますので、多くの方が簡単に、自分のインハウスのデータを使ったモデルを作れるというところも工夫しております。この結果で、実際にプロジェクトで使っていただいて、かなり精度が出るアドメのパラメータに関しては、予測モデルを使い、工事評価に進む仕組みの選抜を行うというフローで、ビボの工夫カボットを選ぶということを実際に行いました。これ何を意味しているかと言いますと、インビトの評価の代わりに予測の結果を使って、カボット選抜をしたというところでして、これまでなかなか弊社でこういう事例がなかったので、一つの大きな成果かなというふうに考えております。実際に後でインビトのデータも取ったんですけれども、多くのケースで非常にインビトの結果と予測の結果が一致しているというデータが得られております。Haze 1、2の昇格ですけれども、まず最初にAI装着に必要なHPC基盤、特にこの時はAWSクラウドを利用していますけれども、こちらを構築しました。ついで公共データを使いまして、AI適用による技術特性評価というのを行い、十分使えるという判断、またスコープ&リミテーションを把握した上で、インハウスへの適用、そして実際のプロジェクトへの応用というところまで進んでいったというところです。現在ではXA系が多くのプロジェクトで、まだ利用されているという状況になっております。続きましてフェーズ3ですけれども、こちらに関しては、さらに次のステップAというところで、大規模データ活用基盤の構築というのを進めてまいりました。こちらのJとしましては、大規模バーチャルスクリーニングと、GPU活用基盤の構築というのを紹介させていただければと思っております。まずはじめに、大規模バーチャルスクリーニング、ULVSというふうに訳されますが、こちらに関してのお話をさせていただければと思います。釈迦に説法にはなりますけれども、ウルトララージバーチャルスクリーニングというのは、近年様々な論文が出ておりますが、大規模な化合物データを活用したバーチャルスクリーニングを行い、広大なキミカルスペースを短期間に探索、新しいヒットを獲得する手法だというふうに言います。近年、3枚の報告が増えておりまして、我々D4でもこのような基盤を社内で構築して、どんどんプロジェクトに適応していくというのを目指しています。目指し、活動を始めました。今回のウルトララージバーチャルスクリーニング基盤の構築の基本方針をこちらにお示しします。まず1点目は、ウルトララージですので、当然ですが、大規模なデータを扱える。例えば、エナミンのリアル、ビリオンスケールのカーブルを扱えるということ。そして、計算リソースをフル活用できる環境にするというところも一つのポイントとしました。具体的には、マシンリソースを十分使える。マシンリソースがあればあるだけスケールするような環境にしたいというところで、オープンソース、ソフトウェアを基益とした開発というのをまずポイントにしました。また、合わせてGPUの利用というのも視野に入れるようにするというのを基本方針に入れております。また、計算のみならず、カオーズ入手のフローというのも含めて、効率的なフローを開発するというのを目指しました。こちらに関しては、実際に計算終わった後でカオーズの入手が非常に時間がかかってしまうと、トータルでのスピードが出ないというところで、こちらも重要なファクターかというふうに考えております。計算環境に関しましては、先ほどのエクサケムでも一緒に仕事をしてきました、エクサビザーズ社と協業で環境構築をするというふうにしております。現時点で構築したバーチャルスクリングのワークフローの簡単な概略をこちらにお示しします。この仕組み自体は2回ドッキングを行うというフローを前提にしておりまして、まず最初に対象とするカオーズセット、数字力のカオーズセットから一定の数をサンプリングし、ドッキングを行います。ここを我々はドックワンというふうに呼んでいますが、ここでドッキングスコアを算出、まずある程度のカオーズで動かれます。このデータを使いまして、ドッキングスコアを予測するモデルというのを構築し、このモデルを使い、全カオーズ、ビリオンのカオーズのスコアを予測、そして予測されて、高スコアを示す、高スコアであると予測されたカオーズについて、もう一度ドッキングを行う、ドックツーを行うというフローになっております。具体的にパフォーマンスがどれほどなのかというのを、こちらのスライドでお示ししますが、データプレパレーションを行い、ドッキング、ここは数はケースバイケースなんですが、例えば400番くらいのカオーズをドッキングを行い、次いでこのデータを使って予測モデルを作る、そして実際にカオーズ、6ビリオンのカオーズを予測にかけて、その中からスコアが良いと判定されたトップ1%をドッキングするというようなフローですと、ここの60億のカオーズの予測に関しては、もう1日くらいで終わりますし、その後のドッキングに関しても、1週間くらいで終わるというようなフローになっております。ドッキングの計算に関しましては、現在さらにスピードアップしているというところで、この計算自体はかなり短期間で終わるフローになってきているかというところです。この後はカオーズは商用のものであれば買いますし、合成するような場合は車内で合成するなど、ここは使うカオーズソースによって切り替えるということが可能になっております。こちらのフローに関しましては、およそ数ヶ月でプログラム自体を完成させまして、実際にテーマにどんどん投入するというふうに進めておりまして、こちらに関して、計算科学者、創薬科学者、薬理研究者の協力体制、また合わせて開発したUltra Large Virtual Screenの基盤を活用することで、難標的からヒットカオーズを短期間に獲得できるという成果が得られております。また、今年度はこのフローを使いまして、複数標的にVirtual Screenを行うということもやっております。続いてはGPU活用基盤というところで紹介させていただければと思います。開発したUltra Large Virtual Screenの基盤というのは、基本的に今、クラウド上でのものなんですけれども、これをさらに高速化したいというところ。合わせて、最近最新のアルゴリズムというのは、論文と同時にコードも公開されることが多いかと思うんですけれども、GPUリソースがそもそもない場合、検証自体が困難ということが増えてきたかと思います。また、合わせて、こういうGPUを使いこなせる、GPU HPC基盤を使いこなせる人材というのも育成していかないと、この辺りのフォローアップができないと。この辺りが課題であり、解決するポイントかなというふうに考えました。また、合わせてDXの推進というところでは、先ほどの予測モデルでもお話をしたんですが、ツールの民主化というのは非常に重要だと思ってまして、ユーザビリティの高いAIツールを作るというのも、一つのポイントかなと考えております。この辺りを満足するような基盤構築というのが大事だろうというふうに考えました。まずはじめにGPU計算基盤の部分ですけれども、弊社は東京ワンプロジェクトに参加させていただいております。こちら、最先端のGPU H100を搭載したDGXを使えるというところ。合わせて、現在弊社とオネ薬品さん、アスティラスさんが入っているというところで、非競争領域で議論がいろいろできるというところで人材を育成できる。他社のエキスパート皆様と議論できるというところで、非常に人材育成にもいいんじゃないかなというふうに考えました。大規模なモデル研究への活用が進むのだろうというところで、強固なデータサイエンス基盤の構築と、データ空型装置のさらなる推進に十分これは使えるものだろうというところで、三角を決めました。実際にこれを使って何をするかというところの事例をここから紹介させていただきます。まず一つは、Alpha Hold 3 Chromeというふうに言っていますが、ホールディングAIの検証という部分になります。Alpha Hold 3自体は、所要利用がライセンス的にできないものだったので、こういったものをどうするかというのが弊社でもずっと議論をしていたんですが、近年になって、Voltz1ですとかChai1、こういった所要利用可能なものがどんどん論文で発表されるようになりました。ですので、こういったものを随時、東京湾上で実装し、いち早く有効性を検証するという体制を現在作っております。こちらには最新のPDBを予測した結果をお示ししております。例えば、Voltz1を使って予測した結果なんですけれども、このグリーンの方が実験結果、PDBから取ってきた情報、そして配列だけを入れ込んだ予測の結果がブルーになってまして、重ねたものがこちらの図になるんですが、見ていただくと分かりますように、この事例では非常に良い精度で、複合った予測ができているかなというのが見えるかと思います。また、この事例ではリガンドタンパクだけだったんですが、リガンドのみならず、コファクターを含むような経緯において、予測させてみても、こちらも結構、リガンドそのものは、ポーズがピシッと決まっているわけではないんですが、ほぼハマっている位置などは一致しているというところで、精度よく配列だけから予測できるなという感触を得ておりまして、現在、社内での結晶データなども使った検証であったり、今後の利用、リガチュアについての議論というのを進めているところになります。こちら、この2枚のスライドのみなんですけれども、検証用のコンテナというのを迅速に構築し、現在、インハワースのデータを用いて、引き続き、東京版上での性能検証などを進めております。先ほどのスライドでは、非常にうまくいった事例を示したというところがありますが、予測精度自体は標的によって異なっているというのが実際のところでして、今後さらなる検証、どういうものだったら使えるかというのを見極めるというのが必要かなと思っています。計算に関しては、クラウド、オンプレ、東京の複合も含めて、GPU基盤というのを現在整備しておりまして、非常に大きなVRAMがないと検証できないようなものなどもあるんですが、この辺りも東京を使うことによって検証できるというところがあるので、非常に入って良かったかなというふうに思っているところです。パブリックなデータを用いたモデルですが、社内のデータを外部テストデータとして利用することで、今後さらなるSBDの強化につなげられないかというのを、今議論しているというところになります。こちらはGPU基盤の活用事例2番というところで、VionにもTotoCanを掛け合わせているという例になります。特に私が最近試して便利だなと思ったNIMという、NVIDIAのほうから提供されている、Ready-to-Useのモデルを使うというところでして、NIMの中のエージェントブループリントというのを利用することで、最先端のAIモデルが、REST経由で簡単に利用可能になるというのに、非常に魅力を感じました。また、この辺りのモデルに関しては、GPUリソースが非常に求められるものなんですが、これもTOKYOが活用することで、非常に高速に動くというのが、一つのメリットかなと思っております。先ほど、このNIMはRESTを使って動かせるというふうに申し上げたんですが、何が私にとってそれで良かったのかというのを、こちらのスライドでお示ししたいんですけれども、弊社では現在、SRの解析基盤として、データグロックというのを利用しております。こちらで、KEMISとの方へのSR表ですとか、デザインアイデアシェアのプラットフォームなどを提供しています。このデータグロックなんですが、REST APIとの通信というのもできるというところで、このデータグロックと先ほどのNIMを組み合わせることによって、緊急者が最先端のAIモデルを簡単に使うようになると。これは先ほど申し上げた民主化のつながらというところで、非常に面白いんじゃないかなというふうに思ったところになります。こちらは非常にシンプルなGなんですけれども、先ほどのNIMではDIFドックですとか、アルファフォールド2、最近ですとMorgenというGenerativeモデルなども提供しておりまして、それらとこのデータグロックをREST APIでつなぐということができまして、社内でこれは検討した結果なんですけれども、このようにDIFドックとデータグロックを連携させることによって、ユーザー側ではここのスペッドシートみたいなところに構造を書いて、バイオにもDIFドックと選ぶだけで、裏では東京ワンジョインジョブを投入して、DIFドックが動く。結果はこのような同じ画面上で見えるというようなことが、すぐに実装できているという形になりました。ユーザー側は2次元で構造をスケッチして、DIFドックがおしまい、フォスターの裏でニューノブループリントに搭載されたコンテナが動いている。結果が返ってくるという仕組みになっていまして、非常に簡便にこういう生成モデルであったり、予測モデルを使えるようになりました。このような形でフェーズ3を進めてきましたが、構築してきたInformaticsの基盤活用進化というところで、ウルトララジバーチャルスクリーンの基盤構築、合わせてそれの実践投入というのをしてまいりました。またGPU、HPC基盤の構築というところですけれども、東京への三角、利活用の推進、社内外のネットワークの構築、人材育成の部分ですね。エキスパート人材育成というところ、これはコミュニティ活動も含めて、その人材をどんどん育成していくというのを進めているという状態になります。最後に、これまとめと今後というところなんですけれども、D4に関しまして、弊社では2019年よりスタートし、チームビルディングと合わせて文化情勢も進めており、徐々に成果が出つあるかなというふうに思っております。例えば予測モデルの利活用、非常に多くの研究者が使っていただけるようになったと。あとは効果測定方法の冊真、これはインフォマティクス導入の効果というのをどう測定するかというのは、非常に難しい部分があるんですが、こちらに関してもいろいろ試行錯誤しながらやっているというところになります。併せて、モノトイというところの主眼を置きますと、バーチャルスキングの基盤構築であったり、GPU、HPC基盤構築とも進めてまいりました。併せて、今後担う人材の育成というところも進めております。本日は紹介はしませんでしたが、弊社でもLLMの利活用なども進めておりまして、特に我々のチームではコードを書くメンバーが多いんですが、コーディング等にも、チャットGPTみたいなコードアシスタントを使って、書いたことがない言語を使って実装するという点も出てきております。先ほどのデータグロックとの連携等においても、こういうコーディングアシスタントを使って、非常にスピーディーに実装が進んでいるという状況があります。今後ですけれども、変化進展の早い創薬の流れを的確に捉えて、現役に貢献していくというのが、引き続き続けていきたいと考えております。具体的には、マルチモダリティの展開、あとは、ラブオートメーションとの連携、インシリコのみならず、ウェットの部分の強化、そことのインテグレーションというのが大事かなと思っております。また、こういった活動を通じて、より明確なD4のプロジェクトへの貢献、キャンディデートを獲得に対してのクリアな貢献というのを、出していけたらよいかなというふうに考えております。最後になりますが、こちらの活動に関しては、非常に多くの方のサポート、協力、これは社内のみならず、社外の皆様の協力あっての活動の成果を、代表して発表させていただきました。引き続き、皆様と議論できればなと思っております。本日はご清聴どうもありがとうございました。それでは私のプレゼンテーションは、こちらでおしまいとさせていただきます。