各位同仁,线上的观众朋友们,大家好我叫杨奎元,来自小米汽车自动驾驶与机器人部小米汽车是2021年正式立项作为2021年加入的首批自驾团队成员我全程参与了小米苏基智能驾驶功能从研发到量产再到OTA持续进化的全周期工作今天我和大家分享的主题是端到端全场景智能驾驶这也是我们刚刚全量OTA推中的最新自驾功能首先让我们聚焦端到端这个技术之高点区别于传统的模块化架构端到端从输入端到输出端完全由深度神经网络建模由之前的感知模型化拓展到了感知归控模型化更彻底地使用数据驱动和模型泛化的能力应对复杂多变的物理世界全场景智驾只是对用户体验的完全重塑过往用户需要在高速、城区、泊车等不同场景分别手动切换对应的功能模块而全场景实现了从车位启动时的自主播出到城市领域再到高速旅行再回到城市领域最终搏入车位的全场景连续的自驾体验下面的分享将围绕如何构建在物理世界中乳帮运行的端到端智能驾驶系统展开分为四部分内容前两部分首先介绍物理世界探索和物理世界建模这是理解物理世界构建智能驾驶系统的基础后两部分是具体的应用实践包含工程落地优化和持续演进、持续交付的自驾功能以世界复杂多变即使将范围限定到交通场景也十分复杂包含复杂的天气光照变化、道路结构变化、行人车辆的复杂行为还有形态各异的常委场景对物理世界的充分探索是机器对物理世界从未知到已知形成全面认知的前提根据机器对物理世界探索的参与程度可以分为两大阶段第一个探索阶段由人类主导对物理世界的建模也主要依赖于人类的大脑在这个阶段典型的信息处理机器如计算机、手机没有自主移动能力我要通过人类整理的文字、图像、视频等数字化信息获取物理世界的部分描述得益于这些人类记录的含量数据也驱动了近期大语言模型的迅猛发展然而人类通常只会记录对人类有价值的信息比如人类只会拍摄一些有纪念意义的照片对物理世界的记录并不连续和完整这种不连续和不完整的记录也限制了机器对物理世界的全面认知随着聚生智能的发展机器开始直接参与到物理世界的探索比如汽车、机器人等他们通过传感器观测物理世界通过执行器在物理世界中自主移动中二可以得到更全面更连续的物理世界描述通过含量连续的多模态的数据我们可以训练更全面的AI模型持续提升机器在物理世界中的适应能力以小米汽车为例目前已经量产交付近一年的苏7系列刚刚量产交付的苏7Ultra以及即将量产的YU7我们在设计这些车型时充分考虑了物理世界探索和实践高阶自驾的需求从外观上我们可以看到在传感器选行和安装上保存了不同车型间的硬件一致性进而保证了数据在不同车型的通用性打好了规模化探索物理世界的硬件基础具体来讲为了实现环境的完整观测以及全场景自驾功能如泊车场景的近距离盲区覆盖高速场景的远距离探测城区路口更宽的横向覆盖小米汽车在车身周围全系标配了11颗高清摄像头形成车身周围360度无盲区的覆盖高配额外增加了前向激光雷达进一步加强前向的感知能力小米苏7去年3月份上世纪交付后得到了广大用户的充分认可销量逐越攀升目前参与物理世界探索的苏7车队规模已经超过18万辆苏7AUCHO也刚刚加入到了物理世界探索的车队整个车队规模以每月超过2万辆的速度快速增长车队规模的快速增长也带来了行驶里程的快速增加去年年底车队每天行驶总里程超过5万万公里目前每天行驶总里程已经接近1000万公里作为参考全国公路总里程为500多万公里苏7车队每天行驶总里程可以覆盖全国公路的一倍以上当然不同路段的覆盖品质并不相同第二次里程的快速爬升也带来了全场景数据的快速累积下面展示了打通全场景自驾的4个关键难力场景停车场ETC收费站城区环岛乡村道路Dunaldun模型需要的训练数据以连续的视频片段Clip为单位每个Clip包含20秒左右的连续传感期数据在去年9月出版Dunaldun模型训练时我们使用了238万Clips经过4个月的积累训练数据已经增加到了1360万Clips这也是我们下一个千万ClipsDunaldun版本所用的训练数据量有了丰富的物理世界探索数据后下面我们进入分享的第二部分物理世界建模我们把整个建模分为三层第一层计为大OT是原始的数据观测层通过车身上多个高分辨率传感器详细记录真实场景当前状态第二层计为大JT是深度神经网络的隐私特征层通过数据驱动的方式形成对当前场景的理解第三层计为大ST是方便人理解和操作的显示符号层左边数据观测层展示了用车身多目相机拍摄的一个行人轨探头场景数据观测层层于底层表达机器无法直接理解需要通过模型生成更高层的理解性用于未来的决策规划也就是隐私的特征表示中间这幅图是在BV空间将高纬隐私特征通过PCA降维后生成的可视化可以看到周边的车辆左前方轨探头行人在特征图上都有清晰的响意甚至被位体内遮挡的区域也有不同的响意当然还有很多其他高纹信息无法在PCA空间展示为了方便人理解以及对接人工规则代码模型会解码出显示的符号表达如静态的车套线斑马线等动态的行人车辆等这些也是监督学习中人工增值标注或者自动化增值标注的表达形式在端到端犯式中还会解码出自车的规划轨迹比如在这个场景中绿色轨迹线代表了合理安全的理浪行为红色轨迹线则代表了危险的不理浪行为当然三层建模是一种粗粒度的划分每一层内部还可以细化为更多的层比如图像金字塔中的多层分辨率图像深度神经网络中不同影尘的特征表示等对于前面介绍的物理世界建模的三层表示具体对应为深度神经网络中的输入层中间影尘和输出层数据观测层大欧体作为神经网络的输入层其中包含了图像点云以及领航功能所需要的导航信息通过BUE编码网络得到隐私的特征表达大GT通过不同的解码器可以分别得到动态元素静态元素以及自车的未来轨迹其中动态元素在场景中分布较为稀疏局部且不同个体运动状态不同需要单独维护各自的历史信息我们使用带有Memory的18式方案进行建模静态元素则相反我们直接采用Dance方案进行建模自责可能的轨迹则是充分考虑了动静态信息之后解码生成最终通过人工设计的cost如何其他战亡计算的碰撞cost和车道线计算的偏离车道cost分纵向Jek计算的舒适性cost用于约束轨迹的合理性整个神经网络的训练由人工定义在最后一层的Loss驱动包含动静态元素和真实之间的差异自射轨迹模仿人价轨迹的差异以及人工设计的多个cost这也是一个复杂的动态系统它还有个重要的维度也就是时间维度已经过去的历史帧有直接的长感级观测建模相对容易而未来帧在车端实施系统中无法直接观测是建模的难点也是重点因为自射主要关心在未来一段时间内的表现前面介绍的三层表帧模型每层在实去建模上都有很高的这些组织的表现这些组织的表现是一个复杂的动态系统每层在实去建模上都有很多优秀的工作可以借鉴下面我们将数据观测层隐私特征层显示符号层从下到上的顺序分别介绍数据观测层典型的信号如视频流目前已经有很多相对成熟的AI技术可以使用如3DGS重建技术Diffusion Autoregression生成技术典型的工作有OpenAI的SoraDeepMind的Jenny到英伟达的Cosmos等这些生成大模型通过直接拟合原始数据的概率分布加上额外使用历史帧图像隐私特征显示符号等控制条件可以进行原始信号的生成这些模型目前生成速度较慢这些模型目前生成速度较慢主要在云端仿真物理世界由于感知载环的闭环仿真评测以及长尾数据的生成这些生成模型通常也需要使用隐私特征但主要次重于传感器细节信号的恢复在理解任务上性能欠佳最近也有些工作开始尝试同时用于生成和理解的隐私特征空间由于隐私特征层和模型相关直接基于隐私特征层进行持续预测的工作还不多近期杨仁坤主提出了Dino World Model直接在Dino V2预训练模型的基础上构建的隐私特征空间进行未来真特征预测从而完成预线设定的目标任务在智能驾驶领域目前还没有成熟的基座模型可以用于生成稳定的特征表达显示符号层类似自然语言表达人工可以直接编码操作借助人类对物理世界已经具备的建模能力可以通过规则代码的方式和模型结合完成时序上的建模如后处理经常使用的运动学模型如云速模型、云加速模型等规控常用的轨迹采样、搜索和优化等在端到端的方式中显示符号层也可以用于显示定义cost对应强化学习中的流落等驱动策略学习另外受大模型scaling law 启发清华造航教授和理想合作的State Transformer苹果、Codent组的CellPlay等工作在显示符号层通过增大数据量也验证了Scaling law对自驾任务的有效性结合各层时序建模的优秀实践我们也在尝试将三层表达联合起来进行实践建模在车端推理时预测未来帧的传感器数据不是必选项在云端训练时离线录制的未来帧数据只可以用于提供模型训练的自建录信号可以在之前介绍的深度神经网络模型上将中间的影视特征在实续维度上拓载到未来帧由此可以形成完整的时空神经网络模型统一由数据驱动学习具体的来说由于动静态元素在未来帧的变化方式不同静态元素的变化主要和自车运动相关而动态元素的变化由他们各自的运动和自车运动共同决定因此在未来帧预测变化时我们同样对动静态元素分开处理为了使得上述模型在云端能够高效顺链在车端能够高效推理我们联合英伟达进行了大量的工程优化这张表列举了一些例子在云端优化上我们将新伟达X-Hiton总共云端推理BubbleLine将自动化标注大模型推理的利用力提升了一倍基于搭力CPU-CULA优化顺链瓶颈将GPU利用力提升了30%车端算力相对有限我们在模型设计时充分考虑了数据的内在特性如吸收性2D到3D几何的对应关系等减少了模型不必要的连接另外在端测实际部署后Profiling出了多个支持不好的耗时算子进行了20%到40%的加速特别是在最新的12平台上整体性能相对出个部署版本加速了一倍为了进一步减少GPU的算力消耗我们把图像前处理点云数据压缩Offload到了VIC,ISP,NV,Encoder等E-GPU计算单元上在AOS电影的技术发布会上雷总首次公开了物理世界建模的几项关键技术包括适用于不同场景的变焦BV技术应对一般障碍物的超分辨率OCC技术以及感知决策一体模型基于物理世界建模能力的提升加上相应的工程度的音化24年我们在智能驾驶上实现了一年追三代的快速追赶从基于高晶地图模块化架构到去高晶地图模块化架构再到端到端架构在场景拓展方面去年三月份量产交付时苏七全市搭展了高速领航组端安全带客泊车辅助泊车辅助泊车等成熟钢需功能在后续OTA升级中首先开通了实陈的城区领航经过三个月拓展到了全国都能开以及最新全量推送的端到端全场景支架目前我们正在准备基于千万克里普斯的端到端版本最后做一下简单总结对于交通场景这位高阶自驾能力的量产车已经具备规模化探索物理世界的能力形成了必要的数据基础借助数据驱动的深度学习模型已经具备系统化建模物理世界的三层时序模型框架在上述物理世界建模能力的基础上我们持续交付的自驾功能由相对简单的高速驳车场景拓展到了复杂的程序场景近期打通了各场景行车的全场景车位到车位的完整体面以上就是这次分享的全部内容谢谢大家下面是问答环节欢迎大家提问