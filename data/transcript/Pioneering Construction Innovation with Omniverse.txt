 Hello everyone, I'm Jérôme Loïc, I work at Bouygues Construction and it's a great pleasure for me to be here for this presentation. Today I will present how we use NVIDIA Omniverse to pioneer construction innovation. Since last year we are the first general contractor to explore NVIDIA Omniverse for design and construction and I am really happy about that because it perfectly illustrates our pioneering spirits. Construction in the construction industry is a key focus for us. It is one of the main drivers of growth for companies seeking to stay ahead. In the past, only major players had the resources to tackle these challenges. And today, technology is making things fair for all companies and they are using innovation to meet client needs and stay competitive. At Bouygues Construction, we are committed to identifying new solutions, innovating and acting quickly to stay ahead. The new innovation strategy is crucial for improving performance. Our goal is to solve real problems that impact our work and our ability to create value. Unlike basic research, our focus is on practical solutions that drive progress on our construction sites. We are committed to prioritizing safety, leading in sustainability and driving digital transformation. And in this time of rapid change, we are driven by a common goal to drive progress that truly makes sense, meets environmental and operational challenges, and rethink what's possible in modern construction. For me, it is incredible to see the changes in the last 15 years in the way we manage, design and build our projects. I remember that in 2010, my first project was a hospital and we produced 3D models of the projects into Autodesk Gravit to explore different use cases, like coordination or quantity extraction. It was a 3D modeling demo project in North of France. And from there, I had the privilege to contribute to deploying BIM, building information modeling, for residential buildings, public facilities or renovation. And today, it's remarkable to see how far we've come and how much the landscape has changed. The importance of quality, safety and meeting delivery deadlines has driven us to adopt new solutions. In France, the adoption of BIM has grown over the years. Initially, at BIM construction, it was driven internally, but gradually, I saw a wider adoption by key stakeholders, like architects, consultants or subcontractors. Implementing use cases on projects is not straightforward and we continue to face challenges. One significant issue is interoperability. Recently, I work on an industrial project involving multiple stakeholders using different softwares to produce 3D models of building components. These components included industrial processes, robotics, steel structures, concrete structures, piping and technical specialties. I spent several weeks finding a comprehensive solution for file exchange, including file formats, metadata and georeferencing. And trust me, it was incredibly time consuming. Another challenge is integrating engineering technologies, such as BIM with information technologies like databases, and operational technologies like IoT or sensors. The construction sites are dynamic environments and digital tools must adapt to real-world conditions, providing more accurate simulations to support better decision making. Universal scene description and omniverse application development are great opportunities to tackle these challenges. In recent years, I have seen several technologies like 3D modeling provides a better understanding of what we design and what we need to build. The BIM ensures collaboration among teams. 3D scanning gives us a precise understanding of the built environment. Virtual reality allows us to immerse ourselves in a project for decision making. 4D scanning, construction apps to visualize plans and 3D models on site using tablets, improving safety and quality inspection in real time. 4D scanning, data to bring different information from different sources to take better decisions. 5D scanning, data to bring different information from different sources to take better decisions. We often hear about the concept of having a single source of truth in project management. But from my experience, I believe there are actually multiple sources of truth. NVIDIA Omniverse can bring these different sources of truth, connected with different technologies into a single ecosystem, where we can simulate, collaborate and optimize every aspect of a project in real time. Before diving deeper into this presentation, let me briefly tell you about BWIG construction. I know that in English it's a bit tricky to pronounce, but it's BWIG. BWIG Group is a large and diversified global company with four main breaches. Construction, Energies and Services, Media and Telecoms. At BWIG Construction, we have a team of more than 32,000 employees working around the world. Last year, our sales reached 9.8 billion euros. What's important to note is that 60% of our sales come from projects outside of France, and half of our business is driven by major projects across the globe. We operate in more than 50 countries including France, Australia, Hong Kong, Switzerland and United States. Being a company that works across the entire value chain and in so many countries, give us a unique advantage. We can share and apply the best innovative practices from one project to another, whether it's from Hong Kong to Miami, from civil works to buildings or across various teams. Here we can see the different types of projects we work on, energy, transport, industry, public utilities, commercial buildings, residential buildings. And a great example of our expertise is the Olympic Aquatic Center built for the Paris 2024 Games. This project showcases our ability to innovate, our commitment to sustainability and our pursuit to excellence. In the construction industry, safety is not just a priority, it's our responsibility. At BWIG Construction, it is our most important commitment. Our ambition is clear, create and maintain safe work environments for everyone. We go beyond regulations to prevent serious accidents for all stakeholders, employees, temporary workers and partners. Lead the way in safety culture and results. We aim to be the best in our industry, in every country where we operate. We guarantee the safety of our construction sites and facilities. We protect our teams from external risks that could impact their safety and well-being. We focus on six main risks that cause 80% of the most serious accidents. Risks related to mechanical lifting and handling. Work at eight. Work at eight. Stability of works and storage. Risks of collision related to the presence of vehicles and pedestrians. Hazardous energies. And finally, risks related to power production equipment. These risks are a big challenge. And I think that digital tools can be an extra shield to protect us. With NVIDIA Omniverse, we can create virtual construction sites. This allows us to see risks earlier, find better solutions and improve safety for everyone. And for several months, I have worked on examples of how to use this technology. Now, let me show you a short video to explain how Omniverse can help us to make construction safer and smarter. In order to develop and test construction specific applications, We construction R&D innovation department has created a virtual construction site within NVIDIA Omniverse. OpenUSD supports the unification of diverse 3D assets into a single scene, including the building structure, environment and construction equipment. We've combined different softwares such as Revit, Solidworks and Cision. We've combined different softwares such as Revit, Solidworks and Cision. We've combined different softwares such as Revit, Solidworks and Cision. This immersive 3D construction layout ensures a clear understanding of access points, storage zones and equipment locations. The RTX rendering provides high quality graphic quality, improving the visual experience. We've developed very different materials of-section, equipmenteny of a machine-collusion, ne frig它s ou trains, Pur so have having an unlimited size of different conditions. Interactive simulations enable the validation of clearance dimensions for construction vehicles, securing future interventions and facilitating the selection of the right equipment. The configuration of a construction site evolves every day, making it crucial to maintain a virtual replica that mirrors the physical sites. Dynamic data connectivity is essential for optimal tracking of predictions and progress on the site. I will provide more details, but we began simply with an Excel spreadsheet and we are now exploring sensor connectivity. In this example, we track the real-time position of the Jeep Tower crane using the MQTT protocol. Omniverse integrates a physical engine, allowing precise simulation of operations for both small and large equipment. The physics engine contributes to finding the best possible solutions. Finally, the generation of 3D synthetic data accelerating the training of computer vision models, which will be discussed more in detail in the presentation. In this video, you've seen how Omniverse helps us identify risks earlier and find better solutions. We've created this virtual construction site to develop use cases. Omniverse allows us to bring different 3D data sources into one shared scene. For example, the 3D environment with 3D tiles from Cesium, the building and construction site layout from Autodesk Revit, the site equipment from SolidWorks. As I mentioned earlier, people often talk about having a single source of truth, and I don't fully agree with that. But Omniverse helps us visualize multiple sources of truth in one place. By combining these sources, we can see the level of detail we need to understand complexity and reduce the gap between virtual and real-world conditions. Real-time composition is also key. It helps us to move from step-by-step workflows to iterative ones, making us more efficient. Omniverse offers the ability to associate data with 3D primitives, opening up powerful opportunities for visualization and interaction. This feature is highly extensible and can work with many different data sources. We explore two main approaches. The first one, we develop an Excel extension to link the primitives in a scene with an Excel spreadsheet. For example, we can change colors, visibility, and update positions. This helps us contextualize data and better understand complex processes. A good example is tracking the progress of structural work in a building. And if we can do this with Excel, we can do it with almost any other data source. We also explore using live sensor data with MQTT protocol. This sends information into an X-Form in Omniverse, allowing real-time updates to value, position, and rotation. With this, we can create a virtual shadow of a construction site, enabling real-time supervision of activities. To achieve this, we collaborated with StingTwin, a German company specializing in these solutions. Both approaches allow us to better visualize and interact with data, improving our ability to manage and optimize construction processes. Training an AI model requires carefully labeled high quality and diverse datasets to achieve the desired accuracy and performance. In many cases, data is limited, restricted, or unavailable. Collecting and labeling real-world data is time-consuming and can be extremely costly, which slows up the development of physical AI models and extends the time needed to find a solution. Synthetic data can help address this challenge. It is generated from computer simulations, generative AI models, or a combination of both. This data can include text, 2D or 3D images in both the visuals, which can be used alongside real-world data to train multi-model physical AI models. This approach reduces the training time and greatly lower costs. Gartner predicts that by 2030, most of the data used in AI will be generated artificially. This includes data created through rules, simulation, and statistical models. According to their reports, synthetic data will become essential. Without it, building high-quality AI models will be nearly impossible. Why use synthetic data in construction? It helps us in many ways. First, it speeds up the training of AI models. Real-time data can be hard to find or expensive to collect. Second, it addresses privacy and security concerns. Synthetic data protects sensitive information while it's still representing real-world situations. Third, it improves accuracy. We can include rare but important cases that are hard to find in real life. The models are also more accurate with the accuracy of bounding box or segmentation mask. Finally, synthetic data is extensible. We can generate as much as we need for many applications. For example, it helps with safety, progress tracking, or managing storage areas. On my way to generating synthetic data with Omniverse, I use Replicator. Let me give you a quick overview of the Replicator process. With Omniverse Replicator, we first create a scene with USD 3D content. Then, Replicator leverages the contextual scene synthesizer, domain randomizers, and the rendering engine to generate the synthetic data needed to train an AI model. For this use case, CAD files in step format were imported and converted into USD. A scene representing a concrete slab and walls was also created in Revit and exported in USD formats. Finally, environments available in the Omniverse library were used to generate the background. Here, you can see examples of 3D content in USD format originally from SolidWorks. These objects have been textured in Omniverse using MDL and PBR. The first step is to prepare the USD assets. In this example, we are working with a steel frame formwork which is widely used in the wall concrete construction. I started by uploading a step file originally from SolidWorks into Omniverse. After that, I modified the materials. Our objective here is to create synthetic data for the guard rail located at the top of the formwork. One of the key advantages of the USD format is flexibility. It allows us to classify, organize, and manipulate geometry. I will use the Pivot Tool extension to adjust the pivot point of the guard rail. By repositioning the pivot, we gain better control over its transformations. Variance and Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. This provides precise and realistic adjustments which are essential for generating high-quality synthetic data. For the environment, I use a Revit file converted into USD with the Revit connector. Now let's go through the Python script step by step. I am not a Python expert, but I use Omniverse documentation and followed some examples. First we import the OmniReplicator core library which is used to create to manage synthetic data workflows in Omniverse. Let's start the layer definition by creating a new layer on the USD stage with rep.newlayer. We define a local path where the output data will be saved. In this case, it's a folder on my computer called 2025 synthetic data. Next we define a function called RandomizeRotation. Its purpose is to change the rotation of a specific object into a scene. The object is a guardrail located at a specific path in the 3D scene. Inside this function, we use rep.modify.pause to apply random rotation to the object. The rotation angles are randomly chosen within a range between 50 and 90 degrees for this example. Finally, we register this function as a randomizer so it can be used during the synthetic data generation process. We set up a trigger to call the randomized rotation function 50 times once per frame. This means the rotation will be randomized in each frame. We locate an existing camera in the scene using its path. The camera is essential for capturing the synthetic data. If the camera is not found at the specific path, the script will be stopped and raise an error. Once the camera is found, we create a render project. It is the output image or video that the camera will generate. We set the resolution to 9020 by 1080 pixels. Next we initialize a writer. The writer is responsible for saving the synthetic data to a specific folder. Here we use a YOLO writer which is designed to save data in a format compatible with the YOLO object detection framework. The output files will be saved in a subfolder called Portillon under the defined local path. Finally, we call rep.orchestrator.preview to preview the results. This will allow us to see how the scene looks with the randomized rotation and camera setup before generating the synthetic data. The next step is to assign labels to the objects in the scene. This is essential for generating bounding boxes or masks needed to train an AI model. To achieve this, I use the Semantic Schema Editor. I create a new type called Class and specify a text value to add semantic data to the selected object. It is also possible to use the PrimNames to label objects automatically. Now you will be able to visualize the bounding boxes or masks associated with the semantic schema. How can you use the same type of image? Isaac Sims offers many possibilities such as RGB, instant segmentation, normals and semantic segmentation. It is also possible to combine different cameras to generate multiple points of view for each iteration. Now that we have generated our dataset, we can use it to train a model. We collaborated with SyncTwin to develop an extension that generates a zip file in the YOLO format ready for use with the synthetic data to train, validate and test our model. In this example, I use Ultralytics platform to visualize the bounding boxes, store my dataset and train my model. I can then easily test it using the mobile application. Now let's highlight the benefits of using 3D synthetic data for safety detection on construction equipment. Firstly, I've identified that the break-even point in terms of time savings is achieved around 80 images. This means that beyond this threshold, synthetic data becomes more efficient than traditional methods across all stages from data search and capture to preparation, labeling and image generation. Secondly, synthetic data generation, including the time for scene and script creation, is five times faster than real data when dealing with a dataset of 1000 photos. Additionally, there is a gain in terms of labeling quality as synthetic data allows us to include only the necessary pixels for labeling. With synthetic data generation in Omniverse, we can simulate dangerous situations in a virtual construction site and combine them with real data to train AI models. By recreating these scenarios using our own safety rules and 3D equipment, we aim to use computer vision technologies to detect hazardous situations and address major risks effectively. NVIDIA Cosmos is a major announcement earlier this year, highlights how technology continue to evolve rapidly. And at BIC Construction, we are committed to use this advancement to solve challenges in the construction industry. Thank you for watching my presentation. I hope you enjoy and have a great time at GTC 2025.