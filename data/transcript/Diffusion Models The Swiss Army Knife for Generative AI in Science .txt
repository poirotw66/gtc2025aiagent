 Thank you everyone for being here today. I know it's early talk and I know that you either choose this talk or maybe getting a good parking spot and that's why early today. I'm not gonna guess which one was the main reason why you're here today. So today I'm going to talk about diffusion models. I'm trying to create a case that diffusion models are strong frameworks for learning JLTF models in science. I'm coming from visual background actually. I did my PhD on computer vision very long time ago when computer vision was just a dream and it's working on actually image generation as early as 2015. This is image generated by DALI. It's a text to image model that takes the description and it generates this image. This was a dream for us coming through. Like for many years we never thought we can have this kind of capability. When it used to work we were struggling generating like single objects and like in an image and now this scene can generate very complex scenes multiple characters interacting with each other. It can generate avocado going through midlife crisis and saying I feel so empty to a psychiatrist in the shape of a spoon as well which is really cool. Anytime I want to create fear of missing art with scientists I show them this video. So this is a texture video it's generated by Sora. The input text caption says something like two battleships floating on top of a coffee mug and this is what Sora generates. So if you ever want to render the scene it's very hard problem. I have no idea actually how you can simulate this and render this and you need to understand physics of liquid water and you need to understand physics of light to be able to simulate this scene. But Sora has no understanding of physics like it's just a transformer giant transformer trained on massive amount of videos and Sora learns now how to you know how the liquid moves have in a battle like ships float on top of water and how light bounces from the surface of water right. So Sora can now simulate light and water for us. So this basically made us think that now we can maybe use Gen AI based tools for simulating you know physical world and physics. So today I'm going to try to talk to you a little bit about diffusion models and flows. I'm going to give you a very high level introduction to these frameworks. I'm going to walk you through four use cases that my team has has built in the past one year or so. And then I want to share some lessons that we learned like things that we failed and how we could fix some of the issues that we saw when we were building generative models on scientific applications. So let's get started with diffusion models and flows. So I always use a picture of my cat. His name is Peanut. You've probably seen him in some other presentation. I've used this picture so many times that even yesterday there was another speaker using this and I can guess the probably speaker doesn't know that that that picture is my cat's picture. He also made it to the Nobel lecture prize by the way. So this is my contribution to science. Mike, he's more famous than I am. So his name is Peanut. We're going to use Peanut to explain diffusion models. Diffusion models or score-based generative models consist of two processes. A forward process that is shown from left to right. We start from, forward process starts from the picture of Peanut and adds noise so many times iterative such that we can convert poor Peanut's picture to pure noise. Reverse process shown from right to left. So it's a reverse generative process. It starts from noise and it learns to generate data by iterative denoising. Right? So the reverse process is actually more exciting thing where now you can start generating pictures of Peanut from pure noise. It's a generative model. And that's what we try to learn with diffusion. We're trying to learn this denoising model. Mathematically, this forward process can be described with stochastic differential equations. If you're not familiar with SDEs, it's all good. I also had to learn about this when I started working with diffusion models. Think of it just a process that adds noise iteratively in so many steps. Right? So this is like some simple Brownian motion we use to add noise. And you can describe the reverse process either with the stochastic differential equations or ordinary differential equations. So here I'm going to use ODEs. In order to mimic this reverse process, you need to have access to this object that I'm showing you in red. So this object is called score function. It is the logarithmic derivative of the data likelihood at different time steps, at different noise levels. Right? So earlier I said in order to generate data, you need to have access to some, you need to learn a denoiser. Right? Denoiser just tells you how you can denoise. Think of that score function, something similar to denoise. It just tells you, think of a vector that tells you if you are here in the noisy data space, this is the direction you need to take to denoise the image. Right? So you can think of it as just a vector function. This turns a vector that says which direction is the denoising direction. We also sometimes talk about flow matching. Flow matching is very similar to diffusion models. They are kind of rebranding themselves, but in reality they're almost the same thing. So in this talk, I'm gonna assume that they are almost identical. This is not exactly correct, but in Euclidean space, they're almost identical. The only difference maybe is the way that you define the forward process. Right? So in flows, the way we define forward process, we no longer use a stochastic differential equation. We just say, let's assume I have one sample from data, again, peanut's picture, and one sample from noise, Gaussian noise, and let's just linearly interpolate these two samples. Right? This is just linear interpolation, linearly interpolating picture of peanut and noise. And this linear interpolation would look like images like that. It's just noisy instances again. The reverse process is defined with an ODE again. And this time now, we drop the score function. We use this vector function. This thing in the similar vector function says in which direction you need to go to convert noise to data. In fact, this thing I'm showing you in red, you can get it from score function, or you can just convert the score function to this. So these are almost identical in Euclidean space. And again, for learning this vector field, you just need to learn a denoiser. It's not really a very different task. So I told you about continuous diffusion models. Sometimes you might be dealing with discrete data, like categorical data, something like text. So you can actually use discrete diffusion models to model discrete data. So again, we're going to use picture of peanut, but this time, think of pixel of peanut is like discrete pixel values, right? Pixel values are like between 0 and 255. Now you want to model that discrete distribution. This time, rather than adding noise, we're going to define a slightly different process, where iteratively we are masking tokens. We're adding more and more masked tokens. We do this so many times, eventually, such that eventually we get to fully masked image on the right side. To define this process, think of a very simple categorical distribution that in one side samples from data, one sample from data, and the other side samples from just fully masked image, right? So this is just like now we are interpolating the probability space between data and probability centered on the mask image. So reverse process is again something like very similar to the denoising model. It's just like now we call it unmasking model that takes this partially mask instances and predicts some of the unmask tokens and unmask it. And then again, it keeps calling this unmasking over and over. You can think of this, if you're familiar with BERT, this is very similar to BERT. It's almost like the objective function training is almost identical to BERT, with the main difference that now you don't sample from one distribution of mask tokens, you actually change the ratio of the mask tokens. Like on the left side you have 0% mask, on the right side you have 100% masking. So you have to train these models, all the models I talked about, they are almost very similar. You take noisy or mask image, you give it to either a unit architecture or maybe vision transformer or transformer in general, and you also give a notion of time. This time says like which time step of diffusion model you're at, and you train this model to denoise, to give the clean version of that input image. So in the continuous case we would train this with regression loss. In the discrete case we're going to use it from cross entropy loss to predict the clean version of the data. So I talked about diffusion models that are trained in the data space, but you don't have to stick to data space. In some cases you may like to go to some latent space and train your diffusion models in that space. Latent models were actually developed at NVIDIA a long time ago before other latent diffusion models that came and became way more famous. We call them latent score based models, not latent diffusion models. So the basic idea of latent diffusion model is that rather than basically training data and data space, you first train an autoencoder. So the job of this autoencoder is to take your images, encode them in some latent space and then learn the decoder to just basically decode back those images to the data space. You can do like you can use whatever loss function you like for this. You can use reconstruction loss, you can use LPIPs loss, you can use adversarial loss to learn this autoencoder. Once you learn this autoencoder you can now train a diffusion model on the latent embedding of data. Now you will train this diffusion model and now we can generate other pictures of peanut by training this diffusion model. So why do you want to do this? There are a few reasons why you want to do latent diffusion models. One main reason is compression. Sometimes the data we're working with is just huge, it's high dimension. Like if you're working with I don't know 3D volume data, if you're working with high dimension videos, it's very hard to learn diffusion on such a high dimension space. Sometimes you want to compress the data, so this autoencoder acts as a compression, you want to compress your data and train that diffusion model in compressed space. Another reason that why we are actually recently also started using latent diffusion model is that sometimes your data either has like a mixture of continuous discrete variables or it has weird ranges. You know like it you need to do like if you want to define the forward pass in the data space you need to take off normalization of data. But when you go to latent space all these things are handled by autoencoder for you and the distribution of latent variables have a little better well-behaved distribution. It's easier to train diffusion on that latent space. So sometimes you may want to do this because of compression and sometimes you may want to do this because the data has some weird like either it's complex continuous discrete data or it has some weird histograms and you want to map it to latent where histogram of data is a bit well behaved. So if I gave you a very quick flavor so we we've done three tutorials I think total maybe 12 hours of content online. The first one went viral it was as early as CVPR 2022 with this this we did this tutorial and it only has like 140 000 views so if you want to check please check one of these tutorials there like each one of them are roughly four hours. So I'm going from computer vision background so let's go back to some scientific domain like here I'm showing you some weather variables so this is just weather variables observed on on globe and we're just opening up this sphere and making showing you as a 2d image. So if you ask a weather scientist what this says they would call like yeah this is like some weather variables they are evolving with some fluid dynamics they can probably even write down the PDE's explaining how these variables are evolving. If you showed this to some computer scientists computer science a very beautiful masmerizing video I really like to model it as a just a video data and learn a video diffusion model on this data. If you train a video diffusion model you can now do weather prediction you take the first current snapshot of earth and just do what Sora did to simulate earth all the variables on earth over time and do weather prediction. So this is my this was my mindset a year ago I said I'm gonna bring all the tools I've learned from computer vision just try to work on this problem. You can imagine that your expectations don't meet reality so things are not going to work the way we think and here are some reasons some things that didn't work right away from beginning. First of all natural images three channels RGB they're very simple uh well-behaved channels but weather data it has 10 to 100 of variables you have temperature pressure wind humidity at all different pressure levels. RGB has limited range between 0 and 255 but weather data has very wide range it can be I don't know you can have heavy tail you can have like different histograms and it's the same as like well-behaved RGB values. RGB channels are highly correlated if you predict one you can predict the other one very easily but weather data you have different correlations between different variables it's not as easy as RGB. If you look at the now frequency response if you look at the spectral uh characteristics of RGB it's they have all the all the three channels have very similar behavior but when we look at the power spectrum of uh weather variables some of them are extremely smooth some of them very high frequency have high frequency content so you you actually need to treat them differently and again there there's abundant uh amount of pictures of cats on internet you can download them and train uh diffusion on cats but yes we have a lot of weather data there's there's decades of weather data but if you start counting number of hours in decades it adds up only 200 000 hours roughly so it doesn't add up to billions of instances that we see on images so there's always limited data so this made us realize that no this is harder than we think uh in order to build really good gen ai models in science for applications including weather you actually need to rethink some of these design decisions so uh this was a very long intro uh let me start with the first week generative super sampling for weather um so if you ever check the weather application most of these use some simulations that they run on 25 kilometer grid i think the distance from here to our headquarter is a bit like roughly maybe less than 25 maybe it's 20 15 kilometer so basically between here and our headquarters these models don't give different temperature you know they represent them as one pixel uh in their models but we wanted to see if we could go to two kilometer resolution can we just make predictions now on the neighborhood level uh for the for weather variables and we thought okay so gene ai has been doing really well in super sampling so this is kind of a super sampling problem where you have a course prediction of weather can we use generative models to do this um super resolution for us to to take it to convert 25 kilometer predictions to five kilometer so um it is not as easy as super sampling problem because these two domains like do these two uh resolution are not coming from the same data set so you may not have exactly the same channels between the two sets like for example on on the regional level we want to generate this radar reflectivity that represents moisture in in the atmosphere we actually don't have that channel in the input it's a totally different type of variable because they're coming from different sources they're not also perfectly especially aligned so things might be a little bit uh not aligned and also some variables you can actually predict them really well using deterministic just a regression model some variables are stochastic you need to generate them so it's a mixture of deterministic prediction and stochastic mapping um so we came up with this framework we call it stochastic flow matching but the basic idea is very simple we said okay let's just train a regression model that takes these input variables and convert it to output variables so i'm calling it encoder that takes these input channels convert it to the channels i want in the output with the resolution i want in the output and then what we did we said okay let's build just a generative model between the output of encoder and the data just like do flow matching do it was like it's stochastic interpolations between out of encoder and data so again this is just now a generative model that starts from out of encoder and learns to generate uh high resolution detailed uh variable so basically we're decomposing the problem into a deterministic prediction and a stochastic uh prediction where this is just adding some of the low-level data so i think i removed my you know i had one oh so okay i had some nice so i wanted to show this um so these are some results so input uh those are the variables in the input so you can see they're very coarse we actually don't have radar reflectivity second column is the art of encoder it's just a regression model it does a good job but it's very blurry it's still even it makes me prediction condition diffusion struggles with generating radar reflectivity uh we believe you could probably get it work uh with just more parameter tuning and stuff but we started with with our method it was very easy just to now add the remaining details on top of the unit output base now our method can take that out of unit regression model and add the low level details now you can get this detailed prediction on these four channels uh i'm going to skip this this was announcement last year uh jensen actually highlighted this on his keynote but because of time we're going to skip this you can find this online um so let me switch to the second part uh a heavy tail data generation with with diffusion models so when you're making uh predictions for weather actually most of the time data is just like a boring sunny day in california you know like yes we we love sun but most of times the predictions are just like a simple usual prediction but actually things are getting interesting important as the extreme values right you want to be able to predict these extreme temperature values these are heat waves you want to predict like extreme rainfall these are like atmospheric rivers if you want to predict like extreme wind speed like a few years ago i bought a house two days after about us there was atmospheric river in california first time after maybe 10 years i lost half of the shingles in my roof right so if i had that prediction two weeks maybe i wouldn't go into contract uh two weeks before that was the best experience as a home like first homeowner and i had to deal with shingles with blown away shingles in my first week and this was just before christmas so imagine how i spent my christmas it was two years ago so if you are using generative models to generate maybe weather data these extreme values are in the tail and this is where we want to model image models don't care usually about tests they want to just generate one cute image that's in the mode it's not in the tail if you want to model weather data you actually need to model this tail we we wanted to analyze if diffusion models can do heavy tail data generation so we create this artificial heavy tail distribution we train the fusion model and obviously now you see that the second dimension at the top horizontal part the red one represents the data histogram and the blue or green or teal i don't know what that color is it represents a histogram of the data generated by gaussian diffusion model so in this paper we argue that probably you need to change the diffusion process you no longer need to use gaussian if you change from gaussian to student t distribution i will go over it why you cannot get much better coverage your histogram will match the data histogram much better so we call this t diffusion and sorry the main idea of t diffusion is that remember i told you in the forward process you use gaussian noise so you keep adding gaussian noise to your data and you do it so many times you can convert your data to pure noise now if your data has extreme values like these are like very large values you need a lot of noise injection to be able to wash out those extreme values but now we argue that if you want to get rid of that signal that like um extreme values you need to change the distribution that you're using for diffusion samples and we argue that you need to use some heavy tail uh distribution to add noise to your data so we we chose to use a student t student t has this heavy tail on the on the sides it is actually this parameter called new is new is the degrees of freedom what's interesting is that if you increase new to infinity you actually get gaussian distribution so you have kind of a knob that you can say some channels maybe are gaussian or you can noise it with gaussian so you can use very large new but if some channels are heavy tail you can reduce new to get heavy tail noise i'm going to skip this um so we show that actually all you need to do is just change a few lines of code in training so instead of sampling from gaussian noise now you're going to sample from student t distribution and use that for diffusion so this is just a diffusion equation where we take an image of cat and diffuse it with this gaussian noise this x zero plus n is just noise now we change the distribution noise from gaussian to student t and similarly for sampling too you just change one line instead of initializing your process from gaussian noise you're going to initialize it from a student t distribution and just do the same thing you usually do again we chose a student t but you can basically try different heavy tail distributions as well and and see which one works well in your prac in your data yeah i'm going to show you one very simple case edm is the model that we built on top of it's a gaussian uh based approach so what you see on the left side so um always on these three curves um blue represents edm so gaussian case and um green represent the test um the histogram of the test data so you can see that gaussian cannot match the histogram of the data by the way this is a variable where there's a lot of sparsity and a lot of extreme value so you have a lot of zeros and you have also a lot of extreme values so we're trying two different simple ideas one is how about we just like normalize the data such that the histogram of data matches gaussian and we say it improves a little bit then we said how about we increase the noise injection we add more noise and then you see it improves actually the histogram and then with our student t in this case you see that you can actually the the best match in terms of histogram of the test data distribution the generated data so i talked to you about whether now i'm going to switch gears slightly and tell you a little bit about other proteins and small molecules um so let me start with protein generation um so if you're familiar with protein generation proteins are a sequence of amino acids there are 20 amino acids in nature these amino acids form chain and these chains tend to fold into the space and they create these 3d structures and these 3d structures usually determine the function that these these molecules micro molecules express if we can build good generative models over proteins now we can actually use them for designing new proteins and these these usually generative models have application antibody design enzyme design and binary design again i'm coming from cs background but i'm fortunate to be working with a lot of folks from different scientific domains and we usually team up with them and build generative models with those folks on on these domains so um i will be talking about this work that we we're going to present at iclear this year it got a oral paper presentation this is a scalable transformer based flow model trained on a protein backbone structure so this is basically trained on just protein structure it's a transformer based model that it can just generate these protein structures from thin air i call so what differentiates protein compared to previous methods that first of all uh we scaled the data as much as we could we trained this on 35 times more data we've we took 20 million synthetic structures generated by alpha fold 2 and train our model on that we use a transformer based architecture we increase the size of model and in contrast to some of the um recent work that use equivalent architecture we actually use just like simple uh massive uh transformer for this problem and and we let the model learn equivalence from data we show that our model gets a state of the art in terms of designably and diverse diversity and i'll talk about some of the downstream applications uh we solve at then i want to say that these are actually condition models there if you are familiar with the protein literature there's some sort of cath labels that gives you the labels for the the the folding label of each protein so these are condition models so you can at the test time say give me protein with alpha helices beta sheets or um or maybe like tim barrel fold so uh one thing that is also protein very good with um because we're using a simple scalable architecture now you can actually generate very long protein something like up to 800 residues these are proteins generated by protein this is very important if you want to ever model for some protein complexes uh with these models so we can all the prior approaches at this uh length they usually fail um most of the scaffolding is this problem it's very small to in painting problem if you're familiar with image generation where like scientists may come and say that i want i i like this motive it expresses function uh the function that i'm interested in give me the rest of protein that holds this motive in this like 3d configuration this is very much like in painting problem you have part of the signal and you want to generate the rest and we show the protein that can outperform some of these prior methods uh on this task as well so in this visualization yellow is the given uh motif um yeah in terms of diversity uh designability and novelty protein outperform some of the actually popular methods called rf diffusion that are usually scientists use in this space um yeah and i'm gonna maybe spend a couple of minutes on genmol our small microgenerative model and then hopefully spend like maybe 10 minutes at the last part on some of our um key design decisions so genmol um so 90 of the fda approved drugs are small molecules these are very tiny molecules that go bind with uh with some targets usually those are like proteins that they go to bind and they either like block their functionality or make them express particular function um the ability to generate and optimize the small molecules is crucial for drug discovery so major drug discovery is about uh finding small market would bind to particular uh targets um so we want to build a generative model on small molecules and one of the design decisions you need to make is what what representation to use to build this generative model um originally people used to use um graph based represent graph neural networks for generating molecules but more and more people are thinking about sequence-based representation um if you want to do sequence-based representation one common represent is something called a smile's representation that takes this molecule and represent it using a string what we're going to use is something called safe representation this is a fragment-based representation so it takes molecule breaks it into smaller fragments hopefully these fragments maybe are fragments or pieces of molecule that um express particular like chemical property right and then we represent each one of the fragments with their smile's representation and use this dot notation just to represent a fragment as a set sorry just to represent molecule as a set of fragments right so this is just a fragment-based representation one reason why we like this is that we actually talked to uh some chemists and they were like saying that in many cases they may have like one fragment that is interesting to them it's like express again the chemical property they want and they're looking for like a molecule that has that fragment you know so so it's actually it's a bit of like compositional approach to molecule generation you you wrap a molecule as collection of these small pieces and we want to manipulate molecules via these small fragments so we're not actually first to think about this so there was a very nice paper called safe gpt their idea is just to train llms on top of safe representation right so for example they show you can do really cool application you can take two fragments and train llms to say what is the fragment that would connect these two fragments right now this problem is called linker design you have two arms that for example they go bind with two proteins and now you want to generate linker between these two arms and llm would do this for you it's a sequence completion task right so it will give you fragment that would fill this gap now this is nice now this is nice but we argue that maybe llms are not the best tool for generating molecules you know llms are designed for natural language natural language has a natural order from left to right for english right to left for arabic right but there is no natural order for molecules um you you depending on how you traverse these graphs you're going to get different sequences so we argue that you can actually use discrete diffusion to generate this um this sequence we we call this framework genmol and visual genmol can actually generate this sequence only in six steps because we can do parallel unmasking whereas if you use uh something like safe gpt on the right side you're doing one token at a time right so you need actually many steps to generate um these molecules um these molecules i think one thing i want to emphasize is that because we're using uh discrete diffusion you actually can use bi-directional attention so every time you're masking or unmasking a token you can look at past and future to make a decision which atom which bond you want to put in this location right lms don't do this only look at back when they're making a decision so genmol is a very simple birth-like architecture train on molecule sequences with the cross entropy loss we trained it once and we showed that you can actually use the same checkpoint and solve so many downstream applications you can do the nova generation you can do linker design you can do multiple extension again the chemist tells you i like this fragment give me a molecule that has that fragment you can generate that uh full molecule sequence and you can also do lead optimization using genmol um we use just one checkpoint and we compare the state of the art uh on a few benchmarks we showed that genmol actually outperform these models by a large margin for example compared to llms genmol um on this fragment constraint generation things like linker design scaffold morphing motive extension um it outperforms safe gpt in terms of the quality of the molecules that it generates um again you can actually trade quality versus diversity and we showed that on this part of frontier uh genmol outperforms llm base uh safe gpt as well and i want to emphasize that these are trained on the same data and same model these are both like transformers 80 million transform we're not like cheating with larger model different augmentation or anything these are like same models almost even same code base um only we change from llm to discrete diffusion um we also showed that you can do now lead optimization we're here optimizing the ducking score like how well a molecule would talk to a target protein starting from a seed molecule so you can see that like we're traversing in the space of molecules with genmol and trying to find molecules that optimize uh this like fitness function you can uh think of awesome i bore you with four projects now i want to tell you what we learned so far uh i have like seven eight minutes so let me first start why again diffusion models are good for science for applications one reason is that their training is very stable and scalable there are scaling laws people showed up with larger models more data you can actually get better generative models with diffusion models they tend to generate really high quality and they have very good expressivity if you have very complex data distribution they tend to capture that to some some good degrees they have very good uh mode coverage like compared to gains they their objective penalizes penalize them from uh missing modes so if you have a application where capturing modes is critical i think diffusion ones are really good for that these are well-defined probabilistic frameworks right so you can actually use a likelihood from these models to do basin inference you can use it for inverse solving inverse problems you can do uncertainty estimation with with these frameworks as i said given especially the power from latent diffusion models you can use them to capture or represent different types of data a continuous discrete point cloud sequence data they have less inductive bias right compared to llms that are left to right now diffusion must have less inductive bias especially in some cases where you need this bidirectional um attention when you are doing generation um i didn't talk about data symmetry sometimes your data is invariant to rotation proteins are invariant to rotation if you take a protein rotate it it's the same protein you can actually bake this into model you can learn the generative model give same likelihood to all the rotations of your data these are called equivalent generative models so you can actually have that in your model you can control the generation of these models by guidance conders conditioning or if you have some like physical laws that you want you want your data to follow you can use that to guide or restrict the generation of your data they have very good internal representation and we had the project where we took the representation learn from the fusion models and solve downstream applications you can actually use use representation from them for like some like classification task as well and finally you can actually build a hybrid physics ml models right as i said you can use for example physics to guide recently there's a lot of interest on using physics uh for reinforcement learning based fine tuning of these more you can like maybe if you have i don't know for example uh binding score you can now say let me fine tune my generative models so they generate molecules that have better binding score to target proteins so you can use this for fine-tuning your models so what are the key design decisions that we always keep going over and over every time we're solving one of the projects so training data quality is crucial like i i remember like when alexnet came there was this expression garbage in garbage art it is super important for general you're learning to generate that data if it doesn't have good quality you're going to generate that data your generative model will not have good quality it's extremely important what we do if unless you have a good benchmark who like where someone someone has done a good job of like filtering and clustering we spend some time filtering our data clustering so that we get good representative samples from our data data representation like on which representation you train your general is important right so sometimes you can say in the data space sometimes you may want to go to latent space for different reasons you may choose to stick to grid graph or point cloud or sequence representation when you're working with the data space normalization and augmentation become very important like remember in the weather i told you they have different ranges the best thing we can do is normalize the data bring all the channels to similar range right so this is like the simplest thing we can do in that scenario network architectures right i used to write fancy papers in my previous job and i would go to my architecture and realize that doesn't matter like which is better architecture you get so much better you know performance i would come with very complex mathematical formulations and just changing convolution layer would just help so much in the result right so i i always emphasize tune your architecture spend a lot of time tuning either like this i'm a unit transformer and graph neural networks and maybe i don't know normalization layers and all these different small details in your architecture or maybe to use pre-trained models if you have access to any as i said you can bake equivalences and symmetries into your architecture you can use for example equivalent architectures that if you rotate input the output would rotate in equivalent way or you can just rely on transformers and let the model learn that hopefully from data and also how to feed the conditional information right so whether concatenate use there's something called control net that is very smart design on how to inject this input control into diffusion models so you can choose also from these different design decisions remember i was telling you that the the choice of noise distribution the forward process is very important basically forward press have some hyper parameters something like how much noise you're going to add and in which rate right so these are very important as i said the noise distribution is very important usually we're training this objective denoising objective on different denoising steps so how you are waiting this objective is also very important so there is a time depending waiting in this objective you can also add additional loss terms if you have like some like understanding of the physics of the data if there are certain constraints on the data you can add these pinless there's a physics informed neural network loss so that the generated data follows some physical laws that you know about your data sampling is important so that's what forward process now when you're generating data at the inference time we've also seen that sometimes depending on you use stochastic samplers or deterministic sample is that the performance changes so you can actually test different samplers um we recently started saying that by introducing temperature think of like temperature as in the knob that would tell you tell your model sample from modes you can actually trade diversity with quality so you would reduce the diversity of your data but you're going to get high quality samples so we wouldn't do this for weather because extreme values are important but some application where we want high quality samples we can use this kind of like temperature tuning and again classifier free guidance or classified guidance is also something very similar where you can now introduce a guidance a scalar to sample from modes um evaluation metrics this is the obvious one but honestly every time we're doing a project i ask my team set up your evaluation metrics early on because we want to measure progress and we want to measure how how well we are deciding on these five design decisions that i talked about right so you need to set up evaluation metrics first and you need to decide if you want to focus on diversity or quality you know like some metrics are sensitive to diversity some of them are sensitive to quality if you are working on scientific data most of times that community has some like uh metrics or some like scientific validity you can use those also to check how valid your generate data is for example in proteins we know the distance of two like carbon atoms on the backbone so we always check like how far are these carbon atoms on the backbone if they're too far or too close we realize that the scientists would laugh at us when we give them these these proteins obviously i'm not doing any of these by myself i'm lucky to have very good team collaborators and many good interns that work with us i'm not going to go over everyone here many of these folks contributed to all the projects that i talked about here and here are the references you can find them from the slides and i don't know if we have time for questions but yeah yeah we're short on time but you can certainly meet with our arash outside the room um and thanks everybody for coming today