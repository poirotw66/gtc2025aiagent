大家好,我是英伟达解决方案团队的Lens今天呢,我会跟Rebecca一起来为大家介绍这个GTC的Session这个Session要解决的任务呢,是在工业场景中的无序拣选的这么一个任务我们也会为大家介绍从仿真虚拟仿真到真实实验中的一系列的探索以及我们的一些解决方案和解决思路希望能够给大家有一些参考会从五个方面来去进行介绍我来为大家介绍前两个方面后面三个呢,Rebecca会为大家介绍首先呢,是背景部分我们要解决的是工业场景下首先就是我有个框,然后我还有个机械臂这个框里面呢,有非常多的弓箭这些弓箭呢,是无序的堆叠在里面的但是请注意,这个弓箭是同种类的也就是只有一种我们要把这个框里面无序的工件呢,去进行一些分解我们机械臂去以某种方式去进行抓取之后然后放在另一个框里面以一种更加合理的方式去进行堆叠或者是码垛或者是摆放这样一个工作后面这部分呢,是一个比较规则或者说Case by Case的事情所以后面这部分我们不去介绍我们只介绍前面,以及说这种抓取和摆放的这个过程以及说整套PIPLAN是我们如何搭建的AVDA针对于机器人相关的任务呢,为大家提供了这么一些工具或者是平台,左边三个呢,是这个Platform也就是平台的部分我们来看中间这个部分就是Iseq Theme就是大家可能熟知的,用来做仿真的但是你在仿真的时候呢你这个场景中可能会不只有物理仿真你也会有一些AI的Model会被运用起来比如说我们后面要去介绍的,用来做6D6自由度估计的FoundationPose以及说甚至是一些World Model这些AI的模型我们可以把它通过IseqNeme来去部署起来,部署在我们的私有云或者是公有云上面然后以某种方式去跟Iseq Theme去进行一个串流或者是交互然后当我们这套开发流程开发完了之后我们需要去把它部署在真实的场景中这个我们就可以用IseqRows来去把它部署在端侧比如说Jetson的Arain或者是Sore上面针对于不同的应用场景呢我们有三个任务,三个参考的工具流来为大家提供一些基本的模块比如说用于机械臂抓取的IseqManipulator我们后面会稍微详细的介绍以及说针对于AMR的这么一个任务的Iseq Perceptor以及说针对于人形机器人的一些常用的任务呃这些常用任务的一个Groot这么一个项目首先是IseqManipulator这个工具呢其实在工业界已经有非常这种广泛的影响我们会今天会重点介绍三个工具首先是一个做detection的工具还有一个是六地六六度估计的一个工具第三个就是用来做Motion Planning的Commotion这么一个工具首先呢是FoundationPost这个可以代码是开源的你可以在IseqManipulator里面去用它的加速过后的版本你也可以在Github上面去直接访问它的官方的版本并且PayPal也是开源的算法细节什么的以及实验数据我们来简单看一下这个算法这个算法呢是一个ZeroShot的一个六自由度估计的一个算法它不只能解决仿真场景中也可以解决在真实场景中的这么一个任务我需要给这个算法给一些什么信息呢首先我要去做六自由度的估计PostIseemation首先我需要给它一个RGBD的信息就是包括深度图我需要去拍一张这样的照片出来还有呢就是相机的内餐我也需要给定到它还有呢就是因为我要做ZeroShot的人物所以我要给告诉这个模型我要去做Iseemation的这个目标物体它是长什么样子的这个长什么样子我可以通过Nurve的方式来去告诉它我也可以通过Mesh的方式去告诉它也就是一个带Texture的一个Mesh知道这些信息之后呢它就可以对这个一个没有见过的物体以及场景包含这个物体的场景去做一个PostIseemation也就是姿态估计的这么一个任务它会输出一个6D的一个Post包括三维的Position以及三维的Orientation嗯它大概分为这么两步第一步呢就是IseemationIseemation的速度大概对于720P的话大概是1.3秒然后后面的Tracking部分可以达到1010我们来看左边的这个例子这个就是在正式场景中的一个Case我们可以看到这个手段它的Iseemation的准确度以及实时性都是非常好的右边的这个呢是用它来去实现的一个AR的游戏嗯这个游戏我们如果细想一下的话我们会觉得就是它的实时就是这个游戏的开发对于实时性以及说Eseemation的精度的要求都是非常高的那这个也证明了FoundationPost这个算法的效果还是挺不错的嗯接下来呢是Commotion这么一个工具Commotion要解决的问题叫Motion Planning是给定机械臂的一个初始的位置以及说一个目标的呃末端执行器的6D的位置我要去呃规划出一条可行的解这个任务的难点就在于说场景中会有一些障碍物我需要在达到目标位置的同时还要去使得机械臂以及我的末端执行器都要去呃避开这些障碍物我们具体的思路是什么样子的呢先对呃目标的呃最终末端执行器的位置我们先经过ik得到目标位置的m个解机械臂的m个joint states然后从一个初始到m个目标的joint states去进行插值得到m乘n个初始解我们把这m乘n个初始解c到网络里面让它进行优化就得到了大概率呢会得到一条可行的解这条可行的解呢是比较顺滑的但是在某些极端的情况呢或者是一些countercase下也没有办法得到一个可行解然后这个时候我们就回退到基于图搜的一种方式先经过图的搜索搜索出一条可行解然后对这条可行解因为它可能并不是这种顺滑的我们在进行优化那就可以得到一条大概率会得到一条可行解通过这种方式呢就完成了精度和成功率以及说smooth的一个tradeoff我们来稍微总结一下这三种方式基于图搜的这种方式呢基本上可以得到一条可行解但是这个可行解呢有可能你可以看到就像这个机械臂一样它是拧巴的非常厉害而且它并不一定是最优的这个时候我们的评价标准比如说jerk或者是叫加加速度就会比较大这种只大的时候会加速机械臂的磨损然后另一种思路就是通过这种轨迹优化的方式但是这种方式呢非常容易陷入到局部最优我们对它的解决方式呢就是给它足够多的初试解让它去尽量的能够搜索到一条全局最优的解但是在某些极端的情况下它也并不一定能够搜索到这么一个解这个时候我们就再回退到graph planning就是基于图搜的这么一个方式来去重新进行规划以及优化这种方式呢就既保证在大多数情况下它的速度和准确度呢都是比较可观的在很少的情况下conarchist的情况下我们会牺牲一部分的速度来确保它的精度这个是comotion的部分接下来呢是把它们简单集合起来的一个参考的工具流这个是ISAC manipulator里面提供的我们简单来看一下相机拍摄到RGBD的图像之后呢我们会给到一个检测器detector这个检测器会检测出一个bonding box但请注意这个detector它是一个就是它并不是一个zero shot的一个算法所以说你可能还需要retrain一下就是finetrain一下它它得到一个这个bonding box之后呢会给到后面的foundation postfoundation post会得到一个目标物体的6D的post信息这个post信息再会给到作为输入给到我们刚刚接受的comotion来去做轨迹规划规划之后呢会进行机械臂的控制这个机械臂呢就既可以是simulation场景下呢也可以是real场景下会上面的这些模块呢都会集成在一个通过一个调度器吧这个调度器在SXSIM中呢叫cortex在比如说在ros中呢我们可以用一些工具比如说behavior tree来去实现或者是你自己定义的一些状态机上面我们介绍了一些工具好用的工具接下来呢我们来介绍针对于random beam picking不需拣选这么一个任务我们具体的解决方案是什么的这个流程呢可能会稍微有点复杂因为我们其实知道在工具场景下这些corner case会比较多而且这些任务的场景呢可能也会比较复杂所以我们可能会用一些模块来去弥补就是一些别的模块的一些缺点吧我们简单来看一下整个算法流程呢分为三个部分左边这部分呢是perception中间这部分呢是planning右边这部分是controlcontrol呢不是我们今天的重点但是会在后面的sim to real的部分去进行设计我们来先来介绍一下这个perception的部分perception的部分有这么几个模块从3D相机中我们先补过到或者说我们先拍到一张RGBT的图像这个信息呢会给到segmentationinstance segmentation来进行实力分割这个地方我们可以用比如说就是sem或者segment anything或者是fast sem等等类似的算法得到每一个proposalproposal它的instance的mask然后对这些mask去进行排序这个排序呢是shape和size都比较敏感的针对于shape也就是形状的部分呢我们用的是hue moments针对于size的部分我们是用简单的一个呃规则的一个思路来去过滤掉过大或者过小的size的这个mask我们会假设过大的呢它可能存在的问题比如说我把这个箱子去检测出来了分割出来了过小的呢可能就是它会有一些遮挡所以说这种尺寸大小比较合适的是我们预期比较合理的然后通过这种方式去进行排序出来的呢我们会觉得知情度最高的就是没有暴露的呃就是暴露出来没有被遮挡的而且比较好抓的我们会拿到它的mask然后再给到后面的fondation post去做六自由度的这种post estimation比如说像右边这个视频展示的这样左上角是rgbd的信息右上角呢是rgb的这个图像右上角呢是排序的结果左下角呢是这个mask右下角呢是这个rgdtectionrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr在抓取过程中发现不可答或者是规划的时候还会进行一个判断这种路径不可答的话我们会把刚刚的那个mask去注册成一个fileer的mask然后再去进行一段重排序再回到这个图里面讲的话刚刚是perception的部分接下来是这个planning的部分planning的部分我们会用一个global的一个检测global的一个判断器吧我们可以这么说来判断当前的这个目标物它是不是可答的如果它是可答的话我们再进行具体的motion的这种generation嗯这种global的判断呢我们这用的是lula的rt或者你也可以用刚介绍的conmotion至于判断它可答之后你具体的这种motion generation可以用mpflow判断出来之后呢或者说是生成完这个motion之后呢你就可以给到控制器去进行这种控制以及具体的抓取这个呢我同时会为大家介绍嗯接下来的这个demo的部分以及后面的部分呢由我的同事rebecca来为大家介绍谢谢大家好我是英伟达的解决方案架构师张瑞rebecca今天下面呢由我来为大家展示一下我们刚才的无序拣选项目的一些demo以及后面我们sim2real的一些实验结果首先展示的demo是在Ur10的机械臂上面我们接了一个长的锡盘来适应这种工业的身框抓取的场景然后我们抓取的是一个工业零件右侧展示的就是我们的感知模块的检测分割的结果下面是6D位置估计的结果然后我们可以看到感知模型的更新的结果呢跟我们仿真里面的动作规划呢是一步来完成的也就是说当机械臂刚已移除我们的相机视野之后呢我们就会触发下一张图片的拍照然后以及感知模型的推理这样一步的一个设计呢可以极大的加快机械臂的抓取节拍你看在这里我们就会更新下一个感知的结果了好我们再来看一下一个例子是U20接了一个两指的Robotique的平行夹爪的这样的一个例子我们用它来夹一个小的螺丝的结果这里面展示的就是用我们的方案可以很容易的来集成不同的机械臂和末端的夹具以及来快速的适配没有见过的新颖的物体好接下来呢我们要展示的是我们跟合作伙伴银河通用在他们的Charlie人型机械人上面做的一些抓取的实验工作然后在仿真里面呢我们主要是固定Charlie的腿部头部和左臂的关节只控制Charlie右臂的关节然后来完成这样的一个无序抓取的任务然后这个例子里面我们展示的是我们可以切换来使用左侧呢就是使用Charlie的头部相机来做感知和决策然后右侧展示的呢就还是使用一个固定的在物料框上方的这样的一个相机来做感知和决策然后都能够达到比较好的精度好接下来的一部分呢我们会介绍我们在SIM2Rail的一些经验和我们的探索工作那么我们首先会跟大家展示一下我们在实验室里面在Gailbot这个人型机械人上面部署的一些SIM2Rail的一个demo的视频然后可以看到跟仿真环境里面一样呢我们有setup一个相同场景的这样的一个用Gailbot的右臂来完成这样饼干和抓取的这样的一个场景然后左下角展示的就是我们的实时的感知的一个结果然后我们可以看到仿真里面的机械臂和真实的机械臂可以完成一个同步的抓取动作然后这里面呢也显示了我们之前说的模块化的设计所以很方便的可以将输入的这个感知模型以及输出的控制呢都改成部署在这个真实的环境中好接下来呢我们就来讲一下SIM2Rail的一个方法论首先呢为了实现这样的一个在真实环境中的一个部署我们主要要完成三大类的一个适配工作第一类的适配工作呢就是对于我们要抓的这个新的新颖的3D目标物体我们首先要对它做一个三维重建并且呢创建对应的SIM2Rail的一个资产这样的话呢它才能够参与我们的渲染和物理仿真然后第二部分就是对于场景中的一些障碍物我们希望能够自动的检测和注册起来而不省去了一些复杂的人工配置的工作在我们的这个抓取场景里面呢就是这个撂框我们希望能够自动的检测撂框的位置并且呢完成注册最后呢就是如何导入和适配一个新的机械臂以及它的夹具那么这里面会分为这是这个SIM2Rail工作的最重要的一部分那么它的工作流呢也会比较长主要呢我们总结分为四个步骤第一个步骤呢就要做一个数字轮升的创建那么就包括首先呢根据机器人的URDF文件我们要导入到USD中接着呢我们会对这个新的机械臂做一些控制的增益调节使得呢我们在仿真里面能够正常的来控制这个机械人的各个关节来做我们的指令跟随那接下来第二步骤呢就是来生成机器人的一些描述文件这里面呢就包括对于机器人它的本体的一个碰撞球的一个表达的拟合这些碰撞球呢就是在我们之后做无碰撞的轨迹规划的时候呢使用的那第三个重要的步骤呢就是对于一个新导入的机械臂或者末端执行器我们都需要为它创建一个可用的控制器controller也就是在我们代码里面实现这样的一个controller的类来完成将上层的一些控制指令转变成这个机械臂的一些底层的关节控制的这样的一个控制器那最后一步骤呢就是我们要完成SIM2RAIL这样的一个任务的同步呢是非常重要的一步操作就是要完成一个实时的控制器那么下面呢我们会对每一个步骤展开介绍首先呢是对于新颖的3D目标物的一个重建和适用于物理仿真的SIMREDIT资产的创建那么对于没见过的一个物体呢我们怎么样能拿到它的一个带纹理贴图的3D资产的呢我们这里面使用的是NV Research的一篇工作叫做BandoSDF它是使用神经网络来同时做目标物的6D位置跟踪以及三维重建那么它的输入呢就是像这个视频里面展示的一段RGBT的video然后同时呢还有采集相机的内参那么我们首先会对这段视频做一个预处理就是使用一些ZeroShot的这个分割Object Segmentation的算法来生成出这一段视频里面的目标物的一个Mask每一帧都能够得到对应的Mask然后这里面我们会利用了一个第三方的算法叫做XMem然后有了这些Mask之后呢我们就可以把它也作为一个输入为给BandoSDF这一个算法这样呢我们就可以输出向下面图展示的这样的一个有贴图的3D模型然后它的贴图展开呢就是像这个样子然后我们可以看到这个算法它的Tracking的效果也是很准确的那么有了这样的一个3D重建出来的3D模型之后呢我们就可以通过Model Free的这个路径来推理我们的Foundation Post的算法来完成这个模型这个新颖目标模型的一个6D位置估计然后调用我们之前的感知Pipeline感知和决策的这个模块之后得到的一个结果呢就像这个视频展示的这样这里面我们用到的这个芥末屏呢就是通过三维重建出来的我们可以看到它虽然呢并不完美是有一些瑕疵的但是呢对于我们的Foundation Post模型来说呢因为模型具有足够的泛化能力所以依然可以比较准确的估计出目标的6D位置好在下一步中比较重要的呢就是要做场景中的障碍物的一个自动检测和注册那么像我们这个场景里面它可能存在的障碍物呢我们需要事先定义我们这里面呢需要定义的就是用户输入的这个物料箱它的XYZ方向的长宽高的尺寸以及壁后有了这些信息之后呢我们就通过一个感知的算法可以从时可以估计出场景中的这个料箱的位置然后呢并根据这个位置来在仿真环境里面注册这个料箱的4B为我们的这个obstacle的这个碰撞几何然后我就像下面图中展示的一样真实的场景中呢我们感知到这个料箱是有点倾斜的状态那我们在仿真环境中呢就可以把这个料箱的位置也进行同步并且呢注册对应的obstacles这些obstacles的几何呢就会被后面我们的motion planning的算法所利用来完成五碰撞的轨迹规划下一步呢比较重要的呢就是我们怎么样来适配新的机械臂或者机器人那么第一步步骤呢我们要做的就是创建一个数字栏升那么我们可以使用我们的URDF importer来直接将机器人的这个URDF模型导入到SX-SIM中之后呢我们就可以向下面视频展示的这样通过Gain Tuner这样的一个extension来完成对这个机器人的各个关节的增益的一个交互式的一个调整我们可以很方便的利用这个extension呢来调整不同关节的一个增益然后呢并做一些单元测试看一下每一个关节是否能够精确的follow我给它的一些控制指令那么做完了增益调节之后呢我们就有了一个在仿真里面基本可以正常工作的机械臂或者机器人了那么下一步骤呢我们就是要为这个机器人来参与物理仿真或者是motion planning的解算呢做一些它的碰撞体的一个表达也就是要生成我们一般呢不会特别精细的对机械机器人的集合做一个表达而是会用一堆球体的集合来对这个机器人的一个外形碰撞外形呢做一个拟合因为这些用这些球体呢来计算这个碰撞是更加高效的然后呢我们可以使用的就是LULA Robot Description Editor这样的一个插件通过呢在这个插件里面我们就可以手动的给这个机器人以这个机器人的各个link也就是它的重要的钢体的关节为参考来添加不同的这个球体的不同尺寸的和位置的球体的表达最终呢可以很好地包落我们这个机器人的一个想要参与控制的机械臂的一个外形比如说在这个Gailbot的这个人形的场景里面我们其实只需因为我们只控制它的右臂来做规划所以我们只需要给它的右臂以及对应的这个长的吸盘来做这个碰撞球的一个生成和拟合就可以了然后其他的头呀腿和左臂呢我们都可以不用考虑然后并且呢可以在这个插件中把这些关节呢都设置为固定的关节而只有右臂的关节呢是一个active的关节然后我们可以把这些所有的配置呢都一键导出到我们的LULA Robot Description的这样的一个yaml file里面然后这个文件呢就会保存我们之前所说的所有的配置包括那些固定关节它的一些默认的位置状态以及我们要做参与控制的这些active关节它的一些状态有了这些除了这些之外还有就是这些碰撞球的一个表达有了这些信息之后呢我们的LULA Framework呢就可以来做无碰撞的轨迹规划了那最后一步很重要的呢就是我们要完成仿真里面的机器人的动作跟真实的机器人的动作的一个同步那也是Theme2Real里面最关键的一步那么我们这个里面呢主要是设计了一个实时的控制器来完成Theme2Real的一个同步的工作那么整个我们的Motion Generation的这样的一个算法呢最终呢我们使用的是RMP Flow这样的一个算法那么右面的这个图呢展示的就是这个算法的一个控制逻辑那么从ASAC Cortex的这样的一个机械臂的一个调度框架里面呢我们可以拿到一个最新的机械臂的控制指令就是它末端要去到的一个位置的command指令那么以及呢我们在仿真里面的这个Belief Robot我们构建的这个机器人我们也可以拿到它当前的一个位置的一个关节位置的信息那么输入给我们的Motion Policy策略之后呢就会得到我们当前时间不要执行的Joint Action也就是每一个关节它的一个位置和速度的控制目标那么有了这些Joint Action之后呢我就可以迭代的来更新我们仿真里面的这个机器人来完成Ding的动作了我不看上面呢在下面的仿真环境里面呢它其实就可以闭环的来完成这样的一个控制也就是说其实我们的这个在Isaxin仿真里面的无碰撞的轨迹规划或者动作生成的算法呢其实是工作在这样的一个仿真的Belief机器人上面的那么我们最终要控制的是呢这样的一个真实的机器人所以呢我们就要在真实的机器人和Belief机器人之间呢定义一个做同步的控制器的这样的一个媒介然后这个媒介呢在我们的这个应用里呢是使用了Rose1的一个Sync的控制器来实现的这个控制器呢主要是完成这样的一个双向的一个通信的一个作用首先呢这个控制器在每一个时间部都会把我们Motion Policy所输出的Joint Action呢打包成关节的轨迹来发给我们的真实的机器人的控制器同时呢它也会把真实机器人的最新的关节的状态那更新给我们的仿真里面的Belief机器人让Belief机器人呢能够跟真实的机器人的关节状态呢做一个同步那么这个Sync的控制器具体是怎么实现的呢可以看我们左下角的这样的一个逻辑随着仿真时间部的一个推进随着仿真中的时间线的一个推进那么我们其实是周期性的来做这样的一个Theme2Real的一个同步工作的那么每一个周期呢我们其实都分三个阶段第一个阶段呢就是这个红色的小箭头的阶段它呢是首先呢在每一个控制周期呢都完成Belief机器人跟真实机器人的DoneState的一个对齐也就是说把仿真里的机器人的状态呢跟真实机器人的状态呢进行一个同步那么接下来呢就会进入到绿色的这个时间线那么也就是我们Motion Policy的迭代的一个过程这个时候呢我们就会连续的把周期性的把我们的Motion Policy输出的Done Action呢发布给我们的真实的机器人那最后呢就进入到了我们的浅绿色的这样的一个时间线那么我们主要完成的是一个同步或者是等待的工作这个时间中呢我们的Motion Policy呢是被抑制的也就是说我们的RNP Flow这个算法呢不会再做迭代更新而是等待我们真实的机器人的状态跟仿真的机器人里面发给它的控制达到一致之后呢我们才能继续的迭代Motion Policy从而呢完成这一轮的SIM2Real的一个同步然后进入到下一个迭代周期那么这里面要实现一个比较光顺的一个机器臂的控制的话呢在真实的机器人的那一端控制的那一端也需要启动一个实时的控制器那么我们在这个Gibboard的机器人上呢也利用了它的实时控制器来完成对于我们发给它的控制指令的一个实时的一个差值从而实现比较光顺的机器人的控制经过了上面我们介绍的四个大的步骤之后呢我们才可以实现对于一个新的人型的机器人我们把它在我们的Beam Peaking的这个项目里面真正的实现了从SIM到Real环境中的一个部署那么最后呢就是一个总结的工作那么这次Talk呢总结下来呢我们主要做了这四件事第一件事呢就是我们给大家介绍了一个端到端的不需要训练ZeroShot的一个无序拣选的解决方案它是构建在NVIDIA的ASACSIM和ASAC Manipulator这两个产品上那么第二点呢就是我们在整个工作流的感知决策和动作规划模块上呢都做了相应的创新来加速整个无序抓取解决方案的开发第三点呢就是我们通过模块化的设计不仅呢方便在仿真环境里面进行算法的验证和调试同时呢也更容易呢完成SIM toReal的一个部署那最后呢就是我们也给出了SIM toReal部署的最佳实践跟大家分享和讨论那么如果大家对于我们上面介绍的NVIDIA的机器人解决方案或者是任何技术细节感兴趣的话呢都欢迎联系我跟Lance我们很愿意呢跟大家分享我们在使用我们的产品和开发整个工作流过程中的一些想法和我们遇到的挑战希望呢用NVIDIA的软件机器人的软件产品呢能够受益所有的社区里面的开发者和工业的合作伙伴好以上就是我们这次分享的全部内容谢谢大家