大家好我是卓域科技的陈小智啊感谢英伟达的邀请今天我来给大家分享一下卓域在端到端正驾驶技术方面近期的一些进展那从标题可以看出这个smile的内容主要包括两块就是end to end model和generative driving experience今天会跟大家介绍我们正在做的这个端到端的世界模型以及我们是如何基于端到端世界模型来去实现生成式的自驾体验那这里自驾体验前面有个定语生成式我们叫生成式的自驾体验这可能是卓域首次提出的这么一个概念这相对于传统的目前大家普遍看到的这自驾体验生成式自驾体验会给用户体验带来跟以往不太一样可能会有一个比较大的这么一个提升那今天会跟大家展开来去说一说首先想跟大家探讨一下什么是好的自动驾驶体验我们都知道一个自动驾驶系统它最终输出给车辆控制模块的就是一条可执行的驾驶轨迹对吧那这条轨迹通常以横纵向的微制坐标和速度来表示实际上就包含了油门刹车以及方向盆的信息那因此一个增加的系统的体验除去软件本身的稳定性问题就驾驶本身而言的体验实际上就取决于这条轨迹比如一根能够让用户感受到安全舒适的轨迹可能是绿色这条但系统的输出可能是紫色这条两指的差异大小就决定了体验的好或者坏那在目前主流的这种端到端的架构下这根轨迹实际上就是端到端模型所输出的轨迹那我们来看一下用户实际喜欢什么样的轨迹呢一个驾驶轨迹好不好大家往往可以用很多维度去来去评价比如说安全舒适等维度这里我们用一个大圈来表示轨迹的解空间也就是所有可能的轨迹的集合那么安全的轨迹应该是这个空间下的一个集合那既安全又舒适轨迹自然是一个更小的子机因为舒适轨迹前提肯定是要安全对吧那在端到端没出现之前以前大家关注比较多的其实就是这两个维度安全和舒适这两个维度也比较容易用数学来刻画那端到端技术出现之后人们关心你们开始关心第3个维度就是理人化比如典型的药型场景系统可以比较容易的输出安全且舒适的轨迹比如遇到这个围停车对吧系统可以先减速到这个围停车的前面然后再等待10秒发现它是围停车在慢慢的要行这个轨迹它实际上是安全的也是舒适的但是显然人类不喜欢这样的轨迹因为他不理人人不会这么去开车对吧那理人化的轨迹就是好的自家体验吗如果平时开车朋友可以想一下比如别人或者说你的家人开你的车的时候你会不会喜欢做他开的事可能不一定喜欢就是大家会发现就我们往往只会习惯自己的这个开车风格哪怕是一家人可能丈夫也不会喜欢妻子开车那妻子也不喜欢丈夫开车因此这里可以我想说的是就单纯的理人化的驾驶体验其实是不够的因为现阶段端道端模型一般都是基于模仿学习来训练来从这种大量的驾驶序中去学习那这种学习方式他学到的实际上是一种平均人的风格对吧就是从大量税中平均的一个风格他不一定是用户所喜欢的风格因此我们认为一个好的自驾体验除了理人还得满足用户的个性化需求那这里就举例三种典型的驾驶风格激进的均衡的保守的驾驶风格他对应了不同的人群的一个偏好我们都可以统称为个性化的一个驾驶轨那这个个性化驾驶轨迹自然他属于是理人化的驾驶轨迹里面又是一个更小的一个子机那么从理人化驾驶再到个性化驾驶如何实现呢刚才提到目前主流的端到端模型的训练都是基于模仿学习来去做的对吧他只能从大数据中去学到一个平均人的驾驶风格它跟用户实际的偏好可能是有偏差的那为了实现个性化的驾驶我们提出了一种端到端世界模型的架构它可以实现自定义的驾驶风格和自定义的驾驶行为同时我们还能支持通过语音交互来去实时改变控制车辆的驾驶风格和动作那这页我们先简单回顾下着域这家系统算法架构的一个演进过程可能和行业整体趋势也是类似的最早我们在22年的时候合作量产的车型其实就只有感知部分是数据驱动的到23年我们在预测部分也做了数据驱动再到去年我们实现了完全的端到端出轨迹的规划那到25年我们的端到端会进一步升级为世界模型这是什么含义呢就目前的端到端我们认为其实更多是一种基于预测方式的端到端就是说他观测到一段传染器的输入然后然后再预测下一步的动作因此他是一次性的这个动作预测的过程那但实际上我们的驾驶行为由于环境不同周围动态交通参与者的交互以及用户自身的驾驶偏好的不同他应该要具备多种可能性的输出那为了实现这一点我们采用了生成式的技术来去做端到端通过世界模型来去生成未来可能发生的N个平行宇宙然后再结合用户的偏好还有各类环境信息来去选择最优的一个轨迹输出OK那置页展示了我们端到端世界模型整体的架构首先最底层是硬件平台包括支架的控制器比如可以用林伟达的计算平台像HorwinSore这些芯片都是可以的以及不同类型的传染器配置像7V10V12V有激光雷达没激光雷达配置这是最底层的这个硬件的平台那在端到端世界模型它的输出部分和常见的做法类似我们可以通过Visionencoder还有各种Tokenizer来去编码这个传染器数据导航信息还有本次的历史轨迹的输入那除此以外呢我们还会将驾驶风格以某种形式编码到这个模型中以及我们还有这个文本的编码器可以接收用户的语音的指令那模型的输出会包括对周围环境的一个理解包括语意啊还有几何的一个理解以及对未来多种可能性的一个生成那对未来这种生成呢我们其实可以有不同的方式那我们会倾向于使用更加高效的一些中间表达来去生成未来而非这个视频空间的这个生成最后就是Driving policy的输出这里我们强调是客制化的驾驶轨迹也就说能够和用户的驾驶风格的偏好还有语音指令的提示来去对其后的这么一个驾驶轨迹的输出那整个模型的训练的Pightline我们是采用这个大模型典型的预训练加后训练方式来进行的在训练这一块我们还有个特点就是我们可以做到硬件无关的训练意思就是针对不同的传染器构型还有不同的芯片类型我们可以只需要训练一个模型就能部署到不同的硬件那基于这些技术在功能层面我们就可以实现这种生成式的自驾体验比如推理时我们可以支持Pound的输入可以根据用户偏好来去改变驾驶行为也包括可以自动的去学习用户的驾驶风格用户也可以去自定义他自己喜欢的驾驶风格或者我们也可以通过自然的云交互来去实时的控制改变模型输出的驾驶行为接下来我们会跟大家展开说一下这里边涉及到的几个关键的基础首先关于是关于训练策略我们采用了预训练加后训练的学习方式在预训练阶段我们的目的是要模型建立一个强大的基础能力包括空间感知能力语意理解能力以及轨迹生成的能力并且希望他具备一个很强的繁华性那常规的端到端模仿学习是使用人类驾驶员的轨迹数据来做这个训练它的优点是质量高可以提供老司机的示范但是缺点就是专家驾驶的数据风格其实比较统一的缺乏这个多样性这对于训练一个放话能力比较强的技术模型其实是比较困难的因此我们除了使用专家驾驶数据还用了大量的交通参与者的轨迹数据也就是我们车辆传染器看到的周围环境所有参与者的这个轨迹也会参与训练这些轨迹具有非常高的多样性并且数据量比专家驾驶数据要高10倍以上它数量会占到整个训练机的大概90%那我们整个训练机规模目前是超过5亿帧大部分也是通过我们的量产车还有采集车来去获取的同时我们也使用了使用了部分的仿真数据来去补充一些场伪的场景那这部分是通过云端的世界模型来进行生产的我们可以使用像英伟达的cosmos之内世界模型来进行生产那通过这些数据结合我们可以让模型获得繁化性很强的轨迹生成的能力啊那预训练的这个训练本身是很大的那所以呢我们通常会以周级别来进行模型的这个更新那为了更快的满足我们量产迭代的速度要求我们还需要后训练啊后训练它可以做到天级别的更新迭代在后训练阶段我们更关注的是模型的常委能力包括在一些具体特定场景的行为决策和轨迹规划能力我们会采用增量学习方式后训练只需要少量的数据主要是专家驾驶数据来进行微调啊收敛常委场景的一个性能体验通过这种预训练加后训练的方式我们让模型先建立了一个很强的一个基础能力然后再通过高频的后训练微调来快速的迭代提升ok那这页想跟大家介绍的是我们首次提出的啊端道端提示推理的技术皇庭E2E端道端模型通常会输出多个互选轨迹然后再结合啊一些打分机制来去选择最优的这么一条轨迹那我们的模型在每个时刻也会输出上百条潜在的交互交互的轨迹这里边他考虑的周围的车量啊行人等障碍物潜在的行为以及和本车的一个行为交互组合出上百种的一个可能性就类似于有N个平行宇宙但是里边可能存在一些非预期的轨迹啊那传统的做法可能会结合一些规则的打分机制来去选取其中的一条轨迹给到控制去执行那我们的做法其实是通过推理时然后给模型去增加这个指令的输入将用户的驾驶意图以指令的形式输入给模型模型就会跟随指令实时的改变轨迹的输出并选出最符合驾驶意图的安全的轨迹那么模型为什么能够实现指令的跟随呢那这里前提其实就是刚才所提到的啊必须要有一个啊很强的通用轨迹规划的能力的基础模型我们是通过一个通用的预训练的环节来去实现这一点的我们来看一个典型的路口场景啊他们是同一个路口区别在于导航不同左边按导航是要路口执行右边按导航是要右转那为了实现这个驾驶意图我们只需要在推理阶段啊将导航的指令输入给模型比如说前方路口执行啊或者前方100米又路口右转输给模型模型就能够自动跟随导航实现相应的一个驾驶的行为那这种推理提示推理的技术可以让我们整个端到端算法架构的实现做到比较简洁通用啊而不需要写太多的这个模型代码前面介绍的其实还是一个相对常规的应用接下来我们可以更进一步通过自然的语音交互来去影响驾驶的行为具体来说啊我们可以基于端到的世界模型做了四个功能左边第1个是场景级别的驾驶风格的定义第2个功能是个性化的驾驶风格的学习那第3第4个功能是可以接入语音的输入然后通过语音来去控制驾驶风格和驾驶行为驾驶风格是指一个长期的驾驶行为的刻画比如说激进的保守的风格那驾驶动作指的是一个具体的顺时的行为比如我要超过前面的车那4种行为基于这4个功能我们不仅可以实现千人千面的驾驶风格来去满足不同用户的风格的偏好还能让驾驶系统听得懂用户的诉求实时的去对齐用户的驾驶意图我们来看千人千面的驾驶风格是如何实现的从功能上来说场景风格是指围绕功能场景维度来去定义的风格比如说根持过程的风格它可以有这个起步的快慢不同还有比如持距保持的距离不同可以有不同的风格比如速度控制的风格路口转弯的风格还有编道的风格等等那个性化的风格是指学习用户自己的风格它可以基于用户一段时间的驾驶记录自动学习出用户的一个驾驶风格的偏好这个过程就类似于在线的去标定用户的一个驾驶偏好的一个过程那整个学习过程它只需要用到次端的算力而不需要任何这种云端的交互当然我们也可以支持多种用户风格的学习可以结合座舱内的人脸识别来去自动绑定不同的用户的ID自动激活选择相应的用户的风格那右边是驾驶风格的一个训练和推理的过程在训练阶段我们会利用大量的用户驾驶轨迹数据来去训练一个style tokenizer就是风格的编码器那训练阶段我们可以将不同轨迹的风格来进行分离那在推理阶段用户选择了某个ID或者某种风格时候style tokenizer就可以输出对应的一个风格的编码迁入到端到端世界模型中从而就可以去影响这个模型输出的一个轨迹的风格这是一个整体的这么一个流程那除了千千面的风格我们还有驾驶行为的一个交互控制有时候选定了风格但系统的驾驶行为可能也不一定完全满足用户的偏好我们的模型可以支持通用的一个字眼语音的输入用户可以通过说话来去直接控制支架系统的style和actionstyle就是长期的一个行为比如说用户他可以说我容易晕车能不能开慢一点或者说不要让其他车加塞我或者说开快一点那模型接收到这些指令他可以根据这些指令实时去调整系统的一个驾驶的风格那第2种prance我们叫action prance他可以支持用户对可以持量顺时动作的一个控制比如说比如用户他可以说帮我超过前面那辆车或者前面200米左转或者不要开靠在最最左边的车道对吧进入俘路靠边停车等等用户可以说不同的话来去改变模型顺时的这么一个行为轨迹并且整个交互他是可以支持通用的一个语言输入的不需要预示具体的指令真正做到让支架系统听得懂话对吧能够理解用户的需求那这种交互式的支架功能可能是卓裕首次提出来的这么一个一个概念啊今年我们也会将这种功能在相关车型上进行量产落地那这里这要给大家介绍的是卓裕的平台化端到端的一个训练技术我们看到目前市面上已经量产的端到端支架模型通常会有一些依赖比如说全氧器大部分都需要有激光雷达的输入或者说算力通常需要比较大的一个算力啊通常都是200TOPS以上的这么一个算力芯片才能跑并且在地图CN方面可能还未需要用到迟到机地图或者中包地图总体而言对于硬件的配置或者CN信息是有比较高的一个要求这其实也给端到端高阶支架的普及增加了一些成本上的挑战那卓裕的端到端模型对这些都是若依赖啊具体具体而言我们可以支持任意构型的传染器配置包括7V10V12V有激光雷达无激光雷达的配置都可以支持那在算力方面我们的端到的模型可以部署到三打算力区间的任意芯片最低到30多TOPS最高到1000TOPS的芯片都可以部署那地图线方面其实我们就用普通的ADMAT导航地图就可以了做到真的只要有路就能开那为了实现这一点我们研发了独特的平台化训练的技术常规的模型训练通常会要求训练和推理使用相同的一个传奇的输入比如说我们训练时候如果用7V的相机输入推理时候也只能用7V相机输入两者必须一致那因此一旦传染器配置多了比如说增加一个相机呀或者甚至这个传染器配置变了数量没变但是传染器的分辨率焦距变了他就需要针对这个新的构型去训练一个新的模型这显然会极大的去增加了数据采集标注和模型训练的成本那卓越做法呢是针对三档算力平台我们叫中算力高算力和期间算力分别只需要训练一个多辣的模型同一档的算力可以支持多种类型的芯片以及任意的传染器的配置这背后就是我们独特的一个平台化训练的技术在训练阶段我们可以把所有构型的传染器数据一起用于训练那并且不同构型数据还能互相增强啊彼此的一个性能同时我们也做到了一次训练多构型多平台都可以部署不需要说针对特定的构型和平台单独进行微调因此卓越不仅实现了全平台都复用相同的端到端算法架构还能将大算力平台的模型能力啊快速的下放到中低算力的平台啊做到样不同价位车型都能够部署端到端大模型都能够支持这种高级的支架功能那么在训练和部署方面我们围绕英伟达的平台也和英伟达合作做了很多优化加速的工作比如针对端到端模型的训练我们在训练的Pine模型计算变形化和框架方面都做了很多优化使得我们整个端到端训练的的速度提升了5倍以上那在部署方面右边是端到端模型在英伟达All in N平台的部署因为这颗芯片大概是84Tops算力不算高为了实现端到端模型的部署我们也做了大量的推理优化包括推理的流水线并行和各种底层算子的优化使得我们从一开始在All in N推理一次要129毫秒优化之后做到了57毫秒比较好的满足了量产的需求这也展示了我们最近拍的一个城市领行的视频它的硬件平台就是刚才提到的因为来到All in N的芯片84Tops的算力啊传染器用了12路的相机还有5个毫米波雷达那这个视频啊是运行的是我们城市Unload A的一个功能对可以看到啊他能比较好的实现比如路口拐弯的时候对其他车量的这个样型啊还有刚开始左转的一个过程大家可以看一下啊啊大家可以看一下啊啊大家可以看一下啊那在这个双铃芯片上我们上了端道端之后其实在很城区很多复杂场景都能比较好应对比如像刚才那个环岛的通行也能比较好的比较丝滑的去通过还有刚才对这个是遇到对施工的水高筒的药性还有跟其他车量的交互啊啊还有你也跑了一段城中村的路啊就有比较多的人车混混型的这种这种路况啊这是我们的一个平台车啊那这个平台其实也有对应的车型已经量产了遇到这个聆听车能够要行啊以及必要对象压线的货车OK行那前面讲的比较多这种驾驶方面的一个东西最后还想跟大家分享一下我们对于呃称价融合的基数架构的一个思考那从去年开始其实大家都能看到一个趋势就是无论是正驾驶还是智能智能坐舱啊都在引入LM大语言模型的能力啊来去增强智能化的表现啊那但是在赤端部署LM其实是比较非算力的目前能支持端侧跑LM的大算力芯片其实也不多英伟达的硕是一个比较好的选择他有700到1000TOPS的算力那么针对智能驾驶和智能坐舱的应用LM的使用场景其实又不太一样如果针对两个域分别部署一个LM其实是非常浪费算力的啊所以我们设计了一种双价融合的大模型部署的架构简单来说啊就是支架域和坐舱域共享一个LM大模型通过这种双价复用大模型的方式啊我们可以显著降低赤端算力的一个成本不需要说分别部署两个大模型OK那最后总结一下我们目前前面提到的端到端的支架系统已经在十几个车型上顺利量产目前卓宇也跟9个优质的车企客户建立了合作今年还有30多款车型在量产开发中前面介绍到的端到端世界模型和松城式的自动驾驶的体验的产品今年也会逐步的量产上吃希望能够尽快的把好用的这家体验带给大家今天我要分享内容就是这些谢谢最好ия