 Hello everyone, thanks a lot for joining us for this GTC session. I'm so pleased to meet you all and get you all here with us for this session on empowering innovation with incredible startups enabling scientific breakthrough. Three startups are with us today, all of them part of the Inception program, Inception program for which I lead the South Europe region and the Benelux region. Super happy to have you all here. Great representations of everything that we do with the program and everything that we've been doing with the program for the past eight years. Even greater things to come with the program growing and discovering startups like yours, more or less mature on the verge of doing great things. So thanks a million for being with us. I'd like to introduce you first with Hannah, working with Amphitrite based in Paris, close to Paris in Saclay, to be honest, and working on amazing things, looking at the oceans and making some of them better, safer and faster. Hannah, please. Hello, thank you firstly for having me here. I'm very honored to be on a panel alongside Yann and Pierre, who are doing very interesting impactful work. So I'm Hannah Bull. I lead the AI R&D program at Amphitrite. So Amphitrite is named after the Greek goddess of the sea. And indeed our work centers around how we can use AI to predict ocean currents, winds and waves. So I thought I'd start off just by showing you what our software looks like. So these are the ocean currents, which we've predicted at a very high resolution at a global scale for today and also for the next week. So if you'd like to check out our software, you can have a look. So our work centers around how ships can best harness the power of ocean currents, winds and waves. So we help ships know when is best to travel as well as the optimal costs. So this helps reduce travel times and fuel consumption and ultimately carbon emissions. So our key R&D work is centered around how to use satellite data with AI methods to produce state of the art weather forecasting methods. So this helps us. This allows us to optimize ship routes at a very fine scale. But also helps in other very interesting projects like figuring out how microplastics diffuse in the ocean and how we can optimize plastic collection. Thanks a minute. I'd like now to go to Pierre. Pierre is one of the most brilliant minds I've had the chance to meet during the inception, creating the future of next-gen materials. We talked about plastics for a second. Let's talk about what's next after plastics and what we can do to make the world a bit more cleaner. So Pierre, if you will. Very nice to be here. Nice to meet you all and absolute pleasure to be on panel with these fantastic minds. So my name is Pierre Salvi. I'm the CTO at Cambrium. You probably have heard about AI for drug discovery a million times. What I like to say is like, we don't do drugs. We make materials. And I think that that sums it up a bit. So the idea that we build the materials of the future with biochemistry and particularly use proteins. The idea is that we don't just predict what protein will have the right material properties to replace polluting incumbents. But also we produce them in the lab and scale them up and sell them at the time scale. So we're not just a computational company. We actually make material changes. Yeah. And I'd love to tell you more about this today. Thanks a lot Pierre. And last but not least, Yann Lechelle is part of those people that have made scientific computing somewhat easier and more streamlined for the whole of us. And beyond being one of the fathers of CYCLEARN and everything that you guys have been relying on for years now, he's now ahead of a new adventure. And it's a crazy privilege for me to have him on this panel with Hannah and Pierre. Yann Lechelle, if you please, please. Thanks Pierre. So to be correct, I have absolutely zero merit nor fatherhood pretension for CYCLEARN because it has been built by a team of researchers for the past 10 plus years and also an entire community spanning the entire world. So this technology has been around for a while, has been in a way participating in growing scientific computing, largely anchored in Python. So scientific Python community in so many ways, and has been instrumental in creating the field of data science. So it is the de facto tool for statistical machine learning. And so I'm just the CEO of the company that is the spinoff from INRIA, the research center. And we are the CYCLEARN company, if you wish, to develop a series of solutions and services around it. So the best analogy that we can find is basically we are to CYCLEARN what Red Hat was to Linux. That is the best analogy as a company. So, yes, we are firmly anchored in the field of scientific computing. We enable compute and we leverage compute so that we can make the most out of data, basically. That's what we do. And we have a mission as a company. It's baked into the bylaws of the company, which is to produce a suite of open source technologies, commons, if you wish, also to enable data science at scale. Because that is the issue also at a societal level. How do we ensure that computing and technology on top of computing enables the entire world to take advantage of those data points that mean nothing to actual human beings? But we need the machines to make sense of it and drive improvement and optimize whatever we do so that we can ensure a more optimal future for society. So that is the positioning of the company. That is what we do. Thanks a lot, Jan, Emilian, for being with us today. I have one question for you all. During this adventure, you've all been through challenges, hurdles that you have to overcome and get to the next step. Quickly, Jan, what was the first one? Like the biggest thing that you guys had to face in the great adventure of Probable? So Probable is an interesting case based on an asset, scikit-learn, open source, meaning that it's difficult to monetize open source. Everybody knows that. But the specificities of this project, it's been that it's been downloaded 2.2 billion times, 80 million times a month. So it is already massively adopted in a way by every single data scientist on the planet. It's part of the toolbox. Right. So the question for us is how do we create the services around scikit-learn so that we do not take away from the community? In other words, you know, it's quite easy to decide to change the license. Well, that's not what we do. We keep scikit-learn as open as possible and we will maintain it. That is part of our mission. The question is how do we build on top of that? And so we have taken several months to identify what it is that we can do to be additive to scikit-learn in a way that greatly complements, in this particular case, enterprise data science. So to us, the big challenge has been to identify something that others weren't doing, in a way creating a sort of blue ocean strategy for which we identify a pain point in the market around scikit-learn. And it turns out that we found in a roundabout way that scikit-learn created a huge problem also for companies around artisanal data science. And so we're trying to fix that. How do we improve data science so it's less artisanal and more on point with business objectives? It's a hard problem to tackle, of course. It definitely is. It definitely is. And I like the fact that you mentioned additive and also what people are not doing because it leads it to a great segue for me, to Pierre. Because basically you're doing this and that at the same time. So challenges that you had to face in maybe convincing people or? Yeah, I mean, we didn't have the luck to come in with already the sort of scikit-learn flag on our backs, right? You know, you look at us and it's like a bunch of young people with like wild ideas. So I'd say the first challenge is credibility, right? I mean, you can have like, you can have the best minds that you have met and hire them together and put them into a fantastic team. But like, ultimately, you have to show a little bit what your credibility is for, right? And so for us, like, of course, you talk about materials, you want to replace all the plastics, micro or micro that are around us, right? But like, if you're a tiny startup, you have no time on the block yet. Nobody knows your name. And you say, you start saying things like we're going to replace all the plastics in the world. Nobody's going to believe you. Nobody's going to fund you, right? So I think that's one thing. But I'd say this is part of the game. Maybe things are a bit harder is, I mean, funding, right? I'd say funding things that are not software in today's age is a bit harder, right? Convincing investors that it's important to have factories in order to make a material change in the world, I think is difficult. So I think that's definitely been a problem. And I mean, at the end of the day, we're doing deep tech, right? And as I like to say, we're having a double deep tech sandwich at Cameram where we do like molecular biology. So we are literally editing DNA. And at the same time, we're doing like protein engineering. So using AI to create new proteins that the world has never seen. And you put all of that together into a gigantic Big Mac. And you're like, hopefully this works. When investors see that, it's hard to convince them that, you know, this is the right way to do things, right? But, you know, the way you put them wrong is like you actually stay around, make recurring revenue and show them that, you know, the double deep tech sandwich is very digestible. That's, that's, I love the analogy of the Big Mac of science and things. I love together. And again, thanks for the segue, but it's amazing that you talk about like credibility and explaining to people something that is super hard. Because like, talk about simulating oceans and explaining people that, oh yeah, it might save you tomorrow, but you don't know it yet. Hannah, in your case, like, I guess there were multiple hurdles, but maybe one that's, you know, stood out among all the others. He's building on top of alpha fold somehow. So there are these foundational AI models, which exist. In our case, this, this is like foundational weather models, which are done using AI. So most of these foundational models, they have really great results on paper. And if you look at the standard benchmarks, they perform really well. But then as soon as you go to a specific case, so our specific case is ocean weather. Well, they're not exactly adapted to ocean weather. They're more about predicting variables in the atmosphere. So we have to somehow build upon these models or fine tune them. And then also like nice results in a scientific article don't necessarily translate directly to nice results operationally. So our challenges are how to adapt state of the art AI models to our specific case, how to build tools on top of this, which reflect the incentives and the way in which ship functions, ship companies actually function. And also to have good results operationally, not just on paper. So I guess one of the main components there is that you guys really faced not only the, because like the science is there and you know exactly what you're doing because you're all specialists in your field. And you know that there is a market for this, that people are actually looking for it or they don't even know it yet. But tomorrow they're going to be very much craving for this. But you also mentioned the fact that it's somewhat hard to build credibility and reliability with the market and the customers. And on that, what was the role of collaboration with the industries when it came to actually creating that particular traction in the market? And Yann, I want to go to you on that particular point because you guys benefited from the scikit-learn environment and everything. But you're also trying to put a foot in something that's, as you said, like is the red hat of what was Linux or what is Linux. How do you make this possible through collaboration? And I would say like, especially with us. So I'm a proponent of openness in terms of an enabler of all the good energies. In other words, we need people to have access to technology and it comes in different shapes and forms. Sometimes it's a proprietary SaaS solutions. Sometimes it's an open source middleware. But at the end of the day, there is physicality and NVIDIA is one of these essential players that brings, you know, compute to life through CPUs and GPUs. So in our case, we see the world as a mix. We talked about the Big Mac, right? So I would say millefeuille in French. In other words, there are in the stack so many players going from energy. Actually, energy is a new player in town. We sort of dismissed that element. But cloud providers know this very well. Energy is a key component. But now because of AI and the demand on AI, energy has become a critical component, which I would put at the very bottom of the stack. So energy, then data centers in which you put chips and storage, in which you put infrastructure as a service and then platform as a service and then software as a service. So it's a full stack approach. And we need to compose with every player that matters. And NVIDIA clearly is a player that matters in the full stack. So for us, it is essential that we enable every level of the stack. So NVIDIA has a specificity, namely in GPUs, but also in CPUs. So we've worked together at multiple startups in the past. In the past, I was involved at SNPs, which was a privacy voice technology, privacy by design. And we were operating on Jetson architecture. But the Jetson architecture was critical because it was edge computing with a powerful framework. And so we needed to make sure that it was empowering that stack because that stack solves a specific use case. Same thing today. In other words, how do we ensure that our technology binds very well with the specific products that NVIDIA sells today to data centers, but also other segments so that the gains for the clients, the total cost of ownership typically is maximal. Right. So we're a provider of that technology. So therefore, NVIDIA is a partner in the way we equip the market. And then there are other ways to do business also around the open source models. So we have certification and training and support, but also new software that we're building. So there are multiple levels, but I see the world as a very complex and dynamic mix in that we need to always think ahead in terms of adoption. It's always hard to know how in technology and I've been in technology for almost forever. You never know what people are going to do with technology. Technology is quite neutral in so many ways. And you never know. And if I may, NVIDIA at some point mostly created graphics cards for 3D gaming. And then at some point it was used or abused for blockchain mining. And then it became the obvious platform for AI. Who would have known? Who would have known? Who would have known? Who would have known? So the point is we need to make sure that we optimize everything so that people at some point embrace the technology and do something good out of it. Thanks for the memories. There was a while ago, Jetson and Snips and Edge AI for speech learning and things. Thanks for the memories. That brings me back to the very early days of NVIDIA. So thanks for this. That's a great segue. Again, you guys, thank you for some segues between you guys because this is really perfect. I have nothing to do. Pierre, you guys with the team, you're working on something that can't be achieved alone because you're providing the very basics of many things in industries that you're just a piece of it, but a very important piece of it. So beyond collaborating with NVIDIA and the inception and the way we help you in many things, how does that collaboration with NVIDIA mix with the other collaborations? How does that like spreads throughout your ecosystem? Yeah, there are. I mean, thanks for the question. I think it's so much that can be said about this. The first thing is deep tech, right? Deep tech means you're doing stuff that usually puts together many, many different deep levels of understanding of different types of sciences. Right. And so in our case, it's like it's molecular biology. It is what we used to call statistical learning is that machine learning and AI. Right. And pure hardware stuff. Right. So if you just take the fact that the center of our R&D design loop in the computer basically relies on specialized models to design biological molecules at a high rate on specialized hardware, then already you see where the collaboration can happen. Right. And in practice, like interacting with NVIDIA allowed us to talk to not only experts that have built protein language models, because like we can't hire them all. Right. So we've seen experts that have been really, really good at translating the structure of these models into software that was very close to the hardware. And we've seen by using the NVIDIA tricks up to like, you know, 20 X speed up in some of our computations, which saves us a ton of time. Like all of a sudden, like something that took a month to compute takes only 1.5 days. So for us, this was critical. I think this is the obvious answer. And there's like also the less obvious answer, which is like, because your company acts as, I would say, like almost concrete now, like cementing together different pieces of different industries. You talk to so many people that when I'm like, hmm, I wonder which chemical company is interesting in this particular functionality. Then I can ask the people at the media and, you know, somebody will be like, hey, yeah, this gigantic chemical conglomerate from Japan might be interesting that, you know, and for us, this is a lot of the hidden value that comes also with this ecosystem. And so I'm super thankful for that because, you know, you get really two different value propositions from the same collaboration paradigm. And I think this is the type of ecosystem in which we, we like to evolve. Thanks. Thanks for the praise on, on how we federate this ecosystem altogether. This is super important for us in terms of feedback. Thanks a million to really why we do this. Anna, same question for you. It's, it's even further because of the novelty of trying to do what, what, what you, you and the team are trying to achieve. I guess it's even more important in some ways to figure out those collaborations. Yeah, exactly. So, um, when you think about AI, obviously also think about GPUs and we, yeah, like I said, we can't really do without an NVIDIA GPUs. Uh, but, uh, also we're using the earth to platform. Uh, so NVIDIA also does really great research, uh, particularly into foundational models. Uh, so the earth to platform has a model called forecast net. So forecast net is basically a foundational model for atmospheric weather prediction. And, uh, this is one of the models which we're building on top of. So, uh, we're fine tuning, retraining this model, but, uh, specific, specifically. For our use case. So for, uh, for ocean data and also on the earth to platform, uh, there is another model. It's a generative AI model called core diff. And, uh, basically the idea behind this model is you can take like large scale global data, which, uh, capture large scale, um, global weather phenomena, and then a trainer diffusion model on top of this to get the really fine scale information. So this model is very interesting for us as well, because really what's enables us to do fine scale ship routing routing is this like very high precision, very fine scale, uh, ocean weather model. So it is, uh, this type of generative AI model to get, uh, really the fine scale details of what the ocean weather is like is what enables us, uh, to do what we do. Excellent. And thanks for that. Thanks for the recognition of the work we've been trying to achieve with, uh, with us. This is super important also. And this is also very much thanks to the community that has been working on this with us. So, uh, thanks a lot. And you mentioned one thing. I, I like the fact that you all talk about foundational model and the importance of deep science behind all of this. So I want to go back to you, Yann, because you were there in the first very early days of the deep learning and everything. And it's been fundamental in everything, especially at SNPs. Uh, now that you brought back the memory, uh, it was key elements of everything. Um, so I, quick question for you on the importance of knowing what deep learning is and knowing how to handle data makes a very big difference in the way you create and use and scale using, um, large models, whatever they are. What we, yeah, what would be your take on this? Like if you had like the wisdom of, of, of one of the OGs on this, what would it be? So I should note also that I was CEO at scale way for a couple of years between 2020 and 2023. So I was very much, uh, in tune with the market dynamics, uh, and the concentration within cloud operators. So I'm seeing a number of things that may, um, affect pretty much everything we do, um, because the geopolitics are at play more than ever. And, um, I find that, you know, technology has never been as political as today. So this will play. You know, in a way that. We'll decentralize compute. So we've been used to huge hyperscalers and, you know, large data centers harnessing and concentrating all of the power. But I'm finding that this is not something that scales very well, actually, in terms of energy. Uh, it's very difficult to find a lot of gigawatts in one place. Number one, number two, uh, because of geopolitics of the data, uh, certain countries will want to make sure that they harness, uh, and control the data that they produce locally. So I'm seeing a world where, and it's not so much desiring a particular outcome. It's just that I'm seeing a world where edge will play a major role going forward. And the forces at play, you know, either through game theory, where you look at the sequence, typically a Lama 2, which was leaked or opened in the world, created a sequence, which is what we have today, where models are being commoditized. And pretty much everyone can now generate a model. So, you know, you had Lama 2 and then you had Mistral and then Deep Seek. Every country in every construct that can spare a couple tens of millions will spin their own model. Why? Because there is a cultural aspect to it. So number one, there is a fragmentation, not a concentration of, uh, model creation. Number two, inference. Inference will also spread to the edge because that is what we need in terms of privacy. Back to Snips. Snips was all about privacy by design. So we wanted to process voice on device because it's not a very good idea to have a Microsoft, not a Microsoft, a microphone that broadcasts your voice to the cloud at any given time. We need a bit of privacy, especially in the bedroom. So, you know, those microphones streaming data to the cloud makes no sense at all. At some point we'll need devices that can process that human interaction on device or on the edge. And a company is also, uh, or desires some sort of sovereignty as well. So sovereignty can be thought of as a, as a notion that applies to individuals, to corporations, and also to nation, you know, nation states. So therefore I'm seeing, uh, not a fragmentation, but a distribution of compute, um, by the sheer force of game theory, um, openness. In other words, the open sourcing, which means open weights in terms of models, plus the need to improve and adopt a copy that is your own, uh, will play towards a redistribution of everything else. And we've seen this in tech for the past 70 years, you know, mainframes and, and PCs and, uh, centralized cloud and decentralized cloud and so on and so forth. Um, you know, centralized, uh, uh, central, central bank banks and then web three and so on and so forth. So the, the history of tech has been following the very same pattern. As soon as you have too much concentration, it deconcentrates. So the question from, uh, you know, from a chip standpoint is, you know, are the chips, uh, good for the cloud or are they good for the edge? I think Nvidia has an answer for both. Um, the point is that these things will keep on, uh, rebalancing each other out. Uh, and that's what I'm seeing as a, at the macro level. That's a good thing that you talked about openness and everything, because I think this is very much key, uh, in the work that Amphitrite is doing, uh, and Hannah and the team are trying to tackle. Um, I know a little about how you guys collect data and how you use it, but I guess there is a future where data collection points will multiply by the dozens because of edge computing being much more and more on board ships and on board. Buoys and maybe even other things that we don't even know about yet. Um, what's, what's the next frontier beyond what you're creating today so that you can process more data, more accurate data. And, and, and even beyond this, bring people to, to the understanding of what it means in their daily life. Not only like for shipping goods, but for everything else. Yeah. So, uh, it's true that the amount of satellite data is huge. Uh, it's so big. We, there are so many applications and so many potential use cases of satellite data. And, uh, there's a large proportion of satellite data, which, uh, it's probably not even touched by anybody. Uh, it's the product of multiple decades, uh, of, of public investment, notably. So from, uh, the European space agency or from NASA or from, uh, different other public investments in satellite data. So we have a lot of very rich data sources and, um, different ways, uh, to process them indeed. So, uh, for, for us, I guess, so, uh, Jan spoke about, um, uh, so Jan spoke about energy usage. So actually for our application, uh, the energy usage is actually less than in the past. So in the past, a lot of weather modeling is, um, based around running numerical models. And these numerical models are actually computationally very heavy and very complex. Uh, whereas our AI models, which do the same thing as these numerical models for the ocean, they're very fast to run and they use far less, uh, computing power. And, uh, the nice thing about, um, about, uh, AI now is that, uh, somehow it enables, uh, small companies to, to do a lot of things. So in the past where you might've needed a hundred scientists to study the, uh, physical dynamics of the ocean to come up with equations to describe this. Uh, now you can just have a team of less than 10 people who train an AI model and get, uh, similar or better results. Uh, so there's a lot of space here for innovation to take, uh, uh, to take things, which in the past you would need hundreds of researchers to look at, uh, to look at various aspects in detail. Now you can do this a lot faster with less computational efforts, uh, using AI methods. And I just want to go back to my question of, of, of, of the public awareness around this. Like how much do you know people think they know about what, what, what the ocean means and, and why this is so important and why you guys are getting so much funding through this in two words. Yeah. I mean, uh, understanding the ocean is very important in the long term for understanding climate dynamics and climate change. So for this, you need to understand, uh, the more long term trends for the moment we're looking more at, uh, more at the short term trends. Uh, but there's lots of potential to, uh, to use ocean data to save, uh, carbon emissions. So for decarbonization, it's, it's very important. So, uh, shipping is about 3% of global carbon emissions. Um, so if we can reduce this, then this would have a huge impact. So I think, uh, the future of decarbonization is really, uh, is really driving what we do today. And it's good that you talk about decarbonization because this is really one of the key key, uh, aspects of, you know, of using less plastics and discovering new materials that will help us in, in getting rid of most of the plastics. That is actually like one of the basics of our everyday life today. Um, yeah, I know that there is something very important for you guys at Cambrium, um, around research and development and how, how much funding it requires, but also how much time it actually requires. Because yes, we can accelerate computing. Yes, we can go faster and simulate more things quicker, but it's not why things do go faster. Um, what, what, what, what, yeah. What's the next phase for this? How, how do you guys like are bringing R and D and, and all of that from great idea on the whiteboard to, okay. Now we are in a lab and we're producing at scale for big corps and big money. It's a multi-step process. Um, just to hit, to echo what Hannah was saying, like, I mean, CO2 emissions at the end of the day is the money we're trying to optimize for, right. Or like we, like we really want to decrease them. Uh, shipping is 3% of the CO2 emissions worldwide. Um, materials is like 25% of the, you know, GHG emissions worldwide. So like all of these are like extremely important. Uh, and so that's why we also want to move fast. Right. We are, we are on the countdown. Um, what's I think is really interesting is when you are in the pharmaceutical sector, everybody is complaining about the fact that, you know, drug development takes years and a lot of money. And then you're like, it is the same with the chemical industry sector, you know, like developing a new material, developing a new molecule, developing a new modality that will, you know, be the Gore-Tex of tomorrow. It takes years of development and a lot of money. Um, the problem is, I think the sector is not ready yet to realize that in order to accelerate, you need to put more money into this and need to put more money towards the people that know how to do the things. Um, we come in with a value proposition of saying, we can take the, the modality you want to produce and make it maybe five times faster and cheaper than any one of your, um, internal development teams. Why is because we don't have the incumbent weight of like, you know, re reusing the, the infrastructure you have, the methods you have. Um, and also because we were just, we, we grew up with AI, right? So like, there's a way for us to make these things faster, but that's only like a part of the, part of the problem. Cause like, you know, you can come up with the next revolutionary material, but if you don't have a way to like scale it up and bring it to market and bring it ultimately to them, to the consumers, then you're not going to do, you're not going to do much. Right. And here it's, it's a bit of an unfair fight. And I think it's really important that people realize how unfair the fight is. Like we are fighting against 200 years of optimization in the petrochemical industry, right? The, the, the cost margins and the optimization that went through that, that all these companies went through are insane. And so all of a sudden you're like your four years old startup is like this double deep tech sandwich and you're trying to reach cards, right? Um, difficult. So the way to do this is instead of going for commodity materials, like, you know, the, the cheap things that make a lot of things, you start with specialty chemicals. You want to go for the things that are still hard to make, still expensive to make, and you want to shift them away and replace them. Mm-hmm. It's a material that is like, at least performing as well, if not better. And then once you have proven that you are able to do this complicated thing, this specialty chemical, and then you can go, you can do good margins on it. Then you have already proved the investors or, you know, anybody else who put money in your company that you can do the thing. You have R&D that is already able to solve the problem. And now the problem is just about optimizing these R&D cycles, right? And you can work down the cost curve so that you can go from like specialty chemicals to commodity chemicals. And then the last step is moving these commodity chemicals inside the companies that are actually making the finished goods, right? Like Cambrium will never produce, um, like a finished piece of equipment, but it will produce the ingredients that will allow you to make your smartphone, for instance, right? And so we are working directly in the factories of the companies that are making the materials that the end user is seeing. So that we make sure we develop solutions that do not need them to change all their machinery or their investment over the last 200 years. And I think it's really important to really have this end-to-end vision. And what I, what I like to say is we often get the question of like, oh, but if I've ever thought becomes open source, like open for instance, it's open source. Like there's also this ever two model that came out recently, which is absolute piece of art. We often get the question, oh, but isn't your business model moot? And the answer is no, like we use these tools, um, to show the world, how you can go from the lab scale to the, to the real world scale, because we have the data to teach them, to fine tune them to the actual use case of like knowing how your molecule rescale, right? Like the, the summary is alpha doesn't know which molecule will behave well in your factories, but we have the data that knows. And so we can retrain alpha falls so that it outputs only molecules that we scale properly in the real world. This is perfect segue again, honestly, you guys perfect for this. Um, I want to go back to the collaboration side because all of you've all explained what are the challenges and, and, and things that you guys are working on. And one common theme between all of you is inference and TCO and cost of ownership, cost of, of running a solution. We praise ourselves and NVIDIA in providing you with the best tools so that you can create the best solutions and do your life's work as Jensen says. We recently launched a couple of tools that everyone talks about, NIMS and agents and all that. In very quick, quick sentences, each of you, can you give a hint to the people that haven't been using it already? What it changed in the way you were trying to go at scale without reinventing the wheel on a few things. And yet I want to start with you on this. Well, I can't really comment on that because we are focusing on a different stack. As you know, perhaps psychic learn is not the go to solution for deep learning. However, psychic learn handles, you know, vector calculations. And so we are actively working with NVIDIA. In fact, there is someone at NVIDIA who is a core developer of psychic learn. And so we are working already on, you know, improving the way psychic learn makes the best of GPUs, for instance. So that is a long term project. There is so much more we can do. But while some people are working on specific tools to provide a 10x improvement here and there, the work that we do may improve, you know, by 1%. But that 1% will touch the world because of the distribution of secular. So every point increase matters to us. So we are working on these things. So it's more, you know, groundwork that has massive societal impact. Because if we shave off 1% of compute worldwide, that's significant. While emerging use cases, and I'll let Anna and Kerr comment on that, will focus on the emerging use cases with these tools that you mentioned. So, you know, again, looking at a millefeuille, we can optimize so many things in the full stack. And thankfully, there are so many players in the field that these things will mechanically occur. Anna? Yeah, so like I mentioned, we have lots of, we're using lots of satellite data. And actually, it's inference time for our ocean models. It's very fast. So we use, of course, NVIDIA GPUs. It's inference time. And in terms of computational performance, we are able in just a few minutes to make forecast predictions of oceans. So a lot of our efforts at the moment is how to improve these models. So we're spending a lot of time trying to figure out which data we should use for training, how we can, how we can train our models better, how we can increase performance. So at the moment, we're doing, we're making about twice as few errors as like a standard traditional models, numerical models, which you use in ocean forecasting on ocean currents. And we're trying to do the same things with ocean winds and ocean waves. Impressive. Pierre, your take? Yeah, I mean, I'm a big fan of BioNemo, which is a life science branch of the specialists software that NVIDIA publishes. Right? We had the luck to be early testers of the suite and the containers. I mean, I don't know if anyone in the audience follows like how many protein or BioG related models are published each month, but it's like, it's a lot. And so tasking your whole team inside a company to try to like, you know, onboard them each time they come in is a gigantic task. And it's also, I think, wouldn't be the most efficient use of our time. But having people on the hardware side being able to say like, hey, we actually onboarded this on a, you know, simple to use container. You can just download the container, deploy it into your infrastructure and use it for inference and fine tuning. First, there was a game changer. Right? And I'm talking up to 100 X performance increase for inference on some particular tasks. And for us, again, like, it's a totally different way to look at your work streams and how you can access new modalities in your model and your design. We also use, I mean, after BioNimo, a bunch of names related to protein use cases have been published as well. And we're also using them. So yeah, this plug and play modular approach for us was absolutely a game changer. So yeah, this is a game changer. One thing though, because you are helping your customers save money, go faster to market, scale better, do things better faster. But it takes money to create money. As the wise man said once, where are you guys with funding? How much of a challenge is it for you being so much at the forefront of doing new things in science? Get to convince people with lots of money to fund your research or fund your company so that you can go to step after. Like, how does it work? And I want to start with you because you are the youngest of you three in terms of company age. So I really want to know how, how do you go from, hey guys, we're going to simulate the ocean and try and figure out how we can paddle plastics in the oceans and make sure that those guys shipping containers are going to save a lot of money. How do you convince them to fund you? Yeah, good question. So we're a spin off company from the Ecole Polytechnique in France. And so from the start, we've had a lot of support from the Ecole Polytechnique. We've had lots of collaborations with academic research labs. We've been involved in lots of R&D projects, which have been funded by public funding and by European funding to get the technology to work. We've since looked for some investors who have invested in the company. I think our main challenge now is getting funding not from investors, but from clients. Yes. So it would be nice to have more recurring contracts from ship captains who are using our software, using our routes in order to optimize their trajectories across the Atlantic or across the Mediterranean Sea. So this is the main funding source that we're looking for now. We have many projects going on with large shipping companies. So for example, like CMA, CGM. But it would be nice if we get more funding from projects at this stage. Yes, sir. Yann, I guess funding has been a problem that you've tackled like so many times that it's not even a problem anymore, but it still is. Well, I mean, yeah, that's the universal issue with startups where we need to, you know, put money at work to create new technology that does not exist so that it generates a return down the line. So our project is quite different in the sense that it's, again, the emanation of a research lab. And the French government is a major sponsor. So we are getting some partial financing from the government directly. And we are probably the only, the first startup ever to benefit from government financing through a sovereign fund. So that is a new type of model, but I've proposed a model where financing is always balanced between private investment and public investments so that we have the joint approach, which I think is a model for future companies. Modern companies, which is to provide as many financial dividends as they are non financial dividends. So our production generates open source as well as financial dividends. And this is the sort of companies that I think we need going forward. Again, the world being complicated. So given the nature of the asset, which is already patrimonial in so many ways belongs to humanity already. Psychic learn is mature. It's used by everybody else. And we're not going to challenge that notion. So it is owned by everybody. So therefore, the nature of the company is dual. So we are appealing to public policy making, and we are appealing also to private money. So some of the private money says, you know, we want to sell this company ultimately to the highest bidder. The answer is no, this company is not meant to be sold to the highest bidder. This company is meant to succeed long term, possibly IPO, and be sustainable to achieve its mission. So the question is, how do we seduce investors on a long term plan that is super ambitious, and yet is not strictly limited to financial return? And I believe that you can provide super performant financial dividends and returns by adopting a model that is compatible with what people are looking for in terms of a corporate citizenship, if you wish. I think the new generation is more likely to join a company that embraces that duality than a company that is only focusing on financial dividends and just flips with the wind, depending on where the money is flowing. So I think the money part is not the only part of the equation that matters. It is also the long term long term plan. And as far as I'm concerned, I'm concerned about, you know, what is it that we desire as a society as well. And again, perfectly to my question to Pierre, talk about mission, replacing what's been there for 200 years. And as you said, like super optimized by an industry that is so powerful and so rich that they had the time for doing it. So the mission of tackling this plus that combined into one, as you said, big sandwich, not to name any, is probably mind blowing for most of the people that are funding startups. And even to the customers. And even to the customers. Next challenge ahead. And I know that you guys have tons of challenge ahead. So what would be your best wish for the upcoming future on your end? Oh, you know, this is one of my favorite topics, right? I think. I think there's a recency bias and a historic problem also in the way people have been investing in the last 25 years, you know, I think people are still trying to reproduce exists like in the head with Facebook or the Google's of this world, right? I mean, PayPal, I think maybe it's the what stays in people's mind. But the problem is, I think we have consumed a little bit everything that had to be done in terms of like, you know, making apps that will do 100x return on investment. And also, right now the world is burning. So maybe we should like, to me, we also have a duty to tell investors like, guys, there's actually something really important happening now. And this is your opportunity to maybe, you know, put a chip early on so that you make a difference, you can make a material difference in the future. And that is like investing in stuff that will change the real world and not yet another app, right? I think. So you have two types of investors, right? You have people that, you know, answer well to this sort of like mission driven statements where you like, we want to reduce CO2, help us do this. And you can see the glint in their eyes and they're like, okay, cool. Yes, we want to be part of this. Unfortunately, there are not the majority. The other majority is investors where like you need to show a financial model that works, right? And I think, again, this has been a problem in the biotech sphere. And I'm talking to non-pharma biotech, where people have been saying like, yes, yes, we do deep tech. Just give us a lot of money and then we'll change the world for, you know, 10 years. And then maybe three gigantic companies have failed in the last five years trying to do that. And so now there's like this general lack of trust about the fact that, you know, our particular technology, like engineering DNA can change the world. And so that's where you also have to be really smart and just be like, we are making a product early to show you that we are not just dreaming about things. We are making them happen, right? And my wish is that people responsible for unlocking investment start understanding that we need to put the money in actual steel in the ground hardware. We need to stop sitting on our hands and trying to get PayPal exits, but we need to create stuff that will make a material change. And that means making tons of products, whether it is plastics or whether it is optimizing the rare earth elements for the whole energy supply chain or chips, right? Like, like, like Hannah is doing. And all of this requires for people to stop sitting in their hands and hoping for things like that happened 15 years ago. And I think we have a duty to keep telling them, like, the world has changed. The modernities have changed. This is how we do things now. I love the fact that you all talked about legacy and sustainability in what you do and not just about the money. So thanks a million for talking about all of this and the money and the vision and how money enables vision and your life's work. But in, as you said, yeah, and the world is changing. As you said, Pierre, the world is burning. And as you said, Hannah, the world is like super complicated and we need to simulate it to do better things. So one word of wisdom from you guys from mission to next next steps. What would be the word of wisdom that you have for the next generation coming after us? And Hannah, I want to start with you. Yeah, sure. So like I said, we're not only focused on getting investment. We're also getting contracts with companies and demonstrating our impact. So building a company and scientific innovation requires more than just a powerful AI model. You also need to robust non AI tools to bridge the gap between research and real world application. And you also need companies or people with whom you can test this in operational contexts. Thanks. Pierre? Pierre? Pierre? Yeah. I think you need to hire diverse early on to get this noble effect. Because I think the biggest threat to, you know, the tech startups, like people going like really hard on one particular subject is echo chamber effect. So make sure you hire people that are not like you, people that will disagree with you so that you can learn from each other what it is that you're not seeing. Thanks. Yann? Okay. So in a couple of words, I've been developing this thinking around openness as policy for, you know, corporations, but also for nation states or even Europe, which is a challenger when it comes to tech. So there's a number of players that have been full stack and essentially driving most of the value capture big tech typically. Nvidia not being one of them. Nvidia is part of the magnificent seven, but it's not part of the full stack, such as Microsoft or Google or even Apple. These companies are great. That's not the issue. The point is there's enough concentration. And so I would take the path of openness that includes open science, open data, open standards, open source, open weights, so that we provide a path for greater adoption, but also understanding what's going on. We need more science basically. Otherwise we're going to end up in a dark ages where we have knowledge as a service, which is a terrible thing to provide because we need for everyone to know what's going on under the hood. So that's my advice, focusing on science, deep tech, because distribution is essentially captured by the usual suspects. So focusing on deep tech so that we can move the needle in terms of science. Thanks a million. Again, thanks a lot for being with us on this. I'm so pleased to have had such a panel with you. I am the one honored to have members like you in the inception program. And that's really what motivated us for the past eight years with that whole adventure through the inception. Working with people, moving the needle, as you said, and doing their life's work. So thanks a million for everything. I hope I will see you face to face in the very near future. And don't forget to tune in for the next GTC, of course. Thank you very much to each and every one of you. I will hear so much more about this content of you.