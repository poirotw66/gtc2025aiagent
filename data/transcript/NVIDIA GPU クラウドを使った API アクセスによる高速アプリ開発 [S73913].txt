 Let's get started. Thank you.はい 皆さん こんにちはこのセッションでは NVIDIA GPU Cloud を使ったAPアクセスによる高速アプリ開発と題しましてお送りしたいと思います簡単に自己紹介ですけれどもマイクロ乗車で13年間 開発者向けに最新技術を啓発するテクニカルバンディストの仕事をずっとやってきましたそしてその後ですねDELとかACCENTERとかElasicとかVMwareといった会社で同じような仕事をしてそして昨年11月にこのFETで同じくレバンディストとしてですね技術開発活動を継続させていただいていますよろしくお願いします本日のアジェンダーですけれども このような形になっています最初にFETおよびFET AI Platform の全体数についてご紹介していきますFETについてというスライドなんですけれどもこれいろいろ書いてありますので 後ほどご覧いただければと思います一言で言いますと ベテラム最大級のデジタルコングロマリットということで大変幅広く授業を展開させていただいていますその中核となるのがですね この FPTソフトウェアという会社で現在ですね 30の国と地域にわたって社員数が3万人以上ということで展開していますその30の国と地域の中にもちろん日本も入っていましてそこで日本法人のご紹介もしていきたいと思いますその日本法人が FPT Japan Holdingsですね社員数が約4000人ということで 非常に最近増えていますそしてですね 成長率も非常に上がっていまして例年20%近い成長率を遂げています国際表示の指認定なんですけどもこちらにありますような さまざまな認定を取得させていただいていますそしてですね グローバルテクノロジーリーダーとのパートナーシップいわゆるパートナー戦略ですけども非常に多くの大規模パートナーと お付き合わせさせていただいていてその中でもですね SAP AWS Microsoft そしてNVIDIAそれからGoogle Cloudといったところが 主なパートナーという形になりますそしてFPTのデジタル変革のコンピテンシーですけどもこちらは後ほどご覧いただければと思いますけどもさまざまな事業をさまざまなプラットフォーム上で行ってインテグレーション コンサルティング アウトソーシングなどを展開していますサービスという観点からもですね コンサルティングに始まりデジタルテクノロジーの活用 そしてITアウトソーシングのご提供そしてプロダクト開発ですね それからマネージドサービスの提供ということでエンドツーエンドでソリューションを提供していますFPTのAIファースト戦略ですけども まず左上ご覧くださいこちらはですね NVIDIAの認定技術者の9000人を超えたということで非常に多くの認定技術者がいますこれに加えて50人以上の活用を取得した それから95件の論文61の出版物ということで こちらはどんどん増えている状況ですそれからその下のAI専用インフラですけども これまでのGoogleクラウドAWS マイクロソフトラージュに加えて NVIDIAのGPUを使ったFITクラウドですね こちらも提供するようになっていますそして右の上の方は戦略的なパートナーシップということでNVIDIAをはじめ このような企業体との連携をしていますしそれからその下では ちょっと細かいんですがさまざまな著名な大学との アカデミックなパートナーシップですねこういったものを連携して 研究をしているということになりますそしてその下はですね 最先端のAI技術を使って研究開発それからさまざまなアプリケーションの提供などを 行っているというところになりますこの辺も後ほどご覧いただければと思いますこちらがですね FPTのGPUクラウドとAIインテグレーションサービスの 概要の中小化された全体像になりますまず下のレイヤーですね インフラのところをご覧いただくとGPUですね NVIDIAのGPUを中心として それを使ったクラウドインフラこれがFPTクラウド 今回ご紹介します FPT AIファクトリーですけれどもこの中でサービスということで 例えばGPUコンテナーだったりマネージョクラスターだったり ベアメタルサーバーだったりというものを提供していますそしてその上にですね アプリケーションのレイヤーがありましてご覧いただいてお分かりのとおり NVIDIAのNEMO それからMetropolisOmniverse Rapidといった さまざまなフレームワークですねこれを使ってですね その上のFPTの製品ということでこの後でご紹介しますが IBChat CodeWistaのようなものですねこのようなさまざまなソリューションが開発されて そしてデプロイされてこれをサービスとして提供していると いったようなところになっていますあるいはアプリケーションとして 提供しているという形になりますこのような形でですね サービスとしてはコンサルティングだったりあとはデータエンジニアだったりというものを提供しつつお客さまのほうに提供しているというような状況になりますそれではですね FPT AI Factorについて ご紹介していきたいと思いますGPU CloudがAI開発を革新という話なんですがこれは要するにですね パブリッククラウドがもう既にだいぶ市民権を得て だいぶコモディティ化してきたという現在ですねどの辺あたりがですね そのお客さまのさまざまな要求にござられるところなのかというところなんですよね実際にファイルプラズ上で ディープラーニングのVMを使うということももちろん可能ですし それも全然意味のあることでありますそしてそういった主体量が適しているものもありますしそれじゃないとできないものもあるんですねただ今回はGPU Cloudということで 例えばこのミニシャンになりますけども高負荷のAIワークロードなどに対してはどうだろうとそれは専用インフラを持っていた方がいいんじゃないかというようなお客さんもたくさんおられますまた必要に応じてですね 拡張可能なGPUインフラといったものを構築したり例えばこの月だけは使いたいけど その次の月は使いたくないとかですねあるいはマネージドのサービスとして使いたいので ずっと立ち上げておきたいとかですねあるいはこの繁忙期のところだけGPUを使って それ以外はですね重量課金でやりたいとかですね いろんなパターンがあるわけですねその辺りを柔軟に提供できるところが 必要とされているというところになりますまたその中でですね これ一番大きいんですが 競争力のある価格ということでそのようなパブリッククラウド上で ディープライニングのVMを使った場合に比べるとだいぶ安くですね 価格として提供することができればこれも非常に選択肢の一つとして 合っているんじゃないかということでこういったものが出てきましたこれはまさに顧客のニーズに基づく GPUクラウドということになりますねユースケースとしましては 今も申し上げたように高性能コンピューティングだったりとか AI 機械学習データサイエンス&アナリティク 真相学習と書いてありますけれども先ほど申し上げてますように これはそれだけにとどまらずですねGPUですので ディープライニングのVMと同じようにですね様々なところに使える もちろん各種AIフレームワークに対応と書いてありますけれどもこれ以外のですね 先ほど申し上げた いわゆるデジタルツインですねそれからレンダリングといった そういった作業そういった負荷にもですね 支えられるようなそのGPUクラウドということになりますはい FPT AIファクトリーについて この4つのピラーをご紹介したいと思いますまず1つ目は FPT AIインフラストラクチャーということでこれデモでご紹介しますが メタルクラウド GPUカスマシンManage GPUクラスター KubernetesですねまずGPUコンテナといったものがありますそしてAPT AIスチューディオというものがありましてこちらでモデルのいわゆる 事前トレーニングやファインチューニングといったものあとモデル自体のカタログ ハブですねこれをこちらから呼びやすく 使うことができるようになっていますまたノートブックを使って Pythonでこの上で構造を実行して結果を得るといったことができるようになっていますそして3番目は FPT AIインフラストラクチャーということで推論のところなんですが デプロイ モデルのデプロイとかあとモデルのサービス化ですねこういったことでAPI化して アプリケーションから使えるようにするこれも後でデモでご紹介したいと思いますそして FPT AIアプリケーションを そのようにしてできたAPIに対してそれを使ってですね アプリケーションをいくつか展開していますよという話でこちらは後ほどまた 3番目のところで ご紹介したいと思っています今のお話をですね もう少しレイヤー的に分けて細かく描いたのが こちらの絵になっていますそれぞれですね インフラのところに対応しているもの例えば NVIDIAのH100 H200といったものが 一番下にありましてその上がプラットフォームとしてですね FPT AIアインフラその中に先ほど申し上げたように GPUカスフォーマシンとかマネージドGPUクラスターとか ネタルクラウドとかがありますこの辺りはデモでご紹介したいと思いますそしてその上のですね AIプラットフォームと書いてあるところですこちらは AIノードブック それからモデルハブモデルファインチューニング そしてその隣のですね FPT AIインフラのところではモデルアイザーサービス モデルサービス この辺りを中心にご紹介していきたいと思っていますその上のレイヤーはですね その後でまたご紹介するという形になりますねFET AIファクトリーサービスの現状ということになりますけれどもこちらはですね まずベトナムと日本の2リージョンでFET AIファクトリーサービスを提供しています日本の方はですね この3月 エメルタブですね そのデータセンターができまして一つのまだゾーンですけれども 東京の方でこのデータセンターにこのFTクラウドが立ち上がっている状態になっていますこの後 間もなくですね 皆さんにこの申し込みの方ですとか実際にどうやって使うのかというのがですね ご案内できるようになると思います実際 このベトナムの方では もう既にリージョン冗長になっていましてこのような形で冗長性のロードバランシングですとかあるいは自殺サリカバリーのような機能ですねついているということになりますねそして FPTのAIインフラですけれども それぞれ細かく説明していますMetal Cloud GPU Managed Cluster そしてGPUコンテナ それから構成のストレージですねその4つからなっています それぞれ見ていきたいと思いますまず FPT AI Metal Cloud ベアメタルのGPUサーバーですねこちらはこの2つの異なるスペックのものが用意されています細かくは後ほど見ていただきたいと思うんですけれどもこういったインフラをですね ベースに推奨追加と書いてありますけれどもワークロード管理ソフトウェアで さまざまなインフラと連携させてそして分散訓練クラスターを使って というような形で展開していくことになりますそれではですね FPT Cloud ベアメタルGPUサーバーの両方というところでご紹介したいと思いますそれではですね FPT Cloud のベアメタルGPUサーバーのご紹介したいと思います特徴としてはですね ベアメタルなので高速にできますということで最新のエネルギーでは100、1200を そのまま使うことができますということでまさにワークロードとデータの安全性となったところに 注意されていますシームレス、ハイバーマンス、単一ポータルということでですねご紹介していきますそしてこれによってコストとかエイデンシーの改善それからモデルと学習性能比、推論処理といったものが 高速化されているということになりますねメタルクラウドの方は左側のメニューの方から メタルクラウドを選んでいただいてこの中でですね メタルクラウドのGPUH100を選んでこの中でUbuntuでもいいんですけども カスタムイメージを選んでいただいておりますここでサブネットとかを設定してあれば それを選んでSSHキーを生成して そしてユーザーデータがあればね それをチェックしますけどもないのでこのままいって このままですねコンソールの方でデプロイ状況を確認していくとそしてその実行中にですね クラスターとか各サーバーのいわゆるログですとかメトリックスとか 確認できますのでそういったものを見ながら 実際にどういった状況になっているかというのを常にモニターにしながら 実行していくことができるようになっています非常にね 簡易なオフザビリティ的なところがありますのでその辺りができるようになっていますACLの設定などもできますので これによってですねサブネットなどを切ってですね セキュリティのACLを設定することができるということができますので この辺あたりはですねまさにパブリッククラウドに慣れた方であれば 同じように設定していただくことができますそして続いてKubernetesクラスターの方なんですが こちらも設定をですねまさに例えばGKEだったりとか AKSだったりとか EKSだったりとかそういったものを設定したことがある方であれば そのまま同じように設定することができるということで マネージョンGPUクラスターも簡単にですね 設定ができてそしてそれをすぐに使うことができるようになっていますはい ぜひこれですね 使ってみていただければと思っていますはい 今のですね FPTクラウドでKubernetesクラスターを初期化するデジについてもう少し詳しくご紹介したいと思いますはい まずですね このKubernetesの左の方からメニューKubernetesのメニューを選んでいただいて この管理画面から新しいKubernetesをクリックしてクラスター名を入れていきますバージョンとしては安定版を推奨していますそしてですね NodePoolの方を設定する最初はそのWorkerの方と それからWorker Group 1と2ですね1の方ではCPU 2の方でGPUを選択していきますGPUの方では これは後ほどまだ設定しますが1の方ではですね こちらは普通にSSEとか選んでですねこのまま入れていく形です Node 2Min Max入れてですねそしてその次Worker Group 2の方で これはGPUの方のノードなんですがWorker CPUと入れていただいてここでですね NVIDIA Tesla A13 これで構成のNVIDIA GPUを最適されたクラスターが構築されることになりますタイプの方を選んでいただいてそしてちょっと上の方のオプションで合ってないのがあったりするので そこをですねGPUシェアリングタイプとか選べるものにね ちゃんと変えていただいてそして ドライバーのところも無しとか色々選んでいただいてですねはい 設定をちゃんとFIXした上でMinノード Maxノード ディスクの80GBとかですねこの辺り入れて作っていただければ稼働するようになっていますこの辺りはですね パブリッククラウドで先ほどと同じですけどもIaaSを作った あるいは Kubernetesクラスターを作ったオプションで 手の方であれば 慣れた手順でですね全く同じように 少し細かいコンフィレーションなんかも含めてですね 作っていただけますのでぜひお試しいただければと思っておりますこれで実際にクリエイドされました ということでございますね続いて FPT AI Studioのご紹介ですねこれ 先ほどもご紹介したんですがAIのためのデータ処理だったり ノートブックだったりモデルの事前トレーニング ファインチューニングといったものモデルのハブですね カタログからモデルを選ぶことができるようになっていますこの辺りのですね この AI Studioのほうに統合されていますので ぜひこちらをですね使っていただいてVisualにモデルを展開したり プログラミングをしたりといったようなことを こちらでまとめて行うことができますのでご覧いただければと思いますまずはですね FPT AI Studioを使ってAIモデルを簡単にファインチューニングする方法ということでご紹介したいと思いますはい こちらはですねまず モデルファインチューニングといったものは何なのかということでユーザーが特定のニーズに応じて生成モデルを完全にカスタマイズできるマネージョンサービスとセルフサービスで AIモデルを簡単に調整できて柔軟性を持っていて 高性能であるといったところであとセキュリティも高度ですよ高速効率も高いですよ ということでご紹介しています実際にそのデモの方なんですけどもこのやはり左側の方からですねこの パイプライムマネジメントという画面がありましてこちらのところでベースモードとかアルゴリズムとかトレーナーボードとかハーバーパラメーターこの辺りを選ぶんですねファインチューニングの目的に応じたベースモデルをどんどん増えていきますけども 選んでいただいてまたはカスタマイズの方も使いますトレーニング用のデータ 評価用のデータなどもこの選んでいただいて 1GBぐらいですかねこのタイプしてますのでこの辺りでデータケースの検証をサポートしてデータ品質をここでちゃんと確定していますエラーなどもここでトラックができるようになっていますねトレーニング設定を選択してビルドインのトレーナーかどっかコンテナイメージに入っているそのドッグのトレーナーですねこちらの方が多いかもしれませんけどその設定を選んでそれをウェブコンテナできるとさらにテストデータをここで使用して複数のテストケースで最終モデルを様々な観点から検証することができるようになっていますこれで設定が完了しましたのでこれで実行してやるとパイプラインの作成完了と同時にその有効化することができるということになりますそしてこの過去のパイプラインもありますのでそれを実行確認して確認して変更ですね確認してその履歴とかあと異常を検出したりすることもできるようにこれは先ほどのエアメタルとかCPUクラウドと一緒ですねこのような形で設定することができるようになりますそれでは次のデモはですねAIノートブックのデモでメタルクラウドで代表モデルを使用したラグの実装こちらのデモをご紹介したいと思いますまずこちらメタルクラウドですね既にデプロイされていて今こういうインスタンス上でこのようなメタルクラウドのようなメトリクスとかログとかちゃんとこう状態とかって分かるようになっていますこのあたりはねデプロイしたら皆さんすぐに確認していただくようにしていただければと思いますで、ノートブックを開いていただくとまずこちらのラグなんですが普通にオーラーマンのインストールと起動というところが出ていますここで実際に実行していただくとこれがですねインストールの方が終わってですね100%になってそして次のところでバックグラウンドで起動というところでドキュメントの読み込みの方に行きますここがまあ重要なところで何のドキュメントなのかというところなんですが今回ですねDPCかR1の論文ですねこちらの英語の論文をですね読ませてこれをそのラグというところでこれをターゲットにですね色々質問をしてみようというような形でコンテキスト情報に入れていますドキュメントの読み込みということでインポートでベクターデータベースを準備しますこれは普通のお決まりのコードですこれによってジャンク化してベクター化してですねそしてそれを確認するといったところが書かれていますそしてLMのプルでこれも最終的に終わったらですねここでコンテキスト情報がいかのとおりですということでプロンプトテンプレートを入れますねこの長期のコンテキストで答えてくださいというようなことを入れています最終的にこのレスポンスのところで答えが返ってくるわけですけどもクエリのレスポンスのところでですねその内容が.クエリのパラメータとしてですねDPCクリーマートの生成合と何が違うの?技術的要素において差別化されており特にDPCの高い性能に寄与しているとなる要素について要素ごとに500文字程度で解説してくださいこういったところをしっかり入れてやるわけですねそうするとこの指示にしたのがあって今実際に実行してますけどこの辺のログとかメトリクスのところとかGPUの予算があまり変わってないですよねそれほど負荷がかかってないということだと思うんですけどこういったところを随時確認することができるようになってきます結果が出てきましたということでこの辺り最初にですねディスプレイでまずユーザーの質問は?ということでディープシークラフとかのSAIとどのような違いがありますか?みたいなのが書いてあってアンサーとして先ほど指示した通り500文字程度ですね大規模強化学習とは大規模パラメータ設計とはということでそれぞれディープシークラフについての特徴がここで述べられていますで、最後にまとめということでねこんな形で出てきていますはい、こんな形でラグの方も簡単に設定することができてこのAIスティジョンのノートブックの中で実行することができるようになっていますそして次はFPT AI推論インファレンスのところですねこれはモデルサービングとモデルアザサービスとお話をしたんですけどもまずはこのハブで放送されているモデルか外部にあるモデルかそういったものに関係なくですね全てのモデルを管理できるそのためのインターフェースこれがモデルサービングということでAIモデルをデプロイしてそのサービスとして提供することができるんですよということですねもう一つのモデルアザサービスの方はこれはお客様のデータを使ってAIモデルを事前にトレーニングして継続的に事前にトレーニングをすることができるそういうマネージドサービスですよとということでこれはもう色々なことができるようになっていてマルチGPU搭載マルチノード統合されたトレーニングパイプラインとか色々書いてありますがモデルをトレーニングするための複雑で反復的なそのコースをですね削除してくれるということで品質も向上しますよということをねちょっとこの辺りはですね2つのデモでご紹介したいと思って見てみたいと思いますまず最初のデモはですねAIモデルをデプロイしてサービスとして提供するモデルサービスの機能についてご紹介したいと思いますはい まずですねステップ1ではまずこちらモデルの設定ですねそしてこのイメージの組み込み型非組み型か非組み型にあたってのを選んでNVIDIA GPUに最適化されたイメージを選んでいきます高性能がNVIDIA GPUを最大限かつ効率的にですね使うためになりますイメージソースはパブリックレジストリーから選ぶかプライベートレジストリーのプライベートを選ぶか用途に合わせて選択できますそんな形になっていてあとはですねこの後プライベートモデルの方を選んだ場合にはこのようにですねモデルバージョンとかトークンとか色々入れていってこれもイメージレジストリーとタグもね入れていきますで、Nextの方を押していきますで、そこでですね今度はここのあたりで色々な指示を行わなきゃいけないんですけどもプリセレクテッドなのかカスタムなのかというところでカスタムの方がねやはり細かい指示が色々できるようになってますのでそのあたりカスタムを選んでいただいてこの後リソースとかも選んでいくとより細かな設定ができるようになっていくのかなとということになりますあとは設定ですのでこの辺は起動のパラメータですねこの辺はいろいろオプションがありますのでこれをつけていただいてその環境に合わせて皆様の方で設定をしていただくとそうすると出来上がりますで、モデルカタログの方をちょっと選択していただいてそして、サービングネーム名前をつけていますねカタログの方を選択して名前をつけてで、このような形で先ほどのオプションが出来ました今度はトラビックのセッティングなどを行っていきますこの辺はもうネットワークのところなので後でまた細かいところをご覧いただければと思いますけどもそしてデプロイメントニューデプロイメントということでこれを行うことが出来ますということですねで、ここで詳しい情報をレビューすることが出来るんですこの辺はもうパブリッククラウドっぽいところですよね非常にこの辺り似てるところだと思いますはいで、次モデルアーザサービスですねはい、モデルアーザサービスですねこちらはモデルアーザサービス、モデルを開発するようにありすことなくAPIのポイントとして事前確認の意味を簡単に統合できるプラットフォームですよとAPIを通じてアプリケーションの関連とここがアプリケーションとのハブになるわけですねそして重量課金モデルとかいろいろ重要に合わせると調子ケーキになるようになっていますそれではデモの方をご覧いただきたいと思うんですがまずはこちらリストからモデルを選べるようになっていますこれがハブですねこれがちょっとこれから皆さんご覧いただけることになると思うんですけどモデルのハブがいくつかあってこの中でですねいくつか出ている中でモデルを選んでいくということでこちらですねAIモデルの情報とか説明とかいろいろ書いてあります制限とか書いてありますどのようにしていきますかということでいろいろあるんですがこの中でGo to Market Planモデルとチャットみたいなね典型的な質問が出てきたりしていますこれでいろいろな答えが返ってくるようになっているということでここで検証するわけですよねARPシステムのブランド、ビジネスバランドを作ってくださいねみたいなことを聞いていますそうすると詳細な答えが返ってきていますねこれでいいやということで出来上がったらそのモデルのAPIをアプリケーションに統合するそのままアプリから使うということですねこのようにサンプルインプットとかサンプルアウトインプットと同時にこのAPIのイワイルエンスということでこのURLが出来上がりますのでここからAPIの公開を行ってアプリケーションから使うよということができるようになりますということでいかがでしたでしょうかFPT AIファクトリーはですねこの3月に新しく日本でもデータセンターが公開されますのでぜひですねこの公開楽しみにしていただければと思いますこのページでこの後の予定とかですね内容を知っていただくことができますのでぜひこちらご覧いただきたいと思っていますよろしくお願いしますさてここから先はですねFPT AIのプロダクトソリューションのケーススタディということでこのFPT AIファクトリー以外のですね様々なAIプロダクトやソリューションについてご紹介していきたいと思っていますアプリケーションが色々ありましてお客のオンボーディングのためのアプリだったりオミニチャネルの顧客体験だったりとそれからビジネス意識管理この辺はかなり需要が高いところですけどもあとはインテリジェント文書処理といったようなところですねそしてこれ後ほどまた事例として出てきます最適化された従業員能力開発トレーニングやキャリア開発のためのアプリそれから効率的な社内業務に対して新事会計IT関連などの従業員のリクエストを処理するためのAIエージェントといったようなものもあったりしますこの辺では少しご紹介したいと思っていますこちらはですねFPTのAIプロダクトソリューションのカテゴリーですFace AI、Vision AI、それからデジタルツインということで出ています先ほどもご紹介したようにCSAだけではなくて製造業でよく使われる例えばデジタルツインだったりとか需要が高いものがありますよねあとはレンダリングを行ってそれを他のところで利用するゲームだけじゃなくて製造業だったり科学や医学や様々なインダストリーで使われることもありますけどもそういったアプリケーションも用意しているとなりますFace AI活用フレームワークとしてはかなり細かいこのような地雷評価がありますのでぜひこちらを後ほどご覧いただければと思いますその中の一つとしてSSAIモデルですけども半導体向けSSAIのファインチュードモデルというところでセミコンという事例がすでにオープンになっていますこちらもぜひご覧いただきたいと思いますセミコンダクターイノベーションエンパーリングセミコンダクターイノベーションということで出ていますのでぜひこちらへご覧いただきたいと思います次にこれは別のイベントでもご紹介していますがビジネス向けSSAI基盤IBチャットというものでありましてこれは非常に多種類のファイル型のマルチデータ例えばPDFで作った書類ですとかWord あるいはPowerPointのバスライドですね様々なものも様々なデータソースに入っているこのようなドキュメントこれがデータソースと接続されていてここからカスタマーサービスとしてナレージベースでこのような欲しいよとこういったドキュメントを作ってくださいあるいはこういったドキュメントを探してくださいとあるいはこのPowerPointの英語版のやつを一気に日本語にしてくださいといったことが簡単にできるようになっていますそのような形で領域特化エージェントを作ることができるようになっていますそして3番目の特徴として厳重なセキュリティ管理と分析目的に応じたLLMの選択ということでここも特徴になっていまして例えばクラウドの方のLLMパブリッククラウドの例えばマイズのAzureのLLMを使って行うこともできますしローカルのLLMですねこれを使ってFITクラウドの上でオーバークスクもできるということで非常にコカスタマイズ性が高くて多言語対応になっているということになりますIBチャットの導入メリットとしては既存の課題としては人的エラー先ほどの例を挙げると例えばパワーポイント英語から日本語にする他の言語にするといったときに人的エラーとかうまくいかなかったりするところもあったりするわけなんですけどもこういったところを一気に一枚一枚ではなくて一気にその日本語に変えてくれるとかそういったようなところだったりとかあとはスケーラビリティの課題ですねこれはもう一つ一つやっていくのではなくてまさにIBチャットがそれを順番にCMをこなしてくれるそしてシーケンシャルにその結果を返してくれるといったようなところでこの辺りも非常に効率が上がるようになっていますこれによって時間自体の商品の削減ができますしコストの削減もこちらにあるように手動プロセスとAIチャットボットを利用した場合で10万ドル近いコストの削減ができましたとかエラー率の削減もですね手動プロセスの場合とAIチャットボットの場合では80%近くですねエラー率が削減できたとかそういったようなメリットがたくさん出てきています特にその金融業界、銀行業界におけるIPチャットの適用事例としては社内業務ということでアクロン、指導化、生産性交渉のアシスタントそれからオンボーティング、トレーニングだとかこちらにも役立ちますしまた対顧客ではカスタマーサービスアメリティクスエージェント、デジタルアドバイス後ほど細かく読んでいただければと思うんですが非常に多岐にわたる業務をこのエージェントとしてこなせるようになっていますまたコールセンターにおける生成AIの活用事例としてFAQとか、基本投約対応の指導化絶績サポートプロセスの指導化感情分析の対応の最適化対言語サポートそれから海外の障害担当者のサポートとこのようなこともできるようになっていますさて次にソフトウェア開発を皆さんGitHubコパイロット等ご存知かと思いますけどもこれと同じようにソフトウェア開発に使えるAIとしてXVista Suiteというのがありまして一番この中で中核になるのはコードVistaというものでコードを解釈して、生成して、リアクタリングしてそしてバグの修正とかコード自体を作っていくといったことができるようになっていますけどもそれ以外にBA Vista要件定義を生成したり設計書を作ったりあとテストVistaこれは単体テストの自動化だったりテスト使用書を生成したりテストのデータを生成したりといったものですそしてPMVistaはまさにPMOのツールでリスク予測やマネジメントそれからチームQAボットみたいなものもこれで作ることができるようなそんなスイートになっています今回はコードVistaを分析をご紹介しますコードVistaというのはGitHubコパイロットほぼ一人だと思っていただいて結構ですSSIを使ってコンテキストが豊富で効率的なID内のアシスタントということになりますコードに関して質問に答えてコードタスクを支援する自然言語で言葉できるということになりますねコードVistaの全体が用ロードマップです差別化としてはプロモートライバリー ドメン特化対応それからインターネット検索可能ということになるんですけどもこの辺りは最近それこそクラインとかカーソルとかWindowsターフといった強力ないわゆるIrcの開発ツールが出てきていますのでそれほど差別必要ないかもしれませんがこの辺りは標準で装備していますまたプログラミング言語に関してはPython、JavaScript、TypeScriptなどをはじめてですねJava、Cシャープ、それからSwift Goといったものにも対応していますまた小堀の対応が大きいところですねそしてIDEのサポートのところも非常に特殊すべきところでしてVisual Studio CodeがメインとはいえですねZプレーンズのさまざまなIDE例えばIntelligent IDEですとかさまざまなものに対応していますあとVisual StudioAndroid Studioの対応も大きいかなと思いますそしてCoreのところでAIモデルとしては基本的には今GPT4が4Oかなこれが固定になっているんですがそれ以外のモデルも使えるようになっていまして今後いろいろなものに対応する予定になっていますそれこそGeminiだったりとかManselic Cloudだったりとかさまざまなものに対応できるんですねそしてここも大きいんですが展開可能なのがクラウドだけではなくてオンプレミスでもできますよということでオンプレミスにこのようなですねまさにドメイン特化対応のこういったコード支援ツールAI駆動コード支援ツールを作ることもできるようになっていますまたセキュリティの対策のところはですねこれも今さまざまなAI駆動化ツールではほぼ対応しているんですけども一つ統計すべきなのはこのトラストレイヤーによる機密情報保護というところが特色かなと思いますそしてCodeVisさん構築の作業とアプローチなんですがこちらは皆さんご存知の通りですまずは解消してタスクをチェックして要件を見取って質疑応答してオンラインでそれを調査しているあるいはそのソースコードを向こうが書いてですねその書いたものに対してテストを実行してここを直しているというようなことでまた修正してもらってソースコードをコミットしてまたレビューしてという形でこのようなコーディング作用とアプローチになっていますこれはチャットGPTだったりGitHub Compilerとこういったものを使った場合とほぼ同じかなと思いますそれではデモのほうをご紹介しておきますマルチエージェントAIシステムによりコーディング作業を劇的に効率化し品質を向上させるための強力な機能ということでご紹介したいと思いますこちらはマルチエージェントAIシステムによりコーディング作業を劇的に効率化して品質を向上させるための強力な機能ですねまずは最初はですねコードの説明という要約ということで最新のプログラム現場でこれは幅広い言語に対応していますこれは次はですねクロスチェックということでこれはWeb検索による回答のフロスチェックです回答の妥当性をですねチェックする機能が搭載されるので情報の信頼性がと考えられていますそして次はコード保管ですねこれは文明を理解してコードのコード保管を提案してくれますこれでサイブミストを減らしたりコーディング速度を幅に向上させることが可能になっています特に繰り返し行うコーディング作業においては非常に有効ですよねそしてこれ少し前に戻りましてこれはですねコードの説明を行わせていますこれはCOBOLのコードですねこれ日本語でやってくださいねというのがですね今このIBMのソースコードですかねIBMのCOBOLソースサンプルというところから取ってきてそうするとコードミストの方が回答してくれますこのコードはCOBOLで書かれておりデータの変換と相当行うプログラムですというようなところがですね出てきてますよねこのようにですねCOBOLのようなどちらかというともう既に経験者が引退されたりあまり読める人がいなくなっているようなものでもですねこれを使って説明することができますので新しい言語に書き換えたりとかというところも参考にしたりあるいはこれを元にメンテナンスしますよみたいな業務があればそれにも対応することができるようになっていますそれからユニットテストの機能ですねこちらはこれをご覧いただければと思いますけどもユニットテストをここで実際メニューから選んでいただくだけですねこのような形でユニットテストを作ってくれますそしてリクエストリングの方もですねこれもコードを選んでいただいてリクエストアドロスすることができるということでこのあたりはGitHub Compilotなどに慣れた方はおなじみの機能かなと思いますこれによって60%のトロードアクティティというのが書いてありますけども非常に効率が良くなって全然生産された方のことは間違いありませんのでぜひ皆さんもですねこれ使っていただければと思います基本的には無償ですので皆さんこれ様々なIDからこのプラグインを入れていただければすぐに使えますのでぜひお試しくださいそしてもう一つの事ですがFPT AI Mentorですねこれ先ほどちょっとだけ出てきましたけどもこれは授業員教育用のマイクロランニングアプローチの学習コンテンツ生成アプリということになりまして質問回答を生成で生成することになりますこれを使っている事業員のパフォーマンスに応じて個別活動ができるまた振り返しのアセスメントなどを実施することができるまた学習内容のレコメントだったりそれを参考にですね今度は教材作る側がですね色々考えたりというのがですねこのドメインナレッジグラフということで可視化管理することができますので非常に効率的なトレーニングをすることができるようになっていますこのAIメンターの事例ですねベトナムの大手100局点でこれ実際にこのマンスマントレーニングを行って非常に大きな効果を得ましたということが書いてあるんですがそこは読んでいただくとしてこれ重要なのはですねこの技術チャレンジのところでFPT AIメンターはNGC LARMAおよびNGC PyTorchに関連するNVIDIA DGX-100ノード上に構築されたFPTの大規模言語モデルAORAを使用先ほども出てきましたねそしてNVIDIA-100を使うことによって時間が学習にかかる時間がだいぶ短縮されましたよとかあとラグを使いましたとかって書いてありますのでぜひこちらはですねNVIDIAの事例としてもですね注目していただきたいところでありますはいそして最後にユースケース伊藤忠祥司さんのマルチエージェントAIによる業務改革IBチャットCodeMisterというのもご紹介したいと思いますはいこちらですね伊藤忠祥司のITストラディシストの原田さんという方はですねこのFPソフトウェアのマルチエージェント生成AIソリューションとしてIBチャットこれをメインで使っていただいてあとCodeMisterも使っていただいて企業全体のビジネス開発チームとITチームの間の迅速な導入だったり新シームレスなコラボレーションといったものを可能にしたというそういうようなお話それで企業効率をどう変革したのかというような話について実はフルバージョンでは7分5分くらい語っていただいているんですが今回はその中でですね特にトランスフォーミングビジネスオペレーションイベーションイズマルチエージェントというところをご紹介したいと思います一部になりますね今回はオテンを効きますその配備 tutorus O未就からテーマイカロ BT Software AI Center team. To date, we are launching some of our very first AI agent with the idea of multi-agent design, such as multi-language translation agent, auto-input agent, data-analyzing agent. Our business unit can translate Japanese presentation file into English with the exact same format and immediately share to the client with a few clicks. As for innovation in the IT project process, our project members are already utilizing AI agent in their individual process. For example, after a developer complete their coding, they use the AI agent to review the code, which improve our productivity and quality. Our project of expanding AI agent is still ongoing, but we definitely see the actual value to utilize AI agent to streamline our business process to improve productivity across the entire our global group. . Hey ... And now absolutely ... The guides for other technologies. As far as we have enjoyed throwing Pierre P allezoy Cielenricho, Our product is nearly all laugh commodity. Their application has run off tú хоть into the video, So, you can explore the information in your app. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.