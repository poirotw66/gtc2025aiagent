 عَلُّهُي فَ believed... عَلَ mình somo chết new y걸 short videoск عن etern they didn't know Exapeau Are they good.ét Thank you. Hello and welcome everyone to this exciting NVIDIA GTC panel. My name is Carlo Ruiz and I will be your moderator today. We're here to discuss a topic that's more relevant than ever. So the title for today, in a world of one-year tech cycles, can traditional financial planning keep up? And I guess you already know why we thought we should address this topic. AI technologies such as NVIDIA GPUs, CPUs, networking move forward at a breakneck pace. We've seen enormous performance lead from one generation to the next. Just look at the jump from Hopper to Blackwell. Massive increases in compute power, but also never seen before efficiency improvements. And all of this is leading to matters such as better energy consumption, better economics per unit of AI performance. But the ability to leverage the latest AI technology makes a huge difference for those that can manage all of this and then stay ahead of the curve. But it's definitely not easy. And that's not how traditional technology refreshes worked in the past. Actually, historically, enterprises and academic institutions planned for five-year or even longer technology refresh cycles. And AI is today definitely changing all of that with leading organizations looking at much shorter upgrade cycles to keep up with all the advancements out there in the world. And that brings both opportunities but also some very big challenges. And so today we're here to discuss how outdated financial models are holding organizations back and also what new strategies can help them to stay competitive in AI-first world. So this topic is critically important, yet it has often been overlooked. For me, it's kind of like showing up in the same Formula One car for five seasons in a row and still expecting to keep up with the pack. So the lack of attention is stalling innovation. It's discouraging top talent to join organizations or it's simply being ignored until it becomes a major issue. As AI projects continue to scale in both complexity, I've heard all about the AI factories here at GTC, but also as they continue to scale in capital investment, the challenge this demands requires very urgent focus from all of us. So to help explore this challenge, we are joined by an incredible panel of experts today from different industries. And I'm going to introduce them one by one. So first, we have Bill Mayo, SVP Research IT from Bristol-Myers Squibb. And yeah, AI is reshaping all kinds of industries with definitely the pharmaceutical industry from clinical trials to patient diagnostic. So Bill, what's your perspective on how financial structures impact your industry? Yeah, thank you. I'm thrilled to be here today and happy to join this conversation. It's undeniable. Well, first, let's lay a little groundwork. Within the pharma industry and on the R&D end of the spectrum, you know, we've been kind of working the machine learning AI space for a decade or more now, whether it be visualizing molecules, optimizing molecules, even just working through how we do sales planning, etc. Across the scope, it's been deeply ingrained. The challenge is we've had this probably first and second derivative improvement in the pace of change that has completely broken financial models. And it's far and away the first thing that ever occurred to me was going to break with this. I was always excited about the tech, excited about the science. And lo and behold, it has completely broken financial models. And I think up and down the stack from what an individual company can afford and capitalize to how fast hyperscalers can provide. So excited to be part of this conversation this morning. Fascinating. I hear over a decade of experience with this challenge. So we're looking forward to hear more. Now, we're also joined by Richard Soentjes. He's the lead of the Supercomputers Center at the Technical University of Eindhoven in the Netherlands. And yeah, universities are a hub for AI research, but they often face financial constraints due to these long-term budgeting cycles. So Richard, can you share how academia is navigating all of these challenges? Yeah, thank you, Carlo. Great being here, by the way. So yeah, well, Eindhoven University of Technology is in one of the tech hubs of the world. It's in the Brainport area. We are surrounded by companies like ASML and NXP, where we have close ties to with research and education and knowledge streaming back and forward from those companies back into the university. So what's really important for the region is that we need to adapt to the growth and to the new tools that are around us. So we really need to compute to compete in this era. And this is also why we need to be able to quickly adapt to this world around us. And that also means that these financial systems has to support this fast-moving world, especially with AI. And so we will go further into the details of that, I think. But that's, I think, the introduction for this. Thanks. Okay. Sounds very interesting. Leading in the academic space, but also part of this larger initiative in the Netherlands at the heart of industrial innovation. Okay, good. And then we have from NVIDIA Financial Solutions, we have Ingmar Lanavi and Tim Shockley, both financial but also, I think, technology lifecycle services specialist. Quite clearly, as you have heard at GTC here at the conference, we're at the forefront of AI innovation. But even the most advanced technology needs financial alignment to be widely adopted. So, Jens, what trends are you seeing in how organizations structure their financial models to keep up with all of this? Thanks, Carlo. I'll kick it off. And great to be here and joining this esteemed crew on this panel, for sure. The biggest point that I would just highlight real quickly here from a trends perspective is really around how most companies are really addressing it right now. And what we do see right now is that many companies are not actually paying attention to this piece. And so, what Tim and I are trying to do on a regular basis with our customers is help them work through the thought process around how to be most effective in terms of how to think about the lifecycle management strategy that they should take advantage of as they make these large investments in this new space called AI. And high-performance compute, essentially. So, it's a journey. And various companies are better at it than others. And we are here to try to help and guide and support them as much as we can. Tim? Yeah. And what Ingemar and I have both done separately at different companies, we've built large finance captive organizations. But that's not what the market needs right now. The market needs information. So, we get a combination of great data from our historical, you know, NVIDIA timeline. But also, with our interaction moving from early-stage startup companies up into Fortune 10, there's a lot of moving parts and various ways to look at these investments in the financial planning. And what we can do with whatever customer and whoever you are, we can help you crystallize what that right lifecycle management plan should be as a start, which then can layer into creating the best financial plan for the business to stay current. Happy to be here. I look forward to a great chat. Thank you for the intro there. And I have the pleasure of working with both of you gentlemen. And I always see you as helping to enable growth, right? And moving all these obstacles away that are blocking innovation. So, with that, thank you all for being here. And to our audience, feel free to raise questions through the virtual room here. Let's jump into this. And let's talk a little bit about the challenge of traditional financial planning. So, traditional models, we all have seen them. They often operate on multi-year depreciation cycles, like the five-year cycle. It's very common in academia. Even today, I see quite often. But also, through the enterprise. So, in the panel's experience, what are the biggest roadblocks these traditional cycles create when trying to keep up with, well, you have all seen it, a one-year tech improvement in AI. Can we start with you, Richard? How does a thing like a five-year depreciation model limit your ability to acquire talent and get the right resources? Yeah, well, exactly. Like you say, we need state-of-the-art tools to do excellent science and research and to attract talent. And talent typically wants to work with great tools, of course. Well, if you look at the AI product cycle nowadays, also within NVIDIA, it's becoming more like one to two years instead of five years, the traditional cycle. So, that means if you buy new tools every five years, well, you're not competing anymore. After two years, you lose talent and you lose innovation. So, we need good tools and to standardize on these tools to improve research and education and also with the high-tech companies around us. Yeah, so, it truly limits us if we really need to stay into the old paradigm, into the old cycle. We need to shift to a faster moving cycle to keep up. And it seems very logical, but what you're just saying, right, this is very innovative in the academic world, right? You went for five to two years, right? That sounds very logical, but I don't see it often. So, quite remarkable. It's quite atypical in the world that I'm in, but I also come from ASML, where I think that the world is changing a little bit faster. And so, I come from industry. I work in academia. So, maybe that's the push they needed. I don't know. It's good to see that crossover. Maybe on that note, let's go to Bill, because also on your side. So, what's your view? So, how do these conventional financial structures, how do they influence the pace of research or commercial innovation? Yeah, and actually, Richard, it's good to go kind of right after your comment. My career has most recently gone the other way. I spent the last seven years in academic research space. And we grappled constantly with the problem that says, in a pure capital model, I was essentially incented to keep it as full as possible, frankly, dangerously full, dangerously close to full capacity, and then to run it for as long as possible. And we were ultimately able to break it there by changing a financial model. I remember working with a large hardware provider and trying to hammer out how we were going to fit terabyte months into the notion of a contract and what that looked like. Here at BMS, so fine, I have more financial flexibility in terms of kind of cash to put to a problem. But I have the exact same incentive problem. And the incentive problem, I look at it this way. At its core, I believe biology is computation. We've seen massive acceleration in how we're able to, the amount of work that we're able to do in the drug discovery space in silico. But we are still many orders of magnitude away from fully realizing that vision. The problem is, a little quick math might point to, you know, maybe we've seen 10 orders of magnitude improvement over the past several decades in compute. If we're still 10 orders of magnitude away from what we need to realize that vision of biology is compute, we're not decades away. We're a couple years away. Maybe five-ish years away, unless you're still using today's tech stack five years from now. So, like, it is so urgent that we break this. And listen, I haven't fully solved the problem. Our first swing at it here was a bold move to four-year depreciation cycle instead of five. But we are still pushing the envelope every day for how do we come up with a completely different way of solving this. I like that vision, right? The horizon of biology is computation. And we need to keep the tech stack and evolving as well, right? Yeah. Okay. Clear, clear. So, let's go a bit deeper here. The economics of AI upgrades. And so, we see these rapid innovation cycles. That means that also, you know, the innovation brings, the new technology brings significantly better performance. But also, it does so at lower cost per unit of AI power. But staying current is the main challenge, right? There's a reason why people have a challenge to adopt. So, from your perspective from the panel, how do organizations justify these continual, more frequent upgrades? And what finance strategies make this feasible? I think, Tim, you have an interesting learning here to share with us. Yeah, we've got some. Here's an example of some of the data that we can provide. And, again, the point is, just as Bill mentioned, it's to engage, to consider, try adjusting. Nobody's here to say exactly what will happen in the future. We just know that we can look at the past. And as an example, what this chart shows is there's been – and, again, I'll go through this very quickly for the purpose of this presentation here. Generally speaking, looking back, there was significant innovation coming every two years from NVIDIA. Now, that doesn't matter as much as the impact to your business case, whatever it is, academia, government, enterprise, et cetera. But when the chat GPT moment hit, all of this conversation went from the outskirts of the business towards the inside of the business. And that's highlighted by this data that says not only is the computational power and the cost for compute getting cheaper, but the power getting so much stronger from a performance perspective, which is not new in technology. It's just how much more performant and how cheaper. And, of course, you've got power consumption to consider. When somebody deep dives and considers this data and then has a conversation, and often including a cross-functional conversation, our customers can make optimal decisions. When you take a look at just deploying an H-200 or B-200 today and then look at this chart and recognize that NVIDIA is coming out with new innovations annually at this point, and that impact to your business, you have to consider where will that H-200 or B-200 sit on a chart like this in two years, in three years, in five years. And that's what is meant to simply help spurn the conversation to help provide the most information to help customers make decisions. And it's not an easy one, as both of you are here to say. You're both on a journey, Bill and Richard, as well as this audience. Wherever you are is where you are. We're trying to help you guys be as agile as you want to be or can be so you can push some decisions off into the future. And that's what we're seeing customers do, at least digest, have cross-functional conversations, and make the best plan that you can today, and hopefully make a good choice and try to perfect it later while, again, heading on to another life cycle when that time comes. It's very interesting, the picture that you show, because quite often innovation, new technology is associated with a lot of cost. But when I'm looking at your table, I'm seeing a tremendous performance leap generation after generation. I see much better energy efficiency, right? So it's a path also to do things more sustainable. But the one that you cannot ignore is the much better economics as well, right? So it's a win-win-win. It's still hard to do it with the lifestyle. I get that. There's a lot of wins in that table that you showed there. It's hard to ignore. All right. And so, yeah, what's the conversation then in the real world? So, Richard, with your finance team, AI performance doubles, budgets remain static. How does that work? Well, I'm not too afraid of getting money when we have success, by the way. So we don't have one financial system. We have multiple faculties or departments, how you would call them. So we try to get money of all these departments to build a system like this to get a bunch of money, for example. And then I actually decided or I advocated that we should have a fast renewal cycle. So we chose for a flexible two-year renewal cycle. And that means that we normally will have a renewal after two years to the next product. But it can also be flexible. So if we see, for example, okay, maybe we need to wait a little bit longer or we have to be a little bit faster. The system and the lifecycle management contract that we have now provides that flexibility. So it gives us control and better agility to look at the moving world at the moment and also to stay of the art. So being state of the art at the moment is nice, but we need to also stay of the art. So getting that renewal cycle in is very important. And I just sold it, to be honest. We need this. We don't do this. We just got to lag behind. Or after five years, we will have the same problem. We have to do a new procurement. Maybe we have to do a tender and all that problem. So I think in the end, it's easier to have a lease renewal contract or a lifecycle management contract, if we call it. Right. Yeah. Yeah, it's interesting. It's this concept of being more flexible, working with faster renewal. But if for whatever reason the project would demand it, you can also go slower. Right. We have not been focusing so far on that, but you also have the ability to adjust in that way if needed. Okay. Let's go to you, Bill. What are the real business impacts that you see if you would have to delay AI upgrades simply due to the older models or budget constraints? Yeah, sure. Our orienting kind of vision across the organization is around who are you serving? This notion of understanding a patient population, understanding an unmet need, understanding the opportunity that exists to change people's lives. So that's the business imperative, to move as fast as we can, to have the best possible insights we can, to minimize off-target effects, to minimize side effects, to have the best possible understanding of the underlying causal human biology for what's going on, to design the perfect molecule, and to do it as fast as possible for the lowest cost possible. Health care systems across the world struggle with the cost of modern medicine. And our opportunity is to leverage tools like this to shift that curve. The challenge, as we've said, is we live in a world where leveraging these capabilities, you know, to be honest, it's all OPEX is what it boils down to. We need the flexibility and the speed and the refresh rate that is kind of the promise of hyperscaler type delivery or cloud-based delivery for this stuff. But demand is so high. But demand is so high. Everybody is leaning so heavily on this that that model is also broken. It's just, you know, we can't, I can't afford to buy a new super pod every year and just use it for a year. I can't afford it at an OPEX rate. And frankly, neither can the hyperscalers afford to buy enough of it to put it available, make it available fast enough that we can all consume that way. So I do wonder a little bit if some of this financing problem isn't transitory. It's about a market that has leapt in capability by several orders of magnitude. Remember, we're not just talking chip performance. We're talking algorithmic performance. We're talking scale. We're talking just clever engineering like we've seen in DeepSeq recently. Like there's just, there's 100 variables that are moving incredibly fast here. And maybe we've just outjumped ourselves for a short time window here. I will say that is part of how I talked about it internally. I got, I got some funny looks when they said, hey, Bill, why are you buying an on-prem capability? And I said, well, it's not really on-prem. We're co-loving this. But the fact of the matter is I'm buying through a time window that maybe will have passed three years from now. And maybe the financing problem might have solved itself. But TBD on that. That's fascinating. There are so many moving parts also in what you described there. Just the industry in which you are, the healthcare, the potential savings, then all the benefits, which rightfully so go way beyond just the infrastructure itself. There are many more gains. And availability itself and the many consumption models that are available. So we can enjoy the moment we're in. Like all the world's interesting problems are at their heart, a big multi-parameter optimization. And that's kind of what we're doing right now. So we can also be a little thankful that we have such an interesting problem in front of us. It's absolutely fascinating. And it keeps us quite busy. Speaking of other challenges, there are more constraints, right, where we need to think about. So there's also physical data center capacity. There's capacity, of course, resources, but also the physical space. And it's also playing a role, of course, in how to evaluate, how to refresh AI technology. So Ingmar, any thoughts there? Yeah, it's a complex issue, obviously. And as the world keeps looking for more capacity, more space, more power. I mean, these systems obviously are very power-hungry systems and are getting more and more power-hungry. So it is an evolving solution or situation in the data center physical capacity and space as well. So for any customer that are going through this kind of internal discussions and conversations and strategy planning, you have to take a look at that as well, because it might be that your physical data center cannot keep up. You don't have enough rack space available to keep adding more capacity from a compute and networking and storage perspective. And, again, also layering in the fact that with the performance improvements we're seeing, you can actually leverage and take advantage of that as well as it relates to the physical capacity in the data center. And a very quick analysis that I put together for one of our customers, just to highlight the differential here is essentially seven DGXA100 80-gig servers produces a certain amount of compute power at about 35 petaflops. That can be replaced today by a single B200 server, and that will generate the same amount of compute power. So we're going from seven physical servers down to a single one. Now, think about that from a space and capacity from a data center rack perspective. That's massive. And if you layer that into your strategy and how you actually plan for these upgrades and changes to your overall strategy from a technology perspective, there is definitely some significant value that you can benefit from this. But only if you actually go ahead and do the more agile upgrade kind of tech refresh as you go through time. Because if you stick with the old mindset where, again, five years was the term, you are running a risk of running out of potential capacity to do what you need to do to stay competitive in your respective industries, essentially. Good insight. And I feel that we are slowly working to solutions here, right? That's, of course, what we want to share with the audience here. So let's go deeper here. So more adaptive financial models, the choice between Capex, leasing, cloud. And so, yeah, it's not just a technology decision. It's becoming also a financial one. So we see the shift going into more flexibility, going into subscription models, going to AI as a service, quite a bit of cloud there. So which strategies are proving to be most effective? Tim, do you want to share some thoughts here? Number one, there's no wrong answer. There's no right answer. If a cloud contract fits and it does great things for you and it gives you what you're looking for, great. Richard said some very key points before. But what we're typically seeing by end users that want the compute power, they're looking for agility. They're looking for some help as they can adjust as this market, their utilization of GPUs matures, right? And Bill mentioned that. That's the word that came to mind as Bill was speaking is we're at an immature time right now and we should enjoy it. It's exciting. Things will mature. A knowledge base will come. But what the right solution is, is really what the customer is needing to do now. And then how do you maintain performance over time? What's the best way to maintain your strategy? Long-term depreciation seems to be a challenge for most. Long-term cloud contracts can be a challenge. The wrong lease term can be a challenge, right? So it is a cross-functional decision based upon what you're trying to achieve today. And then with a consideration with as fast as things are moving, where do you want to be tomorrow? So sorry to be a little bit broad there, Carlo. There's no one answer. But the goal for all of us is to find the best decision we can today. And if possible, there are structures and means to push decision points off to where there is further information and then have that agility, have that control. And of course, if you can cost optimize, those are things that a customer can get with very innovative lease structures. Other customers, and Bill referenced his organization as well, shorten the depreciation term. Sometimes you do it right on the first time and sometimes you got to adjust. The bills may resonate with that, but other companies may shorten. We've got a significant amount of companies that are looking to refresh, depreciate after two years, depreciate after two years, or like Richard, lease after two years. Is that right for you? That's for you to decide. But hopefully we can be a part or you can find the right audience to help you make the optimum decision for you. Yeah. It needs to be an informed decision. And today, quite often, it's not that, right? So, okay, good. Bill, I also heard earlier when you were talking, I also heard availability, flexibility, maybe the friction with on-prem there. So what are your thoughts? Yeah. Yeah. So, you know, in a, so I have, I have to confess, I'm not a fan of kind of building on-prem structures, but I'd put it this way. In a world where things were pretty static, it's okay to pay an overhead of, let's optimistically say months, to be ready on-prem. In a world where things are changing every year or two, it starts to sound remarkably expensive to spend months kind of getting it set up. And, of course, the whole cloud premise for a decade now has been in a world where I might want to change my configuration with any given job. Then what I need to do is turn the setup task into 90 seconds of code execution, right? So that's the spectrum we're playing on here. I've already alluded to, you know, my view is the pace of growth here broke even the astounding capital investment capabilities of the hyperscalers. Like they're $200, $300 billion collected, more than that, I think, $350, something like that, $100 billion of 2025 in target capital expenditure, not just GPU space, but in kind of building out space. And it's breaking that. So we're having to navigate our way through kind of interim pieces in this. I'd love to see, you know, I don't know what else could happen here. A secondary market will open up. The people who want to buy, you know, partially, you know, gently used super pods. I don't know. You can imagine a market opening up for something like that. Tim and I have had conversations around, you know, how do I kind of break partway through this and segue over into a lease-like model? An early piece of tech that helped us through this was a good understanding of kind of base command and my ability to manage my capacity across both what I have, quote, on-prem and cloud-based. So even at that engineering level might let me have a bit of a mix of both and not have to get it perfect and maybe even change the mix over time. So flexibility was a great word for you to kind of pick up on there, Carlo, because I think that's what's needed in periods of incredibly rapid change. Yeah, and I think the other element that you added here, which we did not touch, is we use a metric for some of our projects called time to first training, right? So there's a cost associated to that as well. And what you can do in the cloud with a hyperscaler, with a regional cloud partner or with a DJX cloud where you can very fast switch on a service. That, of course, also translates into benefits. And at the same time, also on-prem to approaches with a bot-like rollout structure. And so, or as we have seen, for example, with X running out a 100K GPU environment in 19 days, right? So those innovations are also really important and help to reduce the cost of waiting, basically, yeah? Yeah. Okay. Richard, what are your thoughts on lifecycle and things like options to purchase, control, agility, the cost associated with it? So I kind of touched on it already, I think. So I think you need full agility, really, to compete. And that means you need a flexible contract. And I talked to NVIDIA before when he started talking about the lifecycle management contract. I quickly found out that, like I said before, you could easily stretch it or shrink it a little bit to your demands. And that's really what is needed. Otherwise, you, well, you said it multiple times now, I think. You get stuck, right? And there's also a problem of when you go to the five-year cycle and people have to wait for five years, they just run away. They go to my research, they will run into a hyperscaler and get a credit card somewhere. But we also lose control of their, you know, their code, their way of working. So there's a lot of things we need to control there. And we want to have the people on our platform. We want to keep them on our platform. So the product cycle kind of dictates this financial cycle as well. So the agility and the control, I think, is a very important part for having the financial cycles up and running in a way that's useful for this kind of platforms and tools. Agility, control, and practical challenges like people running around with credit cards. Love it. And this might be a good moment, Ingemar, to leverage your experience as well, right? You were used to where the treasurer had at the public company. So how did you address these challenges? Correct. Again, going back in my history here, I was the treasurer for NetApp and actually put a lease program in place for the company, both for the engineering and for the IT world. Two main reasons for that was one was cash flow. There are significant cash flow benefits, in my opinion, from a well-structured financing program using fair market value leases. But also the whole notion around keeping the business on the latest and greatest platform in a more proactive way. And what I see a lot is, again, many companies are not very good at that secondary kind of activity of how do I monetize any potential remaining residual value in the technology when I or my company has deemed it to be not very helpful for me anymore because there's new technology that is much better. And what I see is a lot of people struggling with that because, again, let's face it, it's not part of your core business. Nobody really cares if there is an extra 50,000 that can be generated from an old server or something like that. It doesn't normally or naturally translate into an activity that somebody performs on his own kind of thing. And there's certainly no KPIs or measures or metrics around, oh, did we maximize the return of selling old crap that we have in our storage room kind of thing. Doesn't happen. So with that, putting a different structure in place like a lease kind of a model that I did at NetApp, I was able to force decisions onto the businesses to do the right thing when the right thing was there from a timing perspective. So if it was a three-year lease for a particular type of technology, we, my team, helped them basically get their act together with planning in advance. So we didn't wait to the last minute, but it got planned in such a way that the right actions was taken and the replacement showed up. So you didn't miss a beat from a refresh kind of a cycle that otherwise you might because you're like, oh, well, we sold the stuff and we don't have anything to do for two weeks because we wait. We're waiting for the new stuff. Well, that's not a good plan, obviously. So taking a holistic view on that and manage it proactively, that's really how I was able to add a lot of value to NetApp from staying at the cutting edge on the technology and saving a fair amount of free cash flow by switching the model to a very different model than the paying all the cash up front kind of thing. Now I'm going to prompt here. Sorry, Carlo, but Ingemar, you've been in video for a few years now. How has the pace changed today compared to your days as a treasurer? Well, I mean, the technology here is obviously just night and day in terms of how quickly the technology changes. When I talk about my experience at NetApp, it was CPU-based servers, it was Cisco networking, and I actually was working with Tim and his team on the leasing side. But a very different technology than what we're faced with today with the AI and the NVIDIA chips, basically. All I can say is Ingemar is one of the guys you want as your finance executive peer. That guy gets it. He has lifted himself. Okay, we hear that clearly. Definitely. Let's go back a little bit for the world that we come from. So let's talk a bit more about lifecycle management and residual values. So these infrastructure refresh cycles, they used to be very predictable, but we already talked about it. An early refresh now can be a competitive advantage. It's moving so fast to keep up, to publish earlier. And so the question also becomes, how are we thinking about asset life cycles, the residual opportunity, secondary markets? I heard it already from Bill there. So, yeah, it might be very atypical, right, for the academic world to look at things like it. Richard, is that happening? Are you looking at technology resale, repurposing to manage your cost? Not really at the moment. That's very practical economic financial. But we do have a flex contract where we can, for example, buy at the end. And then maybe for lesser mission critical stuff, we could keep it and then put in a new cycle for the highly mission critical stuff and put it in a lifecycle. So flexibility is in a contract there. But for reselling at the moment, no. Yeah, I have seen with some academic institutions that if they have a leading cluster, then in the beginning it's used for the cutting edge, large jobs, large training. And later on, as the other system comes next to it with the latest technology, then the smaller, the early lifecycle projects are moving to that initial cluster. So that's something I have seen as repurposing. Yeah. Well, I can imagine that, for example, we're also doing an initiative with our local government to do something like this with companies. And then I would see something different happen, of course. Then you want to have to maximize the economic value of your systems. And then those things come into play. But in academia at the moment, we don't actually look at this that much. Yeah, might be an interesting topic to investigate a bit more. Yeah. The only thing I would say on the higher education kind of space is there are tendencies for some to actually go and look for the old generation technology. Because, again, it is cheaper, obviously. And that's a trend that I'm starting to see a little bit right now as well. So anyway, I think that's an interesting angle on this as well. So if I can jump into it, I loved your pointing at that, Richard. I think that's this notion of, sure, we're talking about how to stay at the cutting edge for what needs to be at the cutting edge. But there is a good bit of stuff that doesn't need to be at the cutting edge. And that might be the thing that opens the door here. I'm trying to design a model. And I don't know if I can think about it in the framing of a reverse use of base command or SETI, for those who might know this. It's like kind of making your extra compute cycles available. Like we could do net metering on our GPUs. And it'll freak out all the CISOs of the world. But if I've got spare capacity, somebody else can come run their stuff on my cluster for a little while and a little net metering in there. And I'll use it. I don't know. Because that actually gets to one, you know, joking aside, one market reaction to problems like this is often to kind of pool the resource in a way that you can drive up the utilization. And by all of us having this, I hope we're all running these things at full capacity all the time. But I can tell you that's not always true. And there is a lot of, you know, for a world that is demanding a ton more capacity, there is a lot of trapped capacity spread around in all of our individual instances. And who knows what opportunity, clever computer science opportunity exists to open some of that capacity up. Yeah, it's a fascinating topic. I think we'll see quite a bit of opportunity there. Yeah. Well, on the topic of the tech refresh process here, Ingemar, can you take us a little bit? Yeah. It's really just that everyone has a common understanding of it and also more the cost associated with it. Yeah. I mean, so, again, listen, the challenge here that we're all faced with is that this is still very new technology in the grand scheme of things. I mean, GPUs have not been around for 50, 60, 70 years like the CPUs. So the secondary market really has been kind of slow, in my opinion, in terms of picking up and starting to become more of a mature kind of a market. Haven't seen a lot of transactions. And we interact with a lot of the ITAD players on a regular basis just to keep abreast of what's happening in that secondary market space. And there's been a very limited amount of actual transactions where full-fledged GPU servers have changed hands in the secondary market kind of situation. So it's hard to really put a good handle on, like, what the pricing curves and everything else looks like there. Today, it seems like there's an imbalance. There's an imbalance between demand, which is pretty high, and supply. Many of the customers today, the install base that have been buying GPU technology over the last, whatever, six, seven, eight years, they tend to hang on to their GPUs. And a lot of them are doing, like, what you suggested, Bill, in terms of just the cascading thing. I mean, maybe there is a whole nother skunk project over there that can do perfectly fine with a V100 chip as opposed to a Blackwell chip, as an example. It's certainly doable because they're still powerful machine from a compute perspective. And just because there's a new chip coming out, that doesn't mean that the old one is, like, a boat anchor kind of thing. It's time to throw it out. There is still significant boundaries. And, like, what I said as well is true that we're now starting to see some universities in particular that expressing interest of buying an A100 system. Because, again, it's cheaper than the Blackwell, obviously. And they still get a very good kind of compute performance out of it. So it is an evolving kind of situation. Like I said, we're still early. I think it's going to easily take another two to five years before we start seeing a more leveling effect of that supply and demand curve in the secondary market to help us get a little more predictability on the values in the secondary market around the older technology. But, again, time will tell. So, again, I think we're all in a very exciting opportunity and market here. And it would be fun to see how it all plays out over the next years to come here. And, again, one of the overlooked challenges in the AI domain. Yeah. Thanks for sharing that, Mark. Totally. Tim, let's dive into your experience. What's the best practice that really stuck with you? So it was one of our ABCs and a different global pharma CIO, not with Bill's organization. We're having a conversation. And he said, I'm typically able to forecast what my business needs for 10 years. Super simply stating, one refresh after five years. Right. How can I do that when I can't see two years ahead? You've got the innovation coming. You've got the ability to deploy, manage, use all and work and transfer all the data. You've got the rapidly changing, developing, maturing use cases of AI. It's a lot of moving parts. So the best practice is really engaging cross-functionally, put your heads together. In that case, that CIO moved from a five-year depreciable model to a three-year lease. Interestingly enough, no interest in buying the assets after three years. Simply, I want to be motivated to move into the new. And so that's just one example. Again, as I stated already, there is shortening depreciation. When cloud is right, cloud can have a great contract. There's these innovative lease structures, whether it's a timing structure and plan like Richard's put together or something that's more of a combination. It's really about engaging and not sticking your head in the sand just because you're going to be able to get a purchase order out the door. The future is happening as fast as ever. So let's plan for it. I understand the work to get here, but tomorrow's coming. So the best practice is get the work done, get the purchase order out the door, get going. But, you know, let's engage and have a dialogue about your future that's coming. Yeah, that's a clear way to embrace uncertainty. Yeah, that's what I'm hearing you say as well, right? So, and you mentioned future. So that's a nice bridge to our final segment here, right? Where we look ahead to the future of financing AI. So, yeah, AI will continue to mature, maybe to disrupt might be a better word even. So, yeah, how do we envision here financial planning models to evolve in the next, let's say, five to ten years to keep up with these emerging technologies? Are you okay to put any predictions out there or any bold moves that you anticipate in your sectors? So, let's start with you, Richard. Think of maybe flexibility that you need in your organization or things you would like from the government funding. What are your thoughts here? So, first of all, I think if we hang on to the old paradigm, and of course, we are dependent on buying stuff by the financial systems, it will fail. And to think a little bit broader than only our own university. So, we are in the middle of a center of a whole ecosystem of industry, like a semi-com. It's actually like loads of companies that are in the front and in the back of ASML, for example. And we are supplying knowledge to that company and also talent to the company. What I would like, or actually our university would like, is that talent and knowledge will flow into those companies, but it will also flow back to us. We can only do that if we align tools. And by standardizing tools in time, we need financial systems to be consistent to support that, right? So, if we don't do this, we also lose like a lot of opportunities if we don't. So, I would like the financial systems to follow the disrupting systems that are needed to give us the opportunities to grow in our region and basically in all regions, I think. So, financial systems for five years, I think that's old and not of this era anymore. I think it should go. It should be flexible. It should all be flexible. And like, I think also Tim says, we approach a multi-tool approach. So, we have a lot of customers, different questions. Sometimes there's a different timing aspect to it. Sometimes it's two years. Sometimes it's five years. You can look ahead. So, I think you also should have like a multi-tool approach to finance maybe even. Okay. That's enough said, I think. Otherwise, I'm talking all the time. Well, that's okay. That's why you're here. And I also like that you keep coming back to collaboration, right? This is not something for your organization only, but this is something to work with the industry ecosystem, right? Yeah. It's talent and knowledge tools that should be aligned. So, you go from lab to fab and back in knowledge, for example. So, what we call University 4.0 means that we're a real collaboration in delivering tools, talent, knowledge. But it also flows back into the university. So, you get a very nice synergy there. That's what we would like. Financial systems should follow this. It's simple. Okay. Thank you, Richard. So, the future wishes and things that need to be delivered. Bill, what are your thoughts? Yeah. So, I'm confessing an inability to really think of a specific solution. But I have 100% confidence, as sure as I am that it's going to be darker tonight than it was this afternoon. The problem is going to solve itself. Like, I have full faith in the sheer number of people who are interested in this, the sheer number of use cases that are there, the potential kind of across societies for really transformational change for everything. That's including, you know, not just price point, but energy consumption and our ability to treat disease and our ability to figure out the major problems around climate or whatever else is in front of us. Everything is aligned that I have absolutely no question whatsoever. It's going to get solved. And I think Tim's got the great insight in the sense that there isn't a right answer. There's a right answer for the use case or the situation you're grappling with right now. And maybe it's a funding model. Maybe it's a cash constraint. But whatever. As long as we're open to try whatever, we're going to solve this problem. And then we're going to use this solution to solve all the other problems. So, I'm hugely optimistic in this space. I'm going to add, Carlo, is, of course, you know, Richard and Bill's example of what they're doing with their organizations. And then you add the number of people like them doing all this. Collectively, there's going to be smarter decisions. There's going to be right decisions. There's going to be mistakes to learn from, right? And that's what makes probably what Ingemar and I do so interesting and valuable, Candly, because we can collect a lot of that and hopefully share down to that specific problem or opportunity that maybe exists. And again, we don't have all the answers either. It's just a matter of together there's a lot of information when it's able to be shared. To Bill's point. To Bill's point, the stars are aligning on this one. So, it's not often that you see and the performance leap and the energy efficiency and the benefits to whatever we try to achieve and the breakthroughs that will happen. And then so solutions will be found. Yeah. Yeah. And I like that notion. So, and then to close up on the future, right? The financial innovations that could make the technology easier to consume or more accessible. Any last thoughts there from the NVIDIA financial solutions team? Well, I mean, I would just basically say that we obviously, we work on this on a daily basis and we try to come up with more creative ways of doing it. And we are on to something with one model right now that, again, helps to deliver what I would consider more optimal kind of flexibility to an end customer to give them more flexible models, which is, again, locking into a three-year kind of a lease cycle and then give them a choice and a chance to get out after two years and not have them pay all the fees that are involved in that in a normal kind of a lease cycle. And that's a kind of structure, but provide some flexibility there to make that a much more manageable kind of situation, recognizing that, again, the world is changing really quickly. So, again, maybe my three-year horizon seemed right when I started, but a year into it, I go, shit, I need to get out early. And how do I do that without losing my shirt kind of thing? So, those type of structures and concepts, I think, well, I hope that we will continue to be able to deliver. But I also agree with what Bill said earlier. Over the long haul here, things will start to normalize. The markets will normalize. The secondary market will normalize. And things will become more what we probably saw back in the days when the CPU thing came out. I fully expect that this will occur in the GPU kind of technology space as well. And then there will be another one that will come along probably and the whole thing will start over again. Maybe that's the quantum computers. I don't know. Who knows? But, again, this is all part of the excitement for the future, in my mind, at least. Can I respond to that very shortly, Yigemar? Yeah, I was really surprised and also happily surprised about the flexibility of the contracts that NVIDIA delivered. I was thinking, okay, it should be a fixed two-year cycle, three-year cycle. But I found actually almost all flexibility in there. And that kind of convinced me, indeed, not to get stuck into, you know, you don't know everything ahead, right? So, I was really surprised and happy that this is offered. That was the plan. So, I appreciate you sharing that, Richard. But that's really what we're trying to do as much as we can. So, I appreciate that. Yeah, and there's something that I'm hearing back in this conversation as well. It's not only the keeping up and making it possible to adopt the data, but flexibility has been coming back and back again over here. And, yeah, and Yigemar, you're touching the future, a new challenge that might come up or quantum. And here at GTC, right, we have a whole quantum track this year. So, please check out what is happening on that side as well. All right. I think it's time for closing thoughts here. So, if you're okay, if you think you put your point forward, then let me try to wrap up here. So, I think we got some great insights from the panelists today. How to break away from the traditional, more conservative financial cycles and embrace AI-driven growth. And a couple of takeaways stand out. The AI performance and also the efficiency leaps, those win-wins that we discussed, they make frequent refreshes necessary. Definitely at the cutting edge of what's happening. And organizations that fail to see that or adapt to that, they will fall behind. Then, so, I think as we have been innovating on the AI side of things, it's also up to finance to innovate as well. Financial flexibility is crucial. And there's no one answer. We also heard that leasing, cloud-based AI, having enough resources everywhere, alternative funding models, they can help us all to keep the pace. And then, yeah, the traditional asset lifecycle is changing. The industry is learning from it. We need some time for that to stabilize. But, yeah, we need to rethink things. I said depreciation, the residual values, the financing structure. So, practically, all of that came forward. And so, yeah, that leaves me for now. A big thank you to all our panelists for sharing your expertise, longstanding expertise. Because not everyone can say that they have been a decade innovating or have done this for multiple industries. So, thank you for sharing your experience and insights here at NVIDIA GTC. And to our audience, thanks for joining today. And there's also an invitation. Please feel free to reach out to all of us here on the panel. Because we're very keen to continue this conversation beyond today. And with that, many thanks. I'll see you soon. Thank you. Thanks all. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.