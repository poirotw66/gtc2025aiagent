本日はNVIDIA NIMOで実現する生成AIによる資産用レポーティングの変革というテーマでお話しさせていただきます私はSMBCグローバルインベストメント&コンサルティング株式会社のR&Dチームに所属しております今回のプレゼンテーションではNVIDIA社のNIMOとNIMOフレームワークを活用し資産用のレポーティング業務をどのように変革したかについてご紹介します企業業界 特に資産用分野における生成AI活用の具体的な事例とそこから得られる知見を共有させていただきますプレゼンテーションの前半は私 山田から発表させていただきます後半は同じくR&Dチームの白方から発表させていただきますそれでは早速次のスライドから内容に入らせていただきます本日はこのような流れでお話しさせていただきますまず当社の概要について簡単に説明した後今回取り組んだ資産用レポーティングのユースケースについてご説明します続いて技術名について選択した生成AIの基盤モデルとその選択理由そしてどのようなカスタマイズを選択したかについてお話しします実装セクションでは水路インスタンスの構築方法と開発したアプリケーションの概要をご紹介します最後に今後の展望と取り組み方針について共有させていただきますそれではまず会社概要からご説明しますまず弊社SNBCグローバルインベストメント&コンサルティング通称SGICについてご紹介します当社は資産用ソリューションを提供する資産運用投資上限会社として幅広いアステクラスを対象に中立的な立場でグローバルなファンドリサーチを行い最適なポートフォリオを構築していますまた先進的な運用モデルの調査研究を通じて革新的かつコンヒースなソリューションを提供していますご覧の図にあります通り当社は三井住友フィナンシャルグループの一員として三井住友DSアセットマネジメント三井住友銀行SNBC日光証券SNBC新宅銀行などと連携しながら事業を展開しています主要業務としては図の下部にある通りファンドの選定・評価ファンドモニタリングそしてアセットアロケーションを行っています当社ではこれらの業務に加え様々な先端技術の研究開発も進めており今回は生成AIを活用した取り組みについてご紹介します次にユースケースの資産用レポーティング業務についてご説明します今回のプロジェクトが対象とするレポーティング業務についてご説明します資産運用関連のレポートには左側に記載の通り目論見書、運用報告書、そして月次レポートなど複数の種類がありますが今回のプロジェクトでは青字に示している月次レポートに焦点を当てています具体的には外部運用会社から提供される情報をもとに月次レポートにおけるコメント案を作成する業務を効率化することを目指しています右側に示しているのが実際の月次レポートにおけるコメント部分のイメージです市場動向や運用状況、見通しと方針などの項目ごとに専門的なコメントが記載されていますこのコメント案作成にあたっては下部に記載している実施事項のうち特に社内記事に沿った表現の調整と複数の運用会社の報告様式の標準化において生成AIの活用が可能だと考えましたなおファクトチェックは業務として重要ではありますが今回の生成AIプロジェクトでは対象外としております次にレポーティング業務における課題とそれに対する私たちの取り組みについてご説明しますまず左側の課題ですが大きく3つあります1つ目は時間的課題ですレポート件数の増加に伴い作業量も増加しており特に特定期間にレポート修正業務が集中するという問題があります2つ目は品質面の課題です複数の担当者間で表現の統一を図ることが難しくレポートの一貫性を保つのに苦労を要しています3つ目は業務継続性の課題です社内の専門知識やノウハウを効率的に活用し個人に依存しない形で独人的な知識や経験を共有する必要がありますこれらの課題に対する取り組みとして右側に示す通りAIアシスタントの開発導入を進めてきました具体的にはレポーティング業務に特化したタスク特化型LNMを開発し専門知識を持つAIアシスタントとして業務をサポートする仕組みを構築しましたこの取り組みにより予想される効果としてはAIアシスタントによるコメント案の下書き作成が可能となり作業効率の向上が見込まれますまた表現や文体の標準化が進み複数担当者間での一貫性確保にも寄与すると考えられますさらにナレッジ活用と共有が促進され担当者全体の業務進出向上にもつながることが期待されます次に基盤モデルの選定についてご説明します基盤モデルとしてオープンソース型LNMを選定した理由についてご説明しますまず左側のメリットですが最も重要なポイントは金融庁が規定するモデルリスク管理原則いわゆるMRM原則への対応ですオープンソース型LNMを採用することで原則3に関連してモデルの内部構造の確認が可能となり詳細なモデル記述書の作成が容易となりますまた原則5、6に関連して独自の検証プロセスが実装できモデルタリングの方法のカスタマイズも可能ですさらに原則7に関わる統制の柔軟な実装として管理プロセスの組み込みを実現できますその他のメリットとしてはカスタマイズの柔軟性が高いことが挙げられます例えばエンタープライズ用途でよく検討されるAzure OpenAIと比較すると現状Azure OpenAIではローラによるカスタマイズのみの対応となっており変更可能な学習パラメーターも制限されています一方オープンソースLNMでは様々なパラメーター調整や主要の選択が可能となっておりますまたセルフホスト環境でのデータ管理が可能な点も重要ですオープンソースLNMはクラウド環境にもデプロイ可能ですがオンプレミス環境にデプロイした場合機密性の高いデータ処理においてセキュリティやコンプライアンス上の利点があります一方右側のデメリットとしては開発運用コストの増加があります具体的にはモデルのカスタマイズやデプロイ運用さらに周辺ツールの開発など様々なコストが発生しますこれらを総合的に検討した結果下部に記載の通りモデルのリスク カスタマイズ性セキュリティの観点からオープンソース型エレディも選択しましたデメリットに関しては公実のエニメディアにも任務の活用による軽減を図っています次に今回のタスクの詳細と評価手順についてご説明します左側の図は今回のタスクを示しています具体的には外部運用会社から提供されるコメントの原案をLLMを活用して自動的に訂正し当社の基準に合ったコメント案を作成するという流れです評価にはLLMが出力したコメント案と当社に蓄積された実際のコメントを比較します右側の評価手順ですが3ステップで行っていますまず評価基準としてLLMの出力と実際のコメントの類似度を設定しています次にその類似度を数値化するための評価手順として機械翻訳の分野でよく利用されるBLEUスコアを採用しましたBLEUスコアは0から1の数値で示され数値が高いほど高性能であることを意味しますここでPNはNグラムのプレシジョンつまり生成されたコメント案中のNグラムが実際のコメントにどれだけ含まれているのかを表す指標ですさらにBPは短すぎる出力にペナルティを与えるケースとなっていますそして3つ目のステップとしてスライド10以降で実際にいくつかのモデルについてBLEUスコアを計測し複数のローカルLMを評価した上で最も良い性能を示したモデルを選択していますこのような評価手順により私たちの業務で最適な基盤モデルを選択しています次に基盤モデルの選定についてご説明します今回は80ビリオンパラメーター以下のオープンソース型LLMを検討対象としました候補モデルの選定にあたっては日本語リーダーボードを参考に複数のモデルを選定しています表にある通り主に4つのモデルを候補として選びましたメタ社のLAMA3.170ビリオンインストラクト東京科学大のLAMA3.1スワロー70ビリオンインストラクトアリババクラウドのQM2.572ビリオンインストラクトそしてNexus FlowのAthene V2チャットですこれらはいずれも70ビリオンから73ビリオンのパラメーターを持つ大規模現行モデルで日本語の性能が高いとされているモデルです次のスライドではこれらのモデルの評価結果についてご説明しますここではファインチューニング特にローラーを適用した際の各モデルの評価結果をご紹介しますグラフは先ほど説明したBLEUスコアを用いた評価結果を示しています縦軸がBLEUスコア 横軸が各モデルです比較のためにオープンソース型LMだけではなく右側にGPT4O MINIも含めています結果を見るとオープンソース型LMの中では東京科学大の開発したソラオ70ビリオンインストラクトが86.6%と最も高いスコアを示しましたこれらの数値評価に加えてディジタイルの出力結果の品質を目視による確認も行い出力結果に問題がないことを確認しました以上の結果からオープンソース型LMの中では最も高い性能を示したソラオ70ビリオンインストラクトモデルを採用することを決定しました選択肢とスワラオモデルについてもう少し詳しくご紹介しますLAMA 3.1スワラオはLAMA 3.1の持つ英語の高い能力を維持しながら日本語の能力を強化した大規模言語モデルですベースモデルとして米メタ社のLAMA 3.1を利用しています開発は東京科学大情報立候学院岡崎研究室と横田研究室さらに3層研が共同で開発を行っています次にカスタマイズ指標の選択についてご説明しますCOの図はエニメディアにもが提供するLLMカスタマイズ指標の体系を示しています横軸は精度 縦軸はデータ計算リソースを表しています当社ではファインチューニングに必要なGPUメモリを加工しており過去4年分の整理されたコメントデータが800件相談していますそのため私たちのユースケースはこの図の中で位置づけるとリソースの観点では上側に位置しますまた精度の観点では右側に位置します専門用語の正確な使用が必要でありハルシネーション防止も重要な課題となるためですこの位置づけを踏まえ初期検証ではパラメータエフィシェントファインチューニングの主張としてローランクアダプション 以下ローラを採用しましたさらに精度向上のため次のステップでは完全なファインチューニング主張としてスーパーバイズファインチューニング 以下SFTを採用していますこのように段階的にカスタマイズ指標を適用することでリソース効率と精度のバランスを取りながら最適なモデルを開発しています続きましてR&Dチーム 白方よりカスタマイズ環境の選択についてご説明いたしますカスタマイズ環境にはNMediaに基 ハギングフェイスが挙げられます各フレームワークの特徴を主な特徴 主要ユースケース ライセンス提供形態の3つの観点でまとめていますNMediaにもはエンタープライズ向けに最適化されておりNMediaハードウェアと密接な関係性がある点が特徴的です一方でハギングフェイスにおきましてはオープンなエコシステムで豊富なモデルを有しており研究開発やプロトタイピングに適している印象があります両フレームワークにはそれぞれの良さがあるため目的に応じて使い分けることが重要ですここでNMediaにもについてはなじみのない方も多いと思いますので簡単に紹介させていただきますにもはカスタム生成AIモデルをどこでも開発できるエンドツーエンドのプラットフォームですこちらの図はNMediaの公式サイトのものを利用させていただいたものになりますがにもフレームワークでは様々な機能が用意されていますその中でもモデルのトレーニングに関してはにもカスタマイザーにより実現可能ですにもカスタマイザーはドメイン固有のユースケースに合わせてLLMのファインチューニングを簡素化する高性能でスケーラブなサービスとなっておりますこれらのサービスを利用することで生成AIの導入が簡易になります各フレームワークを比較する際の主要なポイントを表でまとめてみました先ほどもお話ししましたがにもはNMediaのGPUに最適化していることから学習や推論が高速である点が特徴的です当社では月次コメント生成タスクにおいて学習速度や推論速度を荷元ハギングフェイスで比較検証を実施しました以降のスライドではその検証内容やその結果についてご紹介いたしますまず初めに学習速度に関する検証を実施しました検証ではPEFT、ロラとフルファインチューニングのSFTを試しましたなおファインチューニングには当社独自のレポーティング業務データセットを利用しておりますベースモデリーにはスワローの8BD4モデルを利用しました実行環境はNVIDIA DGX H100を1台利用しコンテナイメージはNIMO24.12を利用しましたまたフレームワーク間での検証条件を合わせるためにトレーニングに関係のあるパラメータを統一しました主なパラメータは表に載せておりますそれでは検証結果についてですSASはロラの結果ウズはSFTの結果です各プラットフォーム間での学習速度の違いを検証するために1ステップあたりの学習時間を比較しました結果としてはロラでは約44%SFTでは約35%程度の学習速度が改善する様子が見られましたこのような結果からNVIDIA NIMOの学習効率の方が高いことが推察されます続いて先ほどの結果に関する考察ですこちらのグラフはGPUやメモリの使用状況に関する推移を表していますオレンジ色がハギングフェイス緑色がNIMOを表していますGPUユーティライゼーションを見るとNIMOはハギングフェイスよりも高いGPU使用率を示しておりGPU性能をより引き出している様子が見られましたまたメモリについて見るとNIMOは常に高いメモリ使用率を維持しており利用可能なGPUメモリを最大限活用している様子が見られましたこれまでの内容を踏まえ当社ではNVIDIA NIMOを採用しております当社における大規模言語モデルの開発や運用では本番運用における可用性や信頼性厳重なセキュリティ要件 開発効率性を重視しておりますNVIDIA NIMOはパフォーマンスの優位性エンタープライズグレードの信頼性統合されたワークフローであるという点から当社が求める水準を十分に満たしていることから採用に至りました続いて開発したタスク特化型LLMの水準の実装や当社のアプリケーションとして社内にリリースする際の運用イメージについて説明しますまずはじめに水準エンジンの実装です当社では水準エンジンの実装にはNVIDIAインターフェースマイクロサービスNIMOを利用しましたこちらの図やグラフはNVIDIAの公式ページから引用したものになりますNIMOはNVIDIA社のコンテナ化された水準マイクロサービスです当サービスはコンテナイメージが提供されているためコンテナを起動するだけで即座にデプロイすることが可能であり開発運用の負担を大幅に削減できますまたスライド下部のグラフに示されているようにNIMOを用いることでスループと向上が期待できます今回水準エンジンを実装するにあたり従来の水準環境とNIMOを用いた環境の比較を実施しました従来の環境では水準エンジンにVLMを使用しましたまたNIMOではTensor RT-LLMを使用しておりますモデルは先ほどのファインチューニング済みモデルのスワロー8ビリオモデルを利用し当社のレポーティング業務のコメント生成タスクにより性能を比較しました性能比較は1秒あたりの生鮮トーク数としております結果として従来では1秒あたりの生鮮トーク数が16.9トークンであったのに対してNIMOでは23.3トークンでしたNIMOを使用することで約1.4倍のスループット向上が確認されましたこの結果からNIMOを活用することで水論性能の大幅な向上が期待できることが分かりました今回の検証結果を踏まえ当社の水論エンジンにはNIMOを利用しております最後に社内アプリの運用イメージについてご紹介いたしますなおこちらは構想段階であり現在開発中の内容となっております開発言語にはPythonを利用しフロントエンドはStreamlitバックエンドにはLangChainを利用しておりますデータ基盤にはSnowflakeを利用しておりますユーザーはコメントゲイヤーをStreamlitで開発された画面に入力します入力されたコメントはLangChainを通して水論インスタンスのNIMOに渡されファインチューニング済みのLLMによりコメントゲイヤーを修正しますユーザーはLLMの出力コメントを確認し必要に応じてコメントを修正しコメントを完成させます完成したコメントはSnowflakeに保存しておくことでモデルの改良や評価を行えるようなアーキテクチャとなっておりますこちらのスライドではユーザーが利用する画面についてご紹介しますまずはじめにユーザーは画面左の青枠にコメントゲイヤーを入力しAsk LLMボタンを謳歌することでLLMにリクエストを送りますLLMはコメントゲイヤーを受け取りコメントを修正しますLLMによる推論後画面中央の青枠に修正されたコメント画面右にコメントゲイヤーとLLMの出力の差分が表示されますユーザーは差分を確認しながら画面中央のコメントを必要に応じて修正しSave Changesボタンを謳歌することで完成形を保存しますこのような画面とした背景にはLLMの出力には誤りが含まれることがあります修正前後の差分画面を用意することで変更箇所を明確にしユーザー自身が必要に応じてコメントを修正できるようなアプリケーションにしましたこのアプリケーションを利用することでコメント作成業務の効率化やコメントの進出担保につながると考えております最後に今後の展望についてお話しします今後についてはこちらに記載の2点を進めていく予定ですまずはじめに適応範囲の拡大です今回はレポーティング業務についてご紹介しましたが他の業務へのLLMの展開を進めていく予定です他業務への展開としてここでは例を2つ挙げています1つ目はニューステキスト分析への展開です当社ではニュースセンチメントに基づく運用モデルを開発しておりますがその市場センチメントスコアの作成にLLMを活用していきたいと考えておりますLLMを活用することで従来の自然言語処理モデルでは捉えることができなかった表現をスコアに反映することができ運用モデルの高度化につながると考えております2つ目は金融専門文書の分析におけるLLMの適用を考えております当社では有価証券届出書を使用した答申分類を一人で行っておりますがLLMを活用することで業務改善を図りたいと考えております次にモデルの高度化も進めていく予定です今回の例ではオープンソース型のLLMを利用しましたが当社独自のドメイン特化型LLMの開発をしていく予定です当社では金融関連データや当社独自のデータを多く保有しておりますので今後は資産運用業務全般をカバーするようなLLMを開発していきたいと考えております以上になりますぜひ注ぐ目をitéせたい לא�'達をご audiobook centsご視聴ありがとうございました Investigative音ério closing最後の問題はご視聴ありがとうございましたありがとうございましたご視聴ありがとうございましたおいしろお聞き方aríaお聞き方ảngはない場合これか