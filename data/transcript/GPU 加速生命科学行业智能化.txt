大家好,我来自于百图生科今天我和大家交流的题目是GPU如何助力生命科学行业的智能化当前生命科学行业面临着巨大的挑战传统的实验很难在巨大的未知的探索工业里面进行有效的前沿发现有非常多的场景前沿发现都价值巨大像精准药物设计精准Modality设计单个项目都超过价值10亿美金但是它们的设计往往远离自然的产物也远离已知的生物空间像下面这张棋盘图中其中绿色的这个方块代表着当前动物实验的模型能够验证的空间而外圈的黄色是当前高通量实验筛选模型可以验证的范围在外层是使用了动物实验和高通量筛选实验的数据训练的AI模型能够操作的范围但其中这些蓝色的点才是真正价值10亿美金的点而它们分布在广泛的位置的套路空间里边如果不能突破已知的套路范围在位置的空间里面进行高效的发现设计那我们很难在产业中获得巨大的商业价值因此充分发挥AI模型的作用就变得异常的关键生命科学行业的数据非常有特点它的有标注的数据非常少因为生物实验的周期非常长并且非常昂贵所以只在这些少部分的数据里面进行下游任务的训练很难取得较为满意的这个模型但同时它又有着海量的弱关联的高噪音的多模态和多组学的数据如果我们能够充分挖掘这部分数据在这部分数据上进行大模型的预训练同时可以利用生物的语言来进行建模比如说我们以核氨酸胺基酸作为token以蛋白质序列作为句子来进行大模型的运训练这样的模型它可以学习生物的机理深挖一些当前科学家并没有获得的一些洞察能够学得物种之间的进化信息如果这样的模型拆除规模达到了千亿它的数据达到了万亿相信它具备了非常好的一个泛化能力这时我们再用少部分的下游任务数据来基于它做微调就可以在非常多的业务场景里面取得SOTA的效果并且在多过场景里面也得到了实际的认证因此我们建立了生命科学的基础大模型家族一个是Trimo它整体的参数规模达到了2100亿阐数并且横跨了七个生物模态是一个更好的跨模态跨组学的生物表征其中一个Trimo DNA模型是基于基因组进行建模并且因为基因组序列很长所以这个模型的支持的序列长度也达到了128K可以更好的建模生命一个Trimo RNA模型是全面建模了RNA的转路的功能和结构支持了非编码区的高难度的问题并且在多个下游任务中都取得了Sota的效果Trimo protein是我们的蛋白质的预系列模型它的插入规模达到了1000亿是最大的蛋白质预系列模型它可以用于单体的蛋白结构预测属性预测和功能的全面解析并且可以用它来进行生成式的蛋白质设计以动物标的属性优化在蛋白设计场景里面发挥了巨大的作用Utrimo Cell是世界上首个登上NatureMacer的单细胞大模型开创了细胞把点和基因调控元件建模的一个先河Utrimo Chem是小分子的预学链模型是可以用来建模蛋白与小分子之间的相互关系对于小分子的药物设计虚拟筛选都提供了强大的技术支持Utrimo PPI是蛋白之间的互作关系建模可以解决像亲和力预测这样的关键的属性预测难题为药物设计提供了主要的技术支撑Utrimo System是更高层的建立细胞间的调控关系可以用来分析免疫调控多巴组合和工艺激励等问题说明科学大模型有着自己完善的技术体系绝对不仅仅只是一个制限元大模型的垂垂场景有很多核心技术都是有些差异的我们可以分不同的层来去一次分析二者上的一个差异从底往上看的话再撕了一段二者可以认为是一样的都是需要高性能的GPU的异构集群然后并且使用的规模也接近在千亿参数的模型规模下都需要接近千卡级的GPU集群才能完成训练并且也需要高性能的AI工程的优化能力才能让训练效率获得提升训练成本获得降低但是在标注和验证段其实就已经体现出了明显的差异生物的模型需要高通量的实实验的验证才能获得最终的LABEL数据而不是像自然语言通过标注和2C的反馈就能够得到在模型架构上生命科学的模型除了在基于标准的串子方法基础之上还加入了很多的额外的生物机理的模型结构比如DNA场景里边的正义链和反义链的建模和基因主场景下的大小弯的一些不同结构的策略这些都充分体现了生命科学模型架构上的一些差异点并且在数据上生命科学大模型也不是使用自然语言来语教进行训练的而是使用多组学的数据包括基因组、转入组、蛋白组等这些纯的生物机理的数据来进行完整的大模型的预训练并且在应用场景上自然语言大模型的锤类可能更多的解的是医疗问诊这些文本相关的问题而生命科学大模型更多的是解决生物场景中的实际的生产的问题比如说用来助力把点发现用来助力药物设计真正在实际的行业的商业化里面充分发挥着重要的作用我们的蛋白质大模型是一个100B MOE架构的大模型需要用到非常多的GPU资源因此对它的性能优化就是我们的一个重大的课题在MOE训练的过程中我们进行了EP的专家并行同时也采用了Smart MOE的优化策略充分的优化多个专家之间的通讯效率以及通讯和计算之间的overlap整体性能优化了1.5倍并且基于Hubboard GPU的FP8的精度训练我们在3B和100B的规模的模型上都做了尝试同时也在预训练和微调中也做了充分的测试都得到了几乎接近一致的一个结论用FP8的训练可以在训练速度上提升了1.25倍左右并且在效果上实测是几乎无损然后再进一步我们其实也做了智能的一个激活重计算充分利用充分的分析了各个Stage之间的显存在用其实发现各个Stage之间的显存在用并不均衡因此我们也是优先重计算了Stage0和Stage1的部分layer采用了最具性价比的方式来进行显存的节省同时训练的性能也因此获得了1.2倍的训练效率的提升在当个任务就需要1000卡的集群规模下有效的训练时间就变得尤为重要了因此我们除了采用异步的TagPoient的技术之外还会去主动汇报训练节点的Matrix通过对于训练节点的异常那些监控可以自动的提出异常节点在少量的BufferG的情况下可以保证有效的训练效率达到了99%一个吹没DNA大模型是基于基因组织性键膜的这也非常具有挑战最大的挑战是来自于基因组的序列长度是非常长的从左上面这张图可以看出来圆核生物的基因组序列长度可以达到10的11次方我以下面的大长杆菌为例如果是5到10个基因它的占的碱基差不多是8000个而大长杆菌有4300个基因因此它有464万个碱基长度的基因组序列为了解决这样一个长序列的问题我们采用了比较经典的参测变形加Context变形的技术最大化的解决了序列长度的一个问题然后同时我们也采用了不同的HID采用了不同的Ethertension的窗口的方式从128一直到8K一直到128K的长度进一步降低了长序列带来的性能的一个瓶颈但是在效果同时在效果上因为基因组是有两条链的一条正一链和一条反一链我们在模型结构中同时支持它同时输入两条链并且在encoder层我们进行了模型参数的共享这样可以降低模型参数的显存在用同时也降低了长序列带来的一个瓶颈问题最后我们也是考虑了基因组序列里面的大小弯的生物机理的一些结构然后对它进行了多尺度的一个建模整体让这个DNA模型其实不管是在序列长度上还是训练效率上都有了不错的一个突破的同时呢在训练效果上也是取得了全面的一个领先RNA大模型是一个encoder和decoder的架构它的encoder部分呢是一个混合灯gram的一个tokenizer接上Bort encoder的一个结构然后decoder部分呢实际上是一个RNA的diffuse model来去发RNA的设计然后并且整体的这个模型的效果呢也经过了实实验的一个验证在tokenizer阶段呢除了进行单个核杆酸烈度的tokenizer之外呢又考虑到了RNA特别的一些生物机理比如说编码区的部分我们采用了Kernel等约3的CNN部分也为了进一步增加tokenizer的这个效果我们也同时混合了Kernel等于5的CNN的一个技术然后在它encoder部分呢我们其实是进行了MLM的一个预训练使用了对于RNA的二极结构预测RNA的功能预测等以及它自己的序列自恢复这样的相关的一系列任务充分的训练了RNA的encoder部分然后是decoder部分呢结加上Diffuse的那个model实现了这样一个完整的模型架构然后在最终的下游任务的效果上呢可以看到我们在Beacon的benchmark上针对于Nancoding的RNA的这个平摄机上有13个搜查任务我们在其中有8个都是最好的然后同时在右下角的这个生成序列的这个设计任务里边在不同的指标维度上我们的模型其实都是更接近于自然的RNA设例都是更接近于自然的RNA设例也产生的一个效果是一个非常不错的一个设计能力为了支持好前面那么多种模态的模型训练我们开发了Ominibio是一个基于Mectron的一个生命科学领域里边第一个的跨模态的一个训练框架它支持了DNA、RNA、蛋白质、单细胞、小分子还有生物视觉和生物文本等不同的模态并且在Tokenizer阶段也支持序列的Tokenizer结构的Tokenizer以及功能的Tokenizer它是基于Microxen框架之上并且补充完善了不同的训练的优化的能力既有EBOOT的TokenPont也有FAS MOE还有智能的激活重计算并且我们对于生物的数据进行了IOO的优化从而获得了更好的一个样本读取的性能但是之上它还是一个预训练和微调一体化的一个框架除了支持Transformer架构之外还支持不同的像Mamba和Haiyana这样的一个非Transformer的大模型的训练模型结构然后在微调阶段也继承了Laura和Lisa相关的这样的微调的一些技术我们平时并且内置了非常多的生命科学领域的下游的评测任务同时也有一定的生物的一些数据增强的一些能力然后整体上在我们的多个模态的训练中都发挥了一个重要的作用不管是在训练的效率上还是在模型开发的效率上都有一个不错的一个提升讲完了模型训练的部分我来介绍一下生命科学模型的推理在推理的应用场景这是一个mini protein的设计的一个场景是基于结构和表位的Benders design的问题经过对于原始蛋白来做不断的序列优化最终得到效果更好的蛋白质的序列其中每做一次蛋白序列优化都需要对于它的结构进行一次结构预测因此结构预测的性能就成为了整个设计过程中的一个瓶颈原始的Alpha 4.2的Pepiline里边MSA和模板搜索部分都是跑在CPU上的并且性能非常差相当于占比时间非常高超过90%只有它的模型部分的EU4M和SharkModule是跑在CPU里边的这样的性能瓶颈很难让我们去做上万次的序列优化因此急需来对它进行性能改造因此我们是基于一个Tremol Protein的蛋白质大模型给大模型输入它的氨基酸的序列因为这个蛋白质大模型是针对于序列的一个充分的训练所以因此它认为它学习到了MSA的相关的知识的分布可以节省了CPU来去搜索MSA的这个时间然后并且这个Utremol PGRM的这个蛋白的表征过程和EU4M以及StruckModule都跑在GPU里边这样的话训练时间得到了充分的一个优化同时我们的这个模型跑在了以Triton Server为推理服务的然后并且使用了TenCert LM来做推理后端针对于结构预测独有的EU4M部分我们又做了专属的算子优化然后实现了FastEU4M的一个专属算子的一个结构在性能上获得了进一步的一个提升最终的表现上来看的话在CASP15和CAMEO两个平台机里边我们的效果和RF2接近持平在比较少的MSA的场景里边我们的效果比RF2还要更好但是在性能上获来了一个300倍的提升让整个Mini Protein的设计可以完全基于结构预测模型来去做如果进行同样的结构模型预测那就可以相当于从由来的需要10.8年到现在的只需要13天性能提升非常明显但是在很多追求结构预测高准确率的场景比如像符合物结构预测场景里边MSA的搜索部分还是比较难通过大语言模型来去替代的因此MSA的搜索性能本身的优化依然还是要去解决的一个难题我们的Pepiland中使用了Jegg Hammer和MM-Sequest 2两种不同的MSA搜索工具其中性能最差的是Jegg Hammer因此对于它的性能优化就是一个迫带媒介要去进行的一个工作首先我们对于Hammler的离线的文件的数据库进行了预构建并且采用了分片的分布式的方式然后同时每个分片里边都是通过二进制来去建库这样的话不管在查询性能和加载性能上都有了一个很大的突破同时因为我们进行了分片的一个构建过程在搜索过程中就可以进行充分的并行的搜索而且这个过程中我们可以做到是无锁的一个并行在最后只需要在最后进行多个结果的一个模式就能拿到一个完整的结果这样一个优化过程让我们的Hammler的搜索过程时间从112秒优化到13秒取得了8.6倍的一个提升这个对于整个PIPLAN来说都是只关重要的一个意义甚至比之前优化过的中卫优化过的MM-Syql2的性能还要更好同时我们的PIPLAN中也应用到了MM-Syql2NV他们确实开发了最新的MM-Syql2的GPU版本我们进行了实际的测试并且在性能上验证将近有186倍的一个提升最终我们两种优化手段都在我们PIPLAN中去采用在性能上也获得了非常大的一个优势在Hammler的优化里面我们其实还有进一步的优化手段是想要在多序列的搜索过程中进行充分的Batch来更大的利用好CPU的这个算力的资源从而获得更优的一个MS-A的搜索性能MS-A的搜索部分呢对于结构预测的性能和效果非常的重要因此这部分还值得深挖对于少部分场景它的MS-A天然的MS-A结果比较少的情况下大多数情况下它的结构预测的效果也不好那天然的一个思路是说能不能利用生成式的技术生成一些MS-A结果来帮助结构预测效果变好呢这个其实是可能的上面这个PIPLAN其实就是一个基于MS-A的生成做RAG来提升这个结构预测的PIPLAN它的输入是一个要预测结构的序列然后经过我们的蛋白质大模型生成它的Embedding并且在基于Mirrorless的这样一个蛋白质的效量库里面进行效量的召回这部分结果呢就作为了MS-A的一个context然后把这些context呢出入到我们的这个Mirrorless的生成模型里边来进一步生成更多的MS-A序列这样的话就可以扩充了原来天然搜索召回不了的MS-A的结果然后同时把这些MS-A丢进了结构预测模型里边换来了更好的模型预测结果从右边这个图里边可以看出来在CASP15和Cameo的数据集里边其实效果上都超过了Alpha4的图然后并且在这个只有少部分MS-A的结果里边结果的情况下我们的结构预测模型效果上有非常大的一个提升然后说完效果要说一下性能的部分这样一个模型这样一个生成模型其实是我们用它生成到了50K的一个长度来这样来达到一个比较好的一个模型效果生成这样一个长度在性能上也是有挑战的我们除了在Traten和TRTRM基础之上获得了基础性能提升在这个长序列的生成场景基于PageAttention之外然后使用了FlashDecoding的策略以及SmallQuantor的量化并且也尝试了Look at Height的这种投机采样的策略最终在性能上也获得了进一步的提升可以看到从右边这个图里面可以看到在效果上也获得了明显的一个提升同时我们也做了和VLM的一个对比在这个最终评测中也是最终的性能选行上选择了Traten和TRTRM从前面的结构预测场景中可以看出来生命科学的推理场景其实是一个融合了生物的高性能计算和模型的AI推理的一个复杂的过程并且有的节点跑在CPU上有的节点跑在GPU上也是一个易购计算的一个过程从右边这个图里面我们可以拿一个实际的例子看一下这是一个蛋白质设计优化的一个简化的一个场景实际的场景比这个要复杂的更多一些从左边第一步呢是先用生成模型来生成初始的Denovo的蛋白质的一个序列然后我们会对它的多个属性来进行预测来判断它是否是符合我们想要的设计目标其实也就是在不同的属性上它的表现是怎么样的比如下面两个其实是跑在GPU上的两个节点比如说先进行亲和力的预测同时也会进行表达量的预测然后之后也会并行的去做它的结构预测结构预测模型跑之前需要在CPU上来跑高性能的MSA的集团一个过程这样的预测出来的结果呢可以来判别生成的这个序列是否符合预期如果这个设计在多个属性上不符合预期的话那就需要重新去做生成或者是针对于这个设计好的序列来进行一些局部的突变优化来满足各个属性的一个达标如果各个属性都符合预期之后呢会进入后面的在CPU上来去做基于规则的专家的一些过滤的处理以及对于设计的分子进行一些后处理的过程这样整条PIPLAN的最大的并行度和设计的吞吐量呢才是整个在满着设计最关心的一个问题所以它并不是一个单点的模型要跑多快单点的一个CPU节点要它的性能是怎么样的是一个全局的一个流水线性能最优的一个问题所以因此呢我们其实需要一个能够分布式运行的并且是可以在CPU和CPU这样异构节点里边来进行流水线的一个推理这样的一个框架所以呢我们为这样的一个特定的场景基于锐的引擎呢设计了一个生物的HPC和AI推理融合的一套推理引擎这里边的底层呢我们是基于锐的框架来用它的workflow和它整体的分布式的EGO分布式计算的能力然后再至上呢其实我们充分内置了生物AI里面需要的一些组件包括一些生物HPC计算里面呢比如说 MSA的搜索呀MD呀这些相关的一些CPU的计算这部分呢其实我们也需要它对它进行更深的一些HPC的一些优化然后同时呢我们使用Tesati LM呢来对于这些我们实际的预测场景中的使用的模型来进行优化这些模型其实都是基于我们前面的Fondation Model来进行微调得到的CIO任务模型所以整体呢也适用于我们前面的这个推理框架里边能跑的这个模型的一个架构场景然后在至上呢我们会结合着业务呢去来去做不同的构图比如说有蛋白质设计的Graph有结构预测的Graph也有整体的去做稳固构建的Graph这样呢组成了我们一个充分适配于生物场景的这样一个推理引擎来在实际实际场景中发挥了更大的作用比如说我们在蛋白设计场景里边要进行一万次的这个蛋白优化的话如果即使是在这个模型单个模型都进行了优化的前提下我们都需要跑五天的时间那整个在这个流水线的这个框架下来并行跑起来之后呢既有考虑了这个流水线的这个推理过程也有动态的Batch的能力整体呢从五天的时间优化到八个小时所以整体的提升的性能表现是非常突出的在解决了生命科学大模型的训练难题和如何进行高性能的融合推理的问题之后就可以利用AI模型更好的在未知空间里边自由的探索能够突破当前设计的瓶颈这样就能在更多的有更大商业化价值的项目这边取得成功但是如果我们能把这些能力沉淀下来构建一个通用的生命科学的发现系统可以更加普适的助力各个场景进一步的提升它的发现效率这个发现系统其实可以分为三个阶段第一个阶段呢是用户来进行调研和立项阶段第二个阶段呢是进行设计和发现阶段第三个阶段呢是通过实验来做验证的阶段在调研和立项阶段呢用户需要对于市场的信息有更深入的了解对于当前的这个问题的生物的基底需要有更准确的分析我们以蛋白设计为例那这个调研立项阶段呢实际就是把点发现那它需要首先知道市场上有哪些有价值有商业价值的把点还可以值得去做然后在这个把点选择的时候需要通过生物的模型来预测各个把点它的成料性的一些可能和对于把点各个属性的分析这些部分呢都能助力在用户在选择起始把点的时候都能获得一个更好的一个设计的一个前提在设计和发现阶段呢其实是需要更多的A的发现阶段呢其实是需要更多的是需要更多的AI的能力来进一步的提升比如说我们这里需要更好的生成式的一个模型那我们在没有更好的起点之前我们通过生成式的模型找到一个起始的一个设计的种子序列那这个种子序列找的好坏其实就决定了后面在它基础之上优化的难易的程度这里面就变得非常非常关键了然后并且在找到了种子序列之后呢我们可以通过多目标优化的方式并且通过对于蛋白的各个的属性呢用不同的AI的模型来做预测通过AI模型的反馈利用多目标算法的能力来找有指向性的帮助理性设计这一块呢更快更准的找到符合目标的蛋白这里边其实在效率的提升是非常明显的在设计了有更好的设计候选序列之后呢我们是否能够通过智能的实验系统来对它进行高效率的实验验证就变得更加的重要了一方面这里的实验是不是具备着高通量和自动化的基本能力在此之上呢如果我们能对于设计的序列进行一些优先级的一些排序然后对于实验结果可以通过视觉和视觉的模型来去做更高更自动化的自动的结果分析这部分呢都能够提升实验验证的效率经过实验验证之后呢其实就可以实现了说整个知识的过程中呢能够去被沉淀下来然后模型呢其实也可以利用实验的数据进一步的改进然后整体在下一轮的设计过程中其实就会有更好更高效果的模型进一步的迭代然后在这个场景里面会越用越好是这样的一个状态如果抽象下来呢其实是我们是通过生命科学基础大模型的能力加上对于生物数据的深度洞察以及可以沉淀的这个专家的一些经验并且通过高通量实验的验证的能力整体来助力这样一个生命科学领域通用的发现系统来去提高整个的发现效率的一个过程这套发现系统从技术角度其实是一个多智能体的设计它其中包含三个子智能体分别是知识助手的智能体理性设计的智能体和智能实验的智能体其实每个智能体内部呢还可以细分为更犀利的智能体和工具整体呢整个的发现系统智能体是通过全局的设计过程来去做核心驱动的这样一套智能体其实构建在Langraph的智能体空下之上这样可以更好的自由的处理灵活的Operator之间的一些状态的变迁和跳转在知识助手阶段呢其实为了更好的获得相应的一些效果我们是构建在DeepSeqRE之上并且为了更加深度的对于数据的理解我们通过MirrorWars来构建相量的知识库来进行并且进行了DeepSearch来获得更好的REG的一些信息同时为了把我们对于生物数据的理解更好的助力到模型内部呢我们其实通过Neeper Graph来构建了基于生物中心法则的一个生物的知识图谱并且通过GraphREG再进一步增强模型的能力在理性设计阶段内置的这些生命科学的模型们就需要充分的发挥作用了不管是蛋白的属性预测还是细胞的预测甚至是DNA基因组的预测都会在设计过程中充分发挥作用对于生物的属性进行精准的预测并且可以对于设计过程有更好的一个指导来节省整个的发现探索的空间的寻入的一个过程并且是还需要和实验的这个智能体还需要和实验的智能化系统进行打通能够驱动自动的实验验证环节然后把最终的这个结果通过生成模型来返回给用户得到最终的完整的发现的结果其实这也完成了整个生命科学的发现系统的智能体的一个构建以上就是我和大家分享和交流的内容谢谢大家谢谢大家