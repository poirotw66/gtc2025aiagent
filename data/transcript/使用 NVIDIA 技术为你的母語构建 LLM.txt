大家好,非常荣幸今天能在这里和大家分享关于使用NVIDIA技术为你的母语构建LM的主题演讲。我是陈豪杰Jackie Chang,Voltee AI的CTO。另一位讲者是钟卓西Thomas Chong,是我们Voltee AI的人工智能研究工程师。今天的议程主要分为七大部分。首先,我们会探讨为什么现有的大型语言模型可能不支持你的母语。接着,我们将深入了解资源西圈语言构建LM所面临的挑战。然后,我们会介绍如何使用NVIDIA LEMO Curator进行高效的数据准备,以及如何使用NVIDIA LEMO Framework进行模型训练。之后,我们将讨讨论模型评估与微调,分享一些应用案例。最后,我们会展望社区合作与未来的发展方向。首先,让我们进入第一部分,为何大型语言模型可能不支持你的母语?因为,语言并非生来平等。目前,世界上有超过6000种,人说超过7000种人类语言。每种语言都有其独特的特点,受到社会、文化、政治和经济的影响。然而,2021年发表在《自然》杂志上的一项澳大利亚研究显示,在未来100年内,超过1500种语言可能会消失。悲观地看,90%的语言将灭绝。我们认为保护人类语言作为非遗在未来很重要,特别在当前的AI技术、大型语言模型、甚至大型多模态模型的帮助下,作为语言的容器,以保存文化、知识和思维方式。现在,让我们从另外一个角度来看。在机器学习中,我们会将某一些语言描述为资源稀缺语言。那什么是资源稀缺语言呢?这些语言可用于计算处理和分析的语言资源非常有限。我们有来自于CommonCraw还有这个维基百科的数据集。从图表中可以看出,并非所有语言都拥有相同的语言资源。这是维基百科最新的多语言统计数据。如你所见,主流语言,比如英语还有中文,为资源丰富的语言。数据量是十万级别的。然而,粤语还有其他大部分的语言为资源稀缺语言。你可以看到中文的文章的数量是粤语的二十多倍。更不用说英语是中文的十多倍。这种资源的缺乏阻碍了有效的语言模型和NLP应用程序的本地化发展和落地的应用。尽管粤语是一种资源稀缺语言,但它却是世界上使用人类最多的语言之一。使用者超过8600万人,排名第20位。粤语在香港、澳门、广东省、东南亚和海外各个唐人街广泛使用。那么,为资源稀缺语言构建LM究竟有什么普遍价值呢?首先,最重要的一点是文化保护。这是保护和传承语言文化的重要手段,让这些语言在数字时代也能继续焕发生命力。其次,它可以弥合数字鸿沟,让资源稀缺语言的使用者也能平等地享受数字技术带来的便利,不会被技术进步所边缘化。第三,它能够促进本地化。开发者可以开发针对特定语言和文化背景的AI应用,更好的满足本地社区的独特需求,例如本地化的客服、内容创作等等。最后,在资源稀缺语言上进行LM研究,能够推动语言技术发展,探索更有效的数据利用和模型训练方法,从而推动整个NLP领域的技术创新。接下来,我们探讨在构建资源稀缺语言LM时,我们面临哪一些挑战。为了更具体的说明挑战,我们以粤语独特的水文化为例。粤语以其丰富而富有表现力的水文化而闻名。水文化指的是大量使用与水有关的食语。以下是一些例子,比方说,吹水就是闲聊的意思,或者是,威水就是自豪意思。这些表达方式增加了粤语的语言丰富性,但是也给传统NLP带来了挑战,因为它们需要被语言模型准确捕捉和理解。粤语中有很多语言,俗语和网络用语,需要模型准确理解和处理。如果语言模型无法理解粤语用语,有时候会产生不正确或无意义的输出,就是幻觉。所以我们需要消除这些幻觉。以下是一个例子,答谁?它的意思就是有钱,但目前很多的大模型都会错误的理解它。这些挑战凸显了仔细的数据处理和模型训练的必要性,以确保粤语、LM的准确性和可靠性。除了语言本身的复杂性,数据方面也存在诸多挑战。首先是数据稀缺性,高质量的资源稀缺语言文本数据,远少于资源丰富语言,这是最根本的难题。其次是数据偏差。现有的数据可能存在地域、风格或主题上的偏差,这会影响模型的焕发能力。第三是数据清洗。从网络扒取的数据往往噪声很大,需要有效的数据清洗方法来取、触、噪音。第四是合成数据风险。不但的合成数据可能会引入语言错误,反而损害模型性能。最后是分词。资源稀缺语言的分词本身就具有复杂性,特别是对于口语化的语言容易出现长分词问题,影响模型的效率和准确性。为了应对这些挑战,我们使用NVIDIA Nemo Curator进行高效的数据准备。这是一个我们为资源稀缺语言的数据准备流程图。首先,我们需要确定文本类型,例如字典、文本、对话等等。然后,我们需要明确数据来源,例如问卷调查、评论、新闻、教科书等等。接下来,我们需要进行数据处理,包括数据指控、数据脱敏、数据去从和数据清洗等等关键步骤。NEMO Curator工具包可以在这个流程中发挥重要作用。在资源稀缺语言的数据准备中,构建高质量的词汇表至关重要。这里展示了一个粤语、英语、双语词汇对照翻译的例子。它不仅包含了粤语语词条,还提供了普通话翻译、粤语发音、词性以及英语含义。比如,吹水这个词,就详细标注了它的各种发音和词性,并给出了英语的解释。为了更深入的理解词汇的用法,我们还需要构建包含详细解析和使用示例的词汇表。这里继续以吹水为例,展示了更详细的词汇解析。它不仅提供了词汇的词性,还给出了粤语和英语的解释。更重要的是,提供了多个使用的例句,帮助模型更好的学习词汇在不同语境下的用法。例如,针对吹水的不同行义,我们都给出了相应的例句,例如,聊天,讲些未必是真的事,没有具体执行计划,等等。这里展示了另外一个例子,带头。这里的意思不是肚子很大的意思,而是怀孕的意思。同样,我们提供了奇性、粤语和英语解释,以及时使用例句。例如,搞大了人的头和它带了头就没有食音了。这些是传统NLP处理不了的。在数据收集过程中,我们经常会使用一些官方数据集,例如,维基百科。但需要注意的是,即使是官方数据集,也可能存在问题。这里展示了Hugging Face上维基百科粤语数据集存在的一些问题。例如,在香港这个词条中,后续有很多不名所以的标点符号。原因是,本来一个词条的内容就很丰富,很复杂。有英文的翻译,有粤语的拼音,有坐标,有信息表等等。我们发现了这个问题,并进行了修复。这里展示了修复后的维基百科,香港词条。刚刚说到的英文翻译,粤语,拼音,坐标,信息表等等都处理好。虽然这只是一个小小的细节,但它体现了数据清洗的重要性。在构建高质量的资源稀缺语言LLM的过程中,我们需要指示、检查和修复数据中的各种问题。为了更好的训练LLM,我们还需要构建高质量的指令调整数据集。这里展示了创建指令调整数据集的不同方法。我们可以利用现有数据集进行翻译,或者进行合成数据处理。我们也可以利用种子有目的角色数据,使用LLM翻译为目标的语言,然后进行指令数据过滤和查案。此外,我们还可以从支援稀缺的语言词典开始,作为种子的数据,进行翻译和改进。然后按质量和复杂性筛选,生成指令和回复,并利用上下文进行扩充。总而而知,数据整合就是一个多步骤,迭代优化的过程。这里展示了一个基于人物角色的数据集创建的例子。角色设定为音乐家。我们首先定义了角色的描述。例如,我是一个在香港的年轻音乐人。然后,我们根据角色的描述,生成相应的指令。例如,作为一个在香港的年轻音乐人,你的目标是一个充满活力的音乐界,得到迎合。通过这种方式,我们可以构建更贴近真实的场景,更具多样性的指令数据集。接下来,我想重点向大家介绍一下我们今天所使用的核心工具,NVIDIA NEMO Framework。NEMO Framework是NVIDIA专门会构建、定制和部署生成式AI模型而打造的端到端云原生框架。它的设计理念就是为了简化、复杂性、加速创新,让开发者能够更高效构建各种生成式AI应用。尤其值得强大的是,NEMO Framework在处理资源气水语言方面,展示了卓越的能力。正如我们前面讨论的,资源气水语言面临着输出量小,语言特点复杂的诸多挑战。NEMO Framework正是针对这些痛点进行了专门的优化,提供了强大的工具和灵活的架构,帮助我们克服这些困难,构建出高质量的资源气水语言模型。在接下来的环节中,我们会深入探讨NEMO Framework的几个关键组件,包括NEMO Creator用于高效的数据准备,Megatron LM用于大规模模型的训练,以及Auto Configurator用于优化模型配置。通过详细了解的这些工具,大家将会更清晰地了解到,NEMO Framework技术是如何赋能资源气水语言LLM的构建的。接下来,我将介绍NEMO Framework。NEMO Framework Creator,这是一个GPU加速的数据整理库。它可以提升生成式AI模型的性能,尤其适用于预训练的阶段。NEMO Creator可以拓展到多节点多GPU,显著了缩短数据的处理时间。它的主要功能包括数据下载和提取,数据清洗和过滤,重复数据的删除等等。使用NEMO Creator的优势就是在于,我们可以利用更小的数据,获取得更高的准确率,加速模型收拈,并简化数据的处理流程。这里更长期地介绍了,NEMO Creator的特征工程能力。在数据清洗和入处理方面,NEMO Creator可以清洗和入处理粤语的文本数据,提供文本格式化功能,例如,Unicode收服,换行服标准化,URL删除等等。用户还可以创建自定义的文本清洗器,处理粤语,处理粤语特有的问题。在数据下载和提取方面,NEMO Creator支持Common Code,Wikipedia,Archive等多种的数据语言。在词汇汇表构建方面,NEMO Creator可以快速构建低资源语言的词汇表。此外,NEMO Creator还可以提取Ngram的特征,捕获局部的信息。使用NEMO Creator进行数据入处理,可以带来诸多优势。首先是显示加速。NEMO Creator利用GPU加速,可以显示提升数据入处理的速度。其次是降低成本,缩短数据准备时间,减少自算机缘的消耗。第三就是提升迭代的效率。更快地准备数据的速度,可以支持更快速的模型跌达和实验。第四是数据质量。NEMO Creator提供高质量的数据清洗和过滤工具,提高模型的准确性。最后就是易用性。NEMO Creator简化了数据处理的流程,让数据准备的工作更加便捷高效。总结来说,NEMO Creator在支援稀缺语言数据准备方面,具有简注的优势。它可以帮助我们更高效,更高质量的准备数据准备工作,会后续的模型训练,奠定了坚实的基础。这里展示了一个使用NEMO Creator进行粤语文本的清洗的简单撕利代码。我们定义了一个自定义的粤语文本清洗函数,Clean Catalyst Test。它主要的功能就是保留中文汉字,粤语拓长指乎和空格,并去除此大的直呼。然后我们利用了NEMO Creator的Sequential和Modify功能,构建了一个清洗的流水线,包括Unicode收复和自定义的清洗函数。最后,我们将清洗后的数据集转化成Pandas DataFrame并打印输出。那这个只是一个简单例子,实际应用上需要用到更复杂的清洗和预处理步骤。接下来会大家介绍如何使用NVidia NEMO Framework进行模型训练。Megatron LM是NVidia NEMO Framework的周要组成部分,专门用于训练大规模的Transformer模型,它的优势非常显著。首先,它支持大规模模型,可以训练数十亿甚至数万亿的参数模型。其次,它具有高效分布式的训练能力,针对着多GPU和多节点的环境下进行优化。第三,它支持了混合的进度训练,例如FP16和BF16,可以加速训练并减少内存的占用。第四,它提供了灵活的模型架构,支持各种Transformer的架构,方便用户去进行定制或扩展。使用NEMO Framework训练支援奇学语言LM,大致可以分为以下几个步骤。首先是数据准备,我们使用之前介绍的NEMO Creator完成粤语的数据入处理,生成训练的数据集。然后是模型选择。我们可以以挑选合适的预训练模型作为基础模型,例如Chainmark,Lama等等,或者由头开始训练。接着就是NEMO Framework的配置。我们需要配置NEMO Framework的训练环境,包括训练交构、参数、分布式的训练配置等等。配置完成后,我们就可以用来去进行模型训练,启动Megatron LLM的训练脚本。最后,在训练过程中,我们还需要进行监控和调优,根据性能指标调整超参数、优化模型的效果。针对资源气色语言的特点,我们需要进行一些柔和。首先,考虑到数据量有限,我们可能要选择更小的模型规模,避免过异合。其次,我们可以采用更激进的正规化策略,例如Dropout Way Decay,提高模型的幻化能力。第三,迁移学习和微调是非常有效的手段。我们可以利用高质量语言的预训练模型,进行支援气色语言的数据微调。第四,Nemo Framework已经提供了超参数调优工具和方法。我们可以利用这些工具进行超参数的搜索和优化。最后,根据支援气色语言的语言特点,我们还可能需要对模型的架构进行微调,例如调整Embedding Size,Attention Head的数量等等。这里展示了一个Megatron LM训练配置文件的部分式例。我们可以看到,这里可以配置预训练的模型路径,分其次类型和词汇表。模型结构参数例如Hidden Size,Layer数量,Attention Head数量,分布式训练的侧位,数据路径,优化器参数,训练配置和精度等等。这一个就是几个简单的例子,实际应用上还要根据实际情况进行更尝试的配置。模型训练完成后,我们还需要进行评估和微调,以确保模型的性能达到预期。模型评估需要合适的评估指标。我们常用的指标包括困惑度,Proplicity,它很让模型预测文本序列的能力,数值越低越好。Blue,Rosecourt等等的指标,常用于生成文本的质量,例如机器翻译或文本材料用物。更重要的是,我们需要设计语言的特定指标,根据语言的特点,例如考虑语语和口语表达的正确性。此外,人工评估对于资源及器械语言的LM是贯重要。它可以全面地评估模型生成文本的流畅性、地道性和文化的适应性。为了进一步提升模型性能,我们可以采用多种微调的策略。指令微调是常用的方法,使用指令数据及微调模型,提高模型在特定任务上的性能,例如问答、对话生成等等。基于人类反馈的强化学习,RLHF,可以收集人类对模型生成文本的反馈。使用强化学习方法可以进一步的优化模型,提升生成文本的质量和实战性。如果LM针对特定领域的应用的话,例如粤语的新闻杂要,我们可以利用特定数据进行微调。为了更高效地进行模型训练和微调,NVIDIA提供了Auto Configurator工具。它可以根据GPU数量、TFLOPS训练时间点月初,推荐和训练的模型参数量级。它可以预估训练的时间辅助训练计划。它可以生成NEMO 2.0格式的基础模型配置,会后数的优化奠定基础。它也可以收缩并推荐影响吞吐量的关键超参数的优化组合。Auto Configurator可以帮助我们快速找到最优的配置,提升训练效率和模型性能。这里展示了Auto Configurator的使用,初始化Auto Configurator还有生存配置。首先,我们需要初始化Auto Configurator,并指定训练配方Recipe,例如使用Lama Free的145M,以及GPU显存,并行度,Batch Size,最大训练的天数,训练Token量,磁表大小,日制的路径等等的参数。这些参数描述了我们硬件的资源、训练目标和约出桃件。然后,调用了Generate Config run的函数。Auto Configurator会根据我们的参数,自动生成候选的配置列表,并保存在Config的变量当中,方便后续进行选择和评估。然后是运行训练配置和获取结果。在生成候选配置的列表后,我们可以选择一个配置,例如Partials,Argues.runNumber-1,并将其负质给Petrain CFG变量。然后,使用FDL.build构建训练任务,并调用Petrain启动NEMO的训练。训练完成后,我们可以调用Get Results获取训练结果。Auto Configurator会分析训练日子,提取关键性的指标,并推荐最优的配置,帮助用户快速找到最佳的训练方案。这是一个简单的例子,实际应用上会有更复杂的步骤。这是一个评估和微调的流程。首先,我们需要构建评估的数据集,准备高质量的粤语评估数据集,包括各种任务和语言风格。然后,选择评估指标,包括自动指标和人工评估。接着,进行模型评估,分析模型在不同方面的表现。根据评估结果,选择合适的微调策略和超参数,微调模型。最后,进行迭代优化,重复评估和微调步骤,不断提升模型性能。接下来,我们分享一些资源气血语言,LOM的应用案例。资源气血语言,LOM,在许多商业场景中,具有应用的价值,尤其是在那些需要本定语言了解的场景中,例如客服,疫情监控,翻译,教育,呼叫中心,新闻摘要,数码营销,会议记录等等。这里是一个简单的粤语大模型的展示,是我们基于上述方法去训练的粤语大模型。在香港,我们说粤语的时候,很多都是中意混合,我们叫做Close Switching。比如在这里,我们想要聊天机器人去介绍一下香港的茶餐厅,我们说intro一行,而模型还是能够理解和回答。茶餐厅的食物可能比较有利,我们可以追问聊天模型怎么样去吃的健康一点,模型也可以按向下文理解回答。这里是另外一个例子,这是我们的疫情监控平台,能看到香港不同社交媒体渠道,例如Facebook,Instagram,X,YouTube,新闻,论坛等等。这里我们再关注一个话题,就是人工智能。然后可以在5W1H的框架,就是何时,何时,何源,何地,和如何了解话题。我们也可以在不同的视频,例如标签或者是某一个时间点上,看相关的原文,但是实在是太多了,所以我们会用到大模型去分析和总结,还能够有更势力的一些情感分析。这里列举了一些具体的行业案例。在金融业,我们可以使用本地LM,进行语音识别和文本分析,应用于风控和客户服务。在本地媒体,我们可以使用本地LM,自动生成本地语言新闻报道,内容参作。在零售业,也是可以利用本地LM构建智能客服,提升用户的购物体验。在公共的服务机构,我们也可以利用本地LM提供公共服务的信息,例如政策、自询、办事指南等等。最后,我们展望社区合作与未来的发展方向。我们对资源稀缺语言LM的未来充满信心。我们希望将资源稀缺语言LM应用到更广泛的领域,服务更广泛的语言社区。比如,香港的HKX,让更多人受益于AI技术。我们也在积极探索多语言模型,希望实现对多种基源稀缺语言的支持,构建一个更加包容和多元的语言模型生态系统。对于粤语言大模型,我们将持续诱化模型架构和训练方法,不断提醒其性能和应用范围,力争打造世界领先的粤语言模型。为了更好的服务于企业和开发者,我们在研发VotiMagic平台,这是一个一战式训练众多模型的企业级LM训练平台。VotiMagic,专注于全自动智能体运维,从数据收集,数据清洗,数据标注,到模型训练,提供生成式数据管道和模型融合等前沿技术,实现模型训练自动化。我们正在使用VotiMagic构建的一些翻颜和小于种大模型,除了粤语大模型,也开始了包括一般语大模型和早哇语大模型。以早哇语为例,虽然使用的人数超过8000万,主要分布在印度尼西亚,但其数字化程度低,标准化数据集有限。构建早哇语LM的重要性在于提升母语者的技术可及性,并保护印度尼西亚丰富的语言文化遗产。一般语使用人数为70到80万人,主要分布在马来西亚沙拉越。其挑战在于可用语计算的数字语料库和语言资源有限,构建一般语LM的重要性在于保护一般社区的文化与历史身份,同时开拓数字包容性的途径。我们即将支持更多发言和小语种,敬请期待。再次感谢各位的聆听,希望今天的分享能让大家对使用NVIDIA技术构建资源稀缺语言LM有更深入的了解。如果你有任何问题,欢迎随时与我们交流。谢谢大家。谢谢大家。