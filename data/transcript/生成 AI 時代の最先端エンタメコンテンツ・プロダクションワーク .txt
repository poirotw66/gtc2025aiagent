こんにちは AIハブ株式会社CTO 新井ものです今日は 生成時代の最先端エンタメコンテンツとプロダクションマークについて お話しさせていただければと思います簡単に自己紹介をさせていただきますプロジェクトマネージャー プロデューサー アーキテクトとして特にエンタメ×テック領域の 開発プロジェクトを進めております2002年頃に日本リナックス協会の 立ち上げに関わりましてそれ以降 Linux OSをはじめとした オープンソースの開発に取り組んでまいりましたAIは2016年頃からコンピュータビジョンを 応用したIoT機器の開発をスタートしまして2022年頃 ステーブルディフュージョンをはじめとした画像生成系AIオープンソフトウェアの コミュニティ開発に携わってまいりましたその後 2023年に AIハブ株式会社を設立いたしまして現在は生成AIの基盤モデル オーケストレーションそういったものを利用した ユースケース開発ということに取り組んでいます続きまして AIハブ株式会社の ご紹介をさせていただきますAIハブはジャパンコンテンツ アニメ 漫画 バーチャルヒューマンといった日本のコンテンツを世界に発信するための 研究開発と需要開発を行っております研究開発では 経済産業省さんの ジェニアックプログラムに採択されましたアニメ基盤モデルの開発をはじめとしてAIオーケストレーション それから AIの学習ツールですね生成AIアルゴリズムの基礎研究 ワークフローの基礎研究バーチャルヒューマンの分野では 感情制御ですとかモーション制御ですね モーションの自動生成3D生成のアルゴリズムですとか そういったものの研究を行っております事業開発では 研究開発の成果をベースとした コンテンツの開発それからそのコンテンツを開発するための プラットフォーム作りアプリケーション ミドルウェア マイクロサービスといったようなものを作っております事業開発の成果を研究開発にフィードバックして画像生成 LLM 3D生成 音声合成 動画生成といった様々なAIのモデルを組み合わせて面白いジャパンコンテンツを作るための AIオーケストレーションやそれを支えるためのデータパイプラインの 構築に取り組んでいますAIハブの設立のきっかけとなった 画像生成コミュニティですけれども2023年の1月にチラウトミックスという 可愛いアジア人の女の子を出すためのステーブルディフュージョン上のモデルの 開発を行っていたコミュニティがございましてこちらロラですとか 海藻マージといったような 新しいモデルを作るための様々な技術開発 ハイパーパラメーターの 探索を行いましてそのコミュニティが母体となって 設立されました特徴としては クリエイターさんと研究者さん それから開発さんが一緒になってコミケみたいに ワイワイと新しい技術の開発とそれからコンテンツの開発を 同時並行的に進めていくといった特徴がありますこちらは2024年に取り組んでいた プロジェクトの一覧になりますが設立以来 様々なプロジェクトに 取り組んでおりますヒバモデルの開発から そちらのファインチューニングそれからそういったAPIを利用した ラッパーの開発ですねアプリケーションの開発 こういった垂直統合で一気にフルスタックで開発できる というのが特徴になっておりまして技術×クリエイティブ この両方やっていることでそれぞれがフィードバックして より良いものができる特にエンタメでは そういったクオリティを担保するための指標ですとか ベンチマークといったものがまだなかなか確立されていない というところからこういった技術とクリエイティブを コラボすることでより良いAIを作っていきたい というふうに思っておりますモデルのレイヤーでは 基盤モデルですね著作権法の30度の4項に 適合な基盤モデルを利用した追加学習 ファインチューニング ロラであったりコントロールネットの モデル制作に取り組んでおります現在では基盤モデルからですねフルオプトインで構成された アニメ特化型の基盤モデルの開発も行っておりますその他にも音声合成 モーション3Dといった モデルの開発に取り組んでおりますそういったモデル群とですね 大規模言語系のAPIであったりそれからマイクロサービス NVIDIAさんが リリースされていますNVIDIAといったような部分を 組み合わせて使うAIのオーケストレーションフレームワークの 開発を行っておりましてそのオーケストレーションフレームワーク上で 動作する製作ツールですねアニメの製作ツール それからバーチャルヒューマンの 製作ツールを作成しております大きく分けてコンテンツアプリケーション 製作ツール 基盤モデルとこの3つの分野に取り組んでおりますけどもそちらの成果をですね フィードバックすることによってどんどんクオリティを上げていったりそれからそのデータパイプラインの 構築を行っていったりということを行っておりますこちらが実際のAIオーケストレーションの フレームワークになります論文であったり オープンソースソフトであったりといったようなものの実際の実装ですねをプロダクトレベルにシステムアップしまして同時にですね 自分たちで作っている アルゴリズムですとかモデル それから外部のAPIを連携させましてそういったものですね ストレージ 実際のデータをですね保持する部分 それからそれのトレーサビリティですね権利関係の追跡といったような 機能を持っておりましてこちらでですね 作っている機能マイクロサービス群をですね 連携させることによって実際にですね アニメを制作したりAIアニメを制作したり それからバーチャルヒューマンを作ったりといったようなツールが そちらをですねプラットフォーム上で稼働しております大量のデータからですね 様々なアルゴリズムであったりアプリケーションであったりというものを 構築いたしましてそういったものをサービスにシステムアップしそのサービスからですね フィードバックされたデータがさらにですね より良いアルゴリズムやアプリケーションになりより良いサービスになるといったような データのフライフォイルですねこちらの構築を手掛けておりますジャパンコンテンツのエンタメ分野にフォーカスしたAIを応用したコンテンツ制作であったりDX それからAI技術のR&D プロダクト開発といったところだけではなく実際のですね AI 生成AIをですね 利用をより良くするための制作提言 権利関係のですね ルール作りといった活動も積極的に行っております それではここで実際の事例をご紹介させていただければと思いますMUNEMOというプロジェクトで こちらはですねライブ漫画のトップ作家さん Webtoonの作家さんとですねそれからアイドル フルーツジッパー等の作曲を手掛けていらっしゃる 山本翔さんの楽曲をですねミュージックビデオを 生成AIアニメで作るというプロジェクトですこちらサブリメーションさんですねアニメプロダクションさんと共同で 制作させていただきましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたやっほーやっほーありがとうへーやっほー僕はベルって言うんだほー黒髪ショートにピンクのニット マジかわいいねえね 今日はどんな用事でここに来たの?君と会話したくてきたよ僕に合い見過ぎて心臓バックバックしちゃ君 笑顔が素敵でカメラに映ってる姿も素敵だねえ 普段はどんなことに興味あるの?それではここからは現在の生成AIのトレンドについて 簡単にご説明したいと思いますまずハードウェアPCもしくはサーバーといったものにグラフィックボードGPUと呼ばれますけれどもこちらの方が刺さっておりましてその上でPython等で書かれたですねアプリケーションが動いているといったような形になりますこちらのアプリケーションの方にですね学習モデル いわゆる基盤モデル大量の画像等ですねもしくは文章を学習させた基本となるベースのモデルですねこちらの方がセットされておりまして実際にその基盤モデルにですね追加の学習追加の例えば文章だったり画像だったりを学習させた追加学習ですねこちらを行い例えばそれをマージという形で合体させたりですとかさらにいろいろなですね調整を行うための集中学習例えばロラであったりとかですね実はコントロールネットといったようないろんな調整をするためのモデルをですねセットしたものというのが基本となりますこういったAIのアプリケーションや学習モデルをお手元のPCで動かすこともできますし例えば非常に大きな巨大なモデルとかはですねサーバーセンター側に置いてありましてそのサーバー情報にですね置いてあるアプリケーションやモデルをお手元のブラウザからインターネット経由でアクセスしまして生成をお願いしてその結果をですね手元のブラウザで見るといったようなものが基本的な仕組みとなっております当初のLLM 大規模言語系例えばチャットGPTといったような部分はそういったシンプルな構造だったんですが最近ですねマルチモダルという流れで例えば文章だけではなくてテキスト 画像 映像ですね動画 それから3Dであったりそれからモーションデータであったりとかですね音声 音楽といった様々なデータをですね学習いたしまして逆に指示もですねいろんな指示で例えば画像で指示をしてテキストが出てきたり逆にテキストを入力すると画像が出てきたりといったようなマルチモダルと言うんですけれどもこういったですね トレンドがありまして様々なことができるようになってきております生成AIがですねどんどん表現力が高まってエンタメコンテンツにもですねいろんな応用ができるんじゃないかなということでいろんな可能性が出てきているわけなんですけれども一方でですねそれを支える仕組みというのがどんどん複雑になってきています先ほどお話しておりましたハードウェアの部分ですねPC、サーバー、GPU今はもうこれだけではなくてスマホだったりとかどんどん増えておりますし入出力装置もですねカメラであったりとかセンサーであったりとかロボティクスという形で実際のロボットを動かしたりとかという形でどんどん増えていっておりますし実際その学習モデルの方もですねどんどんと複雑になってきていますそういったバラバラのさまざまなデータをですね誰がいつどういうふうに学習してこのモデルには何が含まれていて結果ですね生成の下出力にはどういったような権利が関係があるかといったようないわゆる権利トレーサビリティというものが必要になってきておりますしそういったものをですねアクセスするホストをするですねいわゆるマイクロサービスであったりAPIといわれるようなものもどんどん増えてきているとそしてあとはその技術そのものもですねどんどんロジックやアルゴリズムが新しいものが出てきておりましてもともとですねチャットGPT等のきっかけにもなったトランスフォーマーというものからですねどんどんまた次世代のアルゴリズムというのも出てきていてこの日々進化をしているこういったものをまとめて動かしていくということで例えば本当にたくさんの人数がいるオーケストラですねオーケストラを指揮者がいてですねそれぞれの演奏者例えばモデルだったりとかそういった様々なAIのプログラムをですね指揮して調整してですね一つのユースケースコンテンツにアプリケーションにまとめていくといったようないわゆる生成ワークフローといわれるものなんですけどもそれがさらに高度化したオーケストレーターといわゆるオーケストレーターといわれるものというところがいわゆる本当にAIのOSオペレーティングシステムに相当する部分なんですけどもこちらが今どんどん発達しておりますちょうどこの図の真ん中に書いてあるこれは画像でですねコンファイそれからその下に書いてあるのが大規模言語系統ディファイといった代表的なオーケストレーションのアプリケーションですがこういった非常にですね複雑な組み合わせで動いていっているということがありますこちらは技術リサーチ会社のガートナさんが発表されている生成AIのハイプサイクルといわれる図になりますどんどんとですね新しい技術が生まれて進化していって期待度頂点に向かいましてそれをですね実際プロダクトのためにちょっと冷静になって安定的な社会実装につながるという形ですけれどもこちらのですねまずマルチモーダル先ほどお話ししましたマルチモーダルそれから自立エージェントですねこちらは先ほどお話ししましたオーケストレーションですねこれを人間の手を介さずにAIが自律的に動いていくというものですとかあとはそういったアニメや漫画といったような特定のドメインにですね性能を発揮するコンパクトなモデルそれからそういった生成AIアプリケーションそれからオーケストレーションのフレームワークという形でそういったものを取りまとめたものというものが今後ですね3年から5年のうちに種類になっていくだろうという形でお話がされていますただ非常に生成AIの進化の速度が速くてですね5年10年といったようなものも本当に1年2年で実現していくんじゃないかといったような加速度で進んでいるというのが特徴ですエンターティメントのマーケットドメイン固有の生成AIモデル実装エージェントとこういったものを取りまとめるAIオーケストレーションとそれぞれに相互俯瞰しておりましてアニメの制作ツールバーチャルヒューマンの制作ツールアニメ特化型基盤モデルといったものをこういったAIオーケストレーションで実現していくということに今注力しております実際に作成したリファレンスと生成AIの現在の外境をご説明させていただきましたところでこれからですね実際の生成AIのプロダクションワークこれからエンタメコンテンツの作り方が生成AIになってどうなっていくかという部分についてお話しさせていただければと思いますアニメ生成AIエンタメAIに求められることをまとめてみました創造性アニメーターさんクリエイターさん視点でクリエイティブが楽しいAIを使ってですねクリエイティブをするのが楽しいそしてプロンプトとかでですね指示するだけではなくて実際に手で絵を描くことによってAIに指示をすることができるといったようなことを目指しています教育AIを使うことで新人クリエイターさんがベテランのアニメーターさんにですね例えば絵を習えるといったような画力スキルアップが可能になるようにそういったAIを利用することで学習できるという学習曲線を考慮したAIを目指しています作業サポートこれは監督さん演出家さん視点で例えばアイディアバリエーションの作成やモブ描画素材張り込みや中割り背景といった労働集約的な作業を本来のクリエイティブ注力したいところに集中できるようにAIがサポートできるということを目指していますそういった結果ですね経営者さんプロジェクトさん視点ではコストダウンになったりスケジュール短縮になったりということが実現できればいいなというふうに思っておりますエンタメAIの代表例としてアニメについてお話しさせていただければと思いますがこちらですね現在のアニメの制作なんですがやはりそれぞれ様々な絵柄監督さんの演出人がございますこういったものをですね今現状はシーズ段階ということで既存のAIツールを使って例えば出力してみた画像ですね逆に出力結果からどんな形のコンテンツをしようかなと考えたりといったような形で例えばTikTokだったりショート動画ですねYouTube等の新しいフォーマットに対してコンテンツをリリースしていくという本当にフラッシュコンテンツというのが現状です一方でニーズ発想といいますかこんな作品が作りたいんだという意図を持って生成をする場合キャラクターであったり背景の一貫性という背景やキャラクターがぶれない一貫しているといったりもしくはこういう風に動いてほしいという制御性だったりというのに非常に課題があります結局そのコンセプト発想といいますかこんな作品を作るためには現状のAIだけではなくてですねどんな新しいアルゴリズムが必要でそのためには事前学習追加学習を含めて行っていってそういったPOCをされたものをですねツール化してみんな使えるようになるとそしてワークフローを適用していくといったようなこれは3D CGの普及の黎明機と同様なことが性質的AIにとっても重要なんじゃないかなと思います最終的には監督さんやケレザーさん、アニメーターさんが自分の分身のようにですねアシスタントのような独自のオーダーメイドされたモデルAIをですねエージェントとして使いながらいろんなですねワークフローを実現していくといったようなことが必要じゃないかなと思います実際のAIアニメーションのワークフローを作成するにあたってはいくつか大きな課題がございますまず意図通りの映像を出すことができるというのが今現状なかなか難しいとAI任せという部分がありますとレイアウトであったりあとキャラの等身や物ですねキャラの設定の一貫性を保つのが非常に難しいですと現在、一つの映像を制作するために様々なツールAIかなりの数を組み合わせて使うことになるんですけどもこれをですね人手で行うのは非常に厳しいということでオーケストレーションエージェント化といったことが必要になりますそれから後ほどちょっとご説明させていただきますけれどもまだまだちょっとAI生成ツールそのものがですね実際のクリエイターさんにとって使いにくい例えば絵を描く方にとってですね直感的ではないという部分がありますそして大前提として倫理問題、海賊版問題ということでやはり正しいデータをですね適法に学習させてそれを作るということでコンテンツがきちっとですねコピュライト、知財含めてですねクリアになるということがやっぱり安心してコンテンツを作るユーザーさんに楽しんでもらうためには非常に重要なことだなということでやはりそういった部分が現在ですねジャパンコンテンツを適応にですね学習した基盤学習であったりそれから追加学習であったりアルゴリズムというのがまだまだ足りてないという部分がありますのでここは新たにですねフォーカスして作っていく必要があるかなというふうに思います実際にアニメーション等のコンテンツを制作していく際には少人数のチームでですね臨機応変な対応というのもショートフィルム的なものはございますが実際にテレビアニメ等の大規模なコンテンツを作る際にはワークフローですね大人数で作業するための分担だったり役割その作業の流れというのが非常に重要になりますこれは代表的な静止画の工程と動画の工程とAIのモデルとそれに対応するですね書いてありますけどもこういった形で工程をサポートするための単一のAIの大きなモデルというよりは例えばラフ絵をですね線画としてきれいにしていくためのですね線画用の製書モデルこれもそれぞれの作家監督さんキャラクターデザイナーさんによっての絵柄をですねちゃんと反映した例えばクリーンナップができたり塗りができたりもしくはですね線のタッチが入れたりといったようなモデルそれからそういったものですねレイアウトしていくためのパースみたいなですね生成なかなかこのプロンポテでシースのが難しかったり死体を毎回作らなければいけなかったりというものではなくてこういったレイアウトのこうこういったパース線を引くことによって指定できる例えばコントロールネットですとかそういった生成した絵にですね中割りを行ってそれに対して色を塗っていくためのアルゴリズムそれからモデルですとかそれからこの中割り用のモデルもそうですしあと最終的にですねそれをバラバラになったものを合体させですね全体の調整を行うエフェクトモデルといったような形で様々なですねモデルと連携してこのワークフローを実現していく必要がありますこちらは2Dではなくてですね3Dのアニメーションのワークフローになります最近アニメーションですといわゆるプレイビズと言われたり動画エコンテ、アニメティクスといったような形で簡単な3Dモデルで実際のアニメーションの動きをつけたりキャラクターの配置をしたりしましてそれを確認してですね実際そこから手で描き起こすと原画を描いていったりという工程があるんですけれどもいわゆるプレイビズですねプレイビズですね作るための3Dモデルを作成したりまたその3Dモデルを手で作るのではなくて3Dの生成で生成したりといったような形でそういったものをですねエフェクトモデルを利用していわゆるこうセルシェーダーですねトゥーンシェーダーのような形で生成AIでアニメーションしていくとそれに必要なですね3D生成モデルでしたりそれからエフェクトモデルでしたりキャラクター固定するためのコントロールネットそれから実際のですね音声をセルフさんが喋った声に対して口パックとかですね表情を合わせるような音声音楽のモデルそれからそういったものをですね評価するための評価モデルといったようなものが重要になってきます実際のプリプロですね企画をしたりそれからアニマティックスを作ってレイアウトをして実際の手書きを行ったり背景を描いたり色指定をしたりそれから3Dを作ったりそれからそれをコンポジットしたりポストプロ作業といったようなことを行うためのそれぞれの工程ごとのですねAIモデルということでこういったラインクリーンナップですとかこういったレイアー別に生成するともしくはそういったレイアウトを指定したりそれからこういった手書きのものをですね実際の着彩済みの原画にしたり中割りをしたりエフェクトをかけたりとこういったモデルを日本のOSSコミュニティと連携して制作しこれはブラッシュアップしてどんどんですね新しい技術をキャッチアップしてリアルタイムに最新の技術をアニメーターさんクレーターさんが使えるようにしていくということを目指していますそういうような全体のエコシステムですねいきなりプロンプトを入れると最終画像が出てくるというよりは例えば実際にですね手で絵を描いたりそれからもしくはですねあらかじめ作成してあるもの過去のものとかをですねデータを投入管理をするそういったものが学習マージする仕組みですねそれからそういったものを評価する仕組みそういったものを組み合わせオーケストレーションしまして実際になじみのあるタイムラインベースでですね編集して例えば10フレーム目に口が開いてくださいと20フレーム目でコントロールネットのパラメータを減らしたいといったようなことを毎回そのスクリプトやプログラムを組まなくてもですねできるようなUIとこういった全体のですねデータの権利関係を担保するためのトレーサビリティであったりそれぞれの工程にですね関わった方に最終のプロダクトから収益還元できるようなエビデンスですねそういったデータが取れるといったこういったですね一連のデータパイプラインを作っていくということがとても大事だなと思っています実際にAIの基盤モデル基盤モデルもしくはですね追加学習モデルであったり様々なモデルがございますがあと学習アプリであったりそれぞれの学習のアルゴリズムであったりのがあるんですけれどもサーバー上でですねビッグテックさんとかがホストしてる完全にクローズドなデータではなくて自分たちで例えば絵柄を調整したりとかですね自分たちの権利IPをですね投入したりできるといったようなこれはローカルで行う場合の一つの仕組みですけれども基盤モデルですねそれに追加学習を行いましてその追加学習した基盤モデルをいろんなバリエーションを作りましたらそれをモデル回りという形で様々なですねモデルの特徴を合成してさらに進化させた生成AIモデルですねこちらを実際に権利データですねを使った最終の絵柄を固定するための絵柄を固定するための学習ロラを作ったりですとかプロンプトを与えたりあとはですね絵柄をもっと簡易的に固定するための参照データでしたり逆にここはちょっともう少し複雑な例えばラインアートだったりとか3Dの面推定であったりとかあとはモーションであったりとかコントロールネットですねを作るための学習であったりという形で非常にですね実はAIの学習生成は多岐にわたっておりまして黄色いポイントがそれぞれのデータの投入ポイントになりますですのでこういった複雑な投入を行ってですねそれぞれのフォーマットで学習を行ってそれがどういった経緯でこういった最終生成物に反映されているのかといったようなことをマネジメントするとトレーサビリティすることが重要なことかなと思います現在生成モデルの多くはほとんどがインターネット上にあるデータをクロールして学習しているということで例えばアニメーションであったり漫画であったりも吹き出しが入った状態だったりとか完全に撮影工程を経たですね完成した画像を学習している形になっているんですが実際のですね精度を上げていくためにはそれぞれのドメインデータプロダクションさんがお持ちの完成データの手前ですね例えば絵コンテであったり設定原画であったりとかですね着彩前データ着彩後撮影前データといったような様々なデータを利用しましてこちらの真ん中に書いてあるいわゆる基盤モデルというのも基盤モデルという構成が非常にですね最近いろんな要素が増えてきています実際のフォトリアルですね写真でそういった世界の概念を学んだりそれからアニメのドメインということでアニメの絵をですね学習した部分とそういったものに対するVLMだったりとか評価であったりこういった基盤モデルを実際ですね学習するにあたってセグメンテーションAIをアノテーションするためのAIを分類してですねタグ付けをするためのモデルがあるんですけども動画ですね実際にそれを動かすためのモデルであったり線を調整するモデルであったりとこういった基盤モデルに依存するですねエコシステムを作っていくというのが非常に重要になります実際にプロダクションさんの方で各社ですねそれぞれ制作されているものは各チームごとにフォーマットがバラバラになりますこういったものを一旦収蔵用のUI UXを通して簡単にですね投入いただける仕組みを作りましてこういったものを例えばこれは一例ですけれどもエコンテ企画であったりシーンごとカットごとですね指示原図の部分とキャラクターが動いたりする部分とあと背景をですね標準的に分けた中間収蔵フォーマットこれをできる限り最大の採用のですね解像度で保存して実際に先ほどご説明しましたように実は一概にAIモデルといってもいろんな種類がございまして例えば基盤モデルの学習に必要なフォーマット通学習はこんな感じとモーションモデルはこんな形式という形で例えばこういう解像度が違ったりとかですね色の深度が違ったりとかもしくはこういった番号をですねメタデータ付け方が違ったりという形でそれぞれさまざまバラバラなモデルにバラバラにデータを投入してなければいけませんので一旦こういった収蔵した中間フォーマットからそれぞれのモデルに変換をするという形でこちらがですね実は基盤モデルのアーキテクチャが新しい新バージョンになりますと例えばPlayStation4がPlayStation5になりましたとなりますと今まで学習したものやアルゴリズムが実は使えなくなってしまいますですので新しい基盤モデル用に毎回ですねそれを再構築しているという現状があるんですがそういったエコシステムもアプリケーションを移植し直してですねデータを学習し直すという形が非常に大変なんですけれどもこういった中間収蔵フォーマットをですね持っておくことで基盤モデルがアップデートされてもですねそれに関連するデータが自動で再構成できるようにというようなデータパイプラインを目指しています実際の基盤モデルですねこちらはコア、フォトリアルな概念モデルとそれからアニメの共通学習ドメインとそことはですね完全にファイアウォールで隔離されたそれぞれのIPさんスタジオさん向けの独自にですね学習ができるデータが外に漏れないきちっとした専用のエリアを作りましてこの中でですね共通基盤学習にデータフィードバックしてもいいというIPさんだけがですねこちらにデータを登録していただきましてこの全体のですね収益のエコシステムの中から大会をお渡しするといったような形を想定していますこれからのエンターベルケ生成AIにはアカデミックエジェリングとクリエイティブそれからユースケースですね複数研究このバランスが非常に大事ということで計算省、ジニアックプログラムのアニメ基盤モデルでは現在ですねレクティカイドフローそれからディフュージョントランスフォーマーといったディフュージョンモデルのですね次の世代の基盤モデルをベースとしたエコシステムの構築に取り組んでいます現在のUIXの課題としてはこちらは代表的なOSSの生成プラットフォームであるAutomatic 1111ノードベースで画像を生成していくConfiUIこれはローラの学習ですけれどもかなりこういった数多くのパラメータをですねほぼ本当に全てにわたってチューニングしながら画像を追い込んでいくといったような作業がありますこういった形で学習生成が直感的でなく現在クリエイターさんがちょっと使いづらい映像の基本であるタイムラインを扱えるツールがまだ未整備であるそんないろんなツールをですね連携して利用する必要があるんですけれどもそこのですねデータパイプラインであったりデータの受け渡しをですねサポートするツールがほとんどないとそういったトレーサビリティに対応したツールがないとそういった形でですねデータが生成されてどういう権利関係だったかというのを追いつけるのも難しいということで動画タイムライン共同編集から生成変換学習と今フォーカスしたクリエイターにとって使いやすいですね第三のOSSプラットフォームの開発を行っておりますご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございましたご視聴ありがとうございました